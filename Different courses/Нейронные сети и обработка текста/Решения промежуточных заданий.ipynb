{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c18145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c205b357",
   "metadata": {},
   "source": [
    "## 2.4.5\n",
    "–î–∞–Ω–∞ —Å–ª–µ–¥—É—é—â–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ —Å–ª–æ–≤–∞—Ä—å (–æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏—Ö –Ω–æ–º–µ—Ä–∞) –∏ –≤–µ–∫—Ç–æ—Ä –≤–µ—Å–æ–≤ (DF).\n",
    "\n",
    "$DF(w) = \\frac{DocCount(w, c)}{Size(c)}$\n",
    "\n",
    "  -- —á–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤–∞ $w$ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ $c$ (–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å–ª–æ–≤–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤).\n",
    "\n",
    "–ö–∞–∑–Ω–∏—Ç—å –Ω–µ–ª—å–∑—è, –ø–æ–º–∏–ª–æ–≤–∞—Ç—å. –ù–µ–ª—å–∑—è –Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å.\n",
    "\n",
    "–ö–∞–∑–Ω–∏—Ç—å, –Ω–µ–ª—å–∑—è –ø–æ–º–∏–ª–æ–≤–∞—Ç—å. –ù–µ–ª—å–∑—è –æ—Å–≤–æ–±–æ–¥–∏—Ç—å.\n",
    "\n",
    "–ù–µ–ª—å–∑—è –Ω–µ –ø–æ–º–∏–ª–æ–≤–∞—Ç—å.\n",
    "\n",
    "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å.\n",
    "\n",
    "–ü—Ä–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Å–µ–º–∏–Ω–∞—Ä–∞: [\\w\\d]+. –ü–æ—Å–ª–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –Ω—É–∂–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ —á–∞—Å—Ç–æ—Ç–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.\n",
    "\n",
    "–û—Ç–≤–µ—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏:\n",
    "\n",
    "–≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ - —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–ª–æ–≤–∞—Ä—è - —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –≤ –ø–æ—Ä—è–¥–∫–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏. –ü—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —á–∞—Å—Ç–æ—Ç–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É.\n",
    "–≤–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–µ - —Å–ø–∏—Å–æ–∫ –≤–µ—Å–æ–≤ (DF) —Ç–æ–∫–µ–Ω–æ–≤, –æ–∫—Ä—É–≥–ª—ë–Ω–Ω—ã—Ö –¥–æ 2 –∑–Ω–∞–∫–∞ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –∏ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–∞–º–∏, –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ —Ç–æ–∫–µ–Ω—ã –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c92555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ö–∞–∑–Ω–∏—Ç—å', '–Ω–µ–ª—å–∑—è', '–ø–æ–º–∏–ª–æ–≤–∞—Ç—å', '–ù–µ–ª—å–∑—è', '–Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å']\n",
      "[['–∫–∞–∑–Ω–∏—Ç—å', '–Ω–µ–ª—å–∑—è', '–ø–æ–º–∏–ª–æ–≤–∞—Ç—å', '–Ω–µ–ª—å–∑—è', '–Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å'], ['–∫–∞–∑–Ω–∏—Ç—å', '–Ω–µ–ª—å–∑—è', '–ø–æ–º–∏–ª–æ–≤–∞—Ç—å', '–Ω–µ–ª—å–∑—è', '–æ—Å–≤–æ–±–æ–¥–∏—Ç—å'], ['–Ω–µ–ª—å–∑—è', '–Ω–µ', '–ø–æ–º–∏–ª–æ–≤–∞—Ç—å'], ['–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ', '–æ—Å–≤–æ–±–æ–¥–∏—Ç—å']]\n",
      "Word counts:\n",
      " defaultdict(<class 'int'>, {'–Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å': 1, '–∫–∞–∑–Ω–∏—Ç—å': 2, '–Ω–µ–ª—å–∑—è': 3, '–ø–æ–º–∏–ª–æ–≤–∞—Ç—å': 3, '–æ—Å–≤–æ–±–æ–¥–∏—Ç—å': 2, '–Ω–µ': 1, '–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ': 1})\n",
      "–ß–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: 4\n",
      "[('–Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å', 1), ('–Ω–µ', 1), ('–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ', 1), ('–∫–∞–∑–Ω–∏—Ç—å', 2), ('–æ—Å–≤–æ–±–æ–¥–∏—Ç—å', 2), ('–Ω–µ–ª—å–∑—è', 3), ('–ø–æ–º–∏–ª–æ–≤–∞—Ç—å', 3)]\n",
      "[0.25, 0.25, 0.25, 0.5, 0.5, 0.75, 0.75]\n",
      "–Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∫–∞–∑–Ω–∏—Ç—å –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –Ω–µ–ª—å–∑—è –ø–æ–º–∏–ª–æ–≤–∞—Ç—å\n",
      "0.25 0.25 0.25 0.5 0.5 0.75 0.75\n",
      "{'–Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å': 0, '–Ω–µ': 1, '–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ': 2, '–∫–∞–∑–Ω–∏—Ç—å': 3, '–æ—Å–≤–æ–±–æ–¥–∏—Ç—å': 4, '–Ω–µ–ª—å–∑—è': 5, '–ø–æ–º–∏–ª–æ–≤–∞—Ç—å': 6}\n"
     ]
    }
   ],
   "source": [
    "# 2.4.5\n",
    "simple_regex = re.compile(r'[\\w\\d]+')\n",
    "texts = ['–ö–∞–∑–Ω–∏—Ç—å –Ω–µ–ª—å–∑—è, –ø–æ–º–∏–ª–æ–≤–∞—Ç—å. –ù–µ–ª—å–∑—è –Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å.',\n",
    "         '–ö–∞–∑–Ω–∏—Ç—å, –Ω–µ–ª—å–∑—è –ø–æ–º–∏–ª–æ–≤–∞—Ç—å. –ù–µ–ª—å–∑—è –æ—Å–≤–æ–±–æ–¥–∏—Ç—å.',\n",
    "         '–ù–µ–ª—å–∑—è –Ω–µ –ø–æ–º–∏–ª–æ–≤–∞—Ç—å.', \n",
    "         '–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å.']\n",
    "\n",
    "print(simple_regex.findall(texts[0]))\n",
    "\n",
    "def tokenize_text(text, regex=simple_regex, min_len=0):\n",
    "    text = text.lower()\n",
    "    all_tokens = regex.findall(text)\n",
    "    return [token for token in all_tokens if len(token) > min_len]\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text, **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(texts)\n",
    "print(tokenized_corpus)\n",
    "\n",
    "word_counts = defaultdict(int)\n",
    "doc_n = 0\n",
    "\n",
    "for text in tokenized_corpus:\n",
    "    doc_n += 1\n",
    "    unique_tokens = set(text)\n",
    "    for token in unique_tokens:\n",
    "        word_counts[token] += 1\n",
    "        \n",
    "print(\"Word counts:\\n\", word_counts)\n",
    "print(\"–ß–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\", doc_n)\n",
    "\n",
    "sorted_words = sorted(word_counts.items(), reverse=False, key=lambda pair: (pair[1], pair[0]))\n",
    "print(sorted_words)\n",
    "\n",
    "document_freq = [cnt / doc_n for _, cnt in sorted_words]\n",
    "\n",
    "print(document_freq)\n",
    "\n",
    "print(f'{\" \".join([word for word, _ in sorted_words])}\\n{\" \".join(map(str, document_freq))}')\n",
    "\n",
    "word2id = {token: i for i, (token, _) in enumerate(sorted_words)}\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a125ff7",
   "metadata": {},
   "source": [
    "## 2.4.7\n",
    "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ —Å —à–∞–≥–∞ 5 —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ª–æ–≤–∞—Ä—è –∏ –≤–µ–∫—Ç–æ—Ä–∞ –≤–µ—Å–æ–≤, –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –Ω–∞ —à–∞–≥–µ 5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ $lTFIDF = \\ln(TF + 1) \\cdot IDF$\n",
    "\n",
    "–ó–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–ª–µ–¥—É–µ—Ç –æ—Ç–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–∫, —á—Ç–æ–±—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –µ–≥–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤—ã–±–æ—Ä–∫–µ —Ä–∞–≤–Ω—è–ª–æ—Å—å 0, –∞ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ 1: $x^{scaled}_{i} = \\frac{x_{i} - E(x)} {\\sigma(x)}x$\n",
    "\n",
    "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å—Ä–µ–¥–Ω–µ–µ –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 0, –∞ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ 1.\n",
    "\n",
    "–ü—Ä–∏ —Ä–∞—Å—á—ë—Ç–µ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É $\\sigma=\\sqrt{\\frac{\\sum_{i-1}^n(x_i - E(x))^2}{n - 1}}$\n",
    "–ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ç–∞–∫—É—é –æ—Ü–µ–Ω–∫—É —Å –ø–æ–º–æ—â—å—é numpy, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–¥–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä ddof=1: \n",
    "\n",
    "    feature_matrix = np.zeros((num_docs, num_feats))\n",
    "    feats_std = feature_matrix.std(0, ddof=1)\n",
    "    \n",
    "–û—Ç–≤–µ—Ç –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π—Ç–µ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ –±—ã–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø–æ—Ä—è–¥–∫—É —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ (–∫–∞–∫ –≤ –æ—Ç–≤–µ—Ç–µ –Ω–∞ —à–∞–≥–µ 5, –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é df). –°—Ç–æ–ª–±—Ü—ã —Ä–∞–∑–¥–µ–ª—è–π—Ç–µ –æ–¥–Ω–∏–º –ø—Ä–æ–±–µ–ª–æ–º. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è —Ü–µ–ª–æ–π –∏ –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É –∏–ª–∏ –∑–∞–ø—è—Ç—É—é. –û–∫—Ä—É–≥–ª—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ. –†–µ—à–µ–Ω–∏–µ, –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–∫—Ä—É–≥–ª–∏—Ç—Å—è –¥–æ –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤. –ú–µ—Ç–æ–¥ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è - –ª–∏–±–æ \"–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π\", –ª–∏–±–æ —Å–≤–æ–π—Å—Ç–≤–µ–Ω–Ω—ã–π Python rounding half to even strategy, –µ—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ, –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ IEEE 754.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–µ—Ä–≤—ã—Ö –¥–≤—É—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–¥–æ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –µ—â—ë –¥–≤—É—Ö —Å—Ç—Ä–æ–∫):\n",
    "\n",
    "    1.5  -0.5 -0.5 0.87 -0.76 0.60 0.16\n",
    "    -0.5 -0.5 -0.5 0.87 0.18  0.60 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf83f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "–í—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç—å —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ:\n",
      " [[1. 0. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 0. 1. 1. 2. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0.]]\n",
      "–ë–∏–Ω–∞—Ä–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç:\n",
      " [[1 0 0 1 0 1 1]\n",
      " [0 0 0 1 1 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [0 0 1 0 1 0 0]]\n",
      "TF –≤–∞—Ä–∏–∞–Ω—Ç:\n",
      " [[0.2        0.         0.         0.2        0.         0.4\n",
      "  0.2       ]\n",
      " [0.         0.         0.         0.2        0.2        0.4\n",
      "  0.2       ]\n",
      " [0.         0.33333334 0.         0.         0.         0.33333334\n",
      "  0.33333334]\n",
      " [0.         0.         0.5        0.         0.5        0.\n",
      "  0.        ]]\n",
      "TF-IDF –≤–∞—Ä–∏–∞–Ω—Ç:\n",
      " [[0.80000001 0.         0.         0.40000001 0.         0.53333334\n",
      "  0.26666667]\n",
      " [0.         0.         0.         0.40000001 0.40000001 0.53333334\n",
      "  0.26666667]\n",
      " [0.         1.33333337 0.         0.         0.         0.44444446\n",
      "  0.44444446]\n",
      " [0.         0.         2.         0.         1.         0.\n",
      "  0.        ]]\n",
      "LTF-IDF –≤–∞—Ä–∏–∞–Ω—Ç:\n",
      " [[0.72928643 0.         0.         0.36464322 0.         0.44862966\n",
      "  0.24309548]\n",
      " [0.         0.         0.         0.36464322 0.36464322 0.44862966\n",
      "  0.24309548]\n",
      " [0.         1.15072846 0.         0.         0.         0.38357615\n",
      "  0.38357615]\n",
      " [0.         0.         1.62186038 0.         0.81093019 0.\n",
      "  0.        ]]\n",
      "LTF-IDF –≤–∞—Ä–∏–∞–Ω—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π:\n",
      " [[ 1.5        -0.5        -0.5         0.8660254  -0.76301262  0.59546687\n",
      "   0.16096797]\n",
      " [-0.5        -0.5        -0.5         0.8660254   0.18368241  0.59546687\n",
      "   0.16096797]\n",
      " [-0.5         1.5        -0.5        -0.8660254  -0.76301262  0.29382408\n",
      "   1.04243496]\n",
      " [-0.5        -0.5         1.5        -0.8660254   1.34234283 -1.48475783\n",
      "  -1.36437091]]\n"
     ]
    }
   ],
   "source": [
    "# 2.4.7\n",
    "\n",
    "vectorized_texts = np.zeros(shape=(len(tokenized_corpus), len(word2id)), dtype='float32')\n",
    "print(vectorized_texts)\n",
    "\n",
    "for text_i, text in enumerate(tokenized_corpus):\n",
    "    for token in text:\n",
    "        if token in word2id:\n",
    "            vectorized_texts[text_i, word2id[token]] += 1\n",
    "            \n",
    "print(\"–í—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç—å —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ:\\n\", vectorized_texts)\n",
    "\n",
    "print(\"–ë–∏–Ω–∞—Ä–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç:\\n\", (vectorized_texts > 0).astype(int))\n",
    "\n",
    "tf_vectorized = vectorized_texts / vectorized_texts.sum(axis=1, keepdims=True)\n",
    "print(\"TF –≤–∞—Ä–∏–∞–Ω—Ç:\\n\", tf_vectorized)\n",
    "\n",
    "tfidf_vectorized = tf_vectorized / document_freq\n",
    "print(\"TF-IDF –≤–∞—Ä–∏–∞–Ω—Ç:\\n\", tfidf_vectorized)\n",
    "\n",
    "ltfidf_vectorized = np.log(tf_vectorized + 1) / document_freq\n",
    "print(\"LTF-IDF –≤–∞—Ä–∏–∞–Ω—Ç:\\n\", ltfidf_vectorized)\n",
    "\n",
    "ltfidf_vectorized_scaled = (ltfidf_vectorized - ltfidf_vectorized.mean(axis=0)) / ltfidf_vectorized.std(axis=0, ddof=1)\n",
    "print(\"LTF-IDF –≤–∞—Ä–∏–∞–Ω—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π:\\n\", ltfidf_vectorized_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89e1d1",
   "metadata": {},
   "source": [
    "## 3.4.1\n",
    "–í—ã –æ–±—É—á–∞–µ—Ç–µ Word2Vec Skip Gram Negative Sampling —Å –æ–∫–Ω–æ–º –∑–∞–¥–∞–Ω–Ω–æ–π —à–∏—Ä–∏–Ω—ã. –ù–∞–ø—Ä–∏–º–µ—Ä, –æ–∫–Ω–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 5 –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç, —á—Ç–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è —Å–ª–æ–≤–∞, –æ—Ç—Å—Ç–æ—è—â–∏–µ –æ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –Ω–µ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 2 –ø–æ–∑–∏—Ü–∏–∏ –≤–ª–µ–≤–æ –∏–ª–∏ –≤–ø—Ä–∞–≤–æ. –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ —Å–ª–æ–≤–æ.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ö–∞–∂–¥—ã–π –æ–±—É—á–∞—é—â–∏–π –ø—Ä–∏–º–µ—Ä –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–∏–¥ –∫–æ—Ä—Ç–µ–∂–∞ –∏–∑ —Ç—Ä—ë—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ $(CenterWord, CtxWord, Label)$, –≥–¥–µ $CenterWord \\in \\mathbb{N}$ - –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–∫–µ–Ω–∞ –≤ —Ü–µ–Ω—Ç—Ä–µ –æ–∫–Ω–∞, $CtxWord \\in \\mathbb{N}$ - –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–æ—Å–µ–¥–Ω–µ–≥–æ —Ç–æ–∫–µ–Ω–∞, $Label \\in \\{0, 1\\}$ - 1 –µ—Å–ª–∏ $CtxWord$ –Ω–∞—Å—Ç–æ—è—â–∏–π –∏ 0, –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤.\n",
    "\n",
    "–ê—Ä–≥—É–º–µ–Ω—Ç ns_rate –∑–∞–¥–∞—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –∫–∞–∂–¥—ã–π –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä. –ü—Ä–∏ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –æ–±—ã—á–Ω–æ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è—é—Ç, –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Å–ª–æ–≤–æ –≤ –æ–∫–Ω–µ. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Å—Ä–µ–¥–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –º–æ–≥—É—Ç –ø–æ—è–≤–∏—Ç—å—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ.\n",
    "\n",
    "–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç —É–∂–µ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω, —Ç–æ–∫–µ–Ω—ã –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã.\n",
    "\n",
    "–¢–µ—Å—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
    "\n",
    "- len(text) < 20\n",
    "- window_size <= 11, –Ω–µ—á—ë—Ç–Ω–æ–µ\n",
    "- vocab_size < 100\n",
    "- ns_rate < 3\n",
    "–°–ª–æ–≤–∞ –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã 0..vocab_size - 1 (–∫–∞–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç np.random.randint).\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ —Ç–∞–∫–∂–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ -3 // 2 != -(3 // 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1f7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1],\n",
       " [1, 5, 0],\n",
       " [0, 1, 1],\n",
       " [0, 1, 1],\n",
       " [0, 3, 0],\n",
       " [0, 2, 0],\n",
       " [1, 0, 1],\n",
       " [1, 0, 1],\n",
       " [1, 4, 0],\n",
       " [1, 2, 0],\n",
       " [0, 1, 1],\n",
       " [0, 0, 1],\n",
       " [0, 4, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 5, 1],\n",
       " [0, 3, 0],\n",
       " [0, 0, 0],\n",
       " [5, 0, 1],\n",
       " [5, 0, 1],\n",
       " [5, 3, 0],\n",
       " [5, 1, 0],\n",
       " [0, 5, 1],\n",
       " [0, 3, 1],\n",
       " [0, 5, 0],\n",
       " [0, 2, 0],\n",
       " [3, 0, 1],\n",
       " [3, 5, 1],\n",
       " [3, 2, 0],\n",
       " [3, 3, 0],\n",
       " [5, 3, 1],\n",
       " [5, 5, 1],\n",
       " [5, 5, 0],\n",
       " [5, 5, 0],\n",
       " [5, 5, 1],\n",
       " [5, 3, 1],\n",
       " [5, 1, 0],\n",
       " [5, 3, 0],\n",
       " [3, 5, 1],\n",
       " [3, 0, 1],\n",
       " [3, 0, 0],\n",
       " [3, 1, 0],\n",
       " [0, 3, 1],\n",
       " [0, 5, 1],\n",
       " [0, 2, 0],\n",
       " [0, 1, 0],\n",
       " [5, 0, 1],\n",
       " [5, 0, 1],\n",
       " [5, 3, 0],\n",
       " [5, 4, 0],\n",
       " [0, 5, 1],\n",
       " [0, 5, 1],\n",
       " [0, 1, 0],\n",
       " [0, 0, 0],\n",
       " [5, 0, 1],\n",
       " [5, 2, 1],\n",
       " [5, 5, 0],\n",
       " [5, 5, 0],\n",
       " [2, 5, 1],\n",
       " [2, 0, 1],\n",
       " [2, 5, 0],\n",
       " [2, 4, 0],\n",
       " [0, 2, 1],\n",
       " [0, 1, 1],\n",
       " [0, 0, 0],\n",
       " [0, 2, 0],\n",
       " [1, 0, 1],\n",
       " [1, 3, 1],\n",
       " [1, 2, 0],\n",
       " [1, 0, 0],\n",
       " [3, 1, 1],\n",
       " [3, 5, 0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4.1\n",
    "\n",
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "sample_input = (\n",
    "    [1, 0, 1, 0, 0, 5, 0, 3, 5, 5, 3, 0, 5, 0, 5, 2, 0, 1, 3],\n",
    "    3,\n",
    "    6,\n",
    "    1\n",
    ")\n",
    "\n",
    "sample_output = [\n",
    "    [1, 0, 1],\n",
    "    [1, 2, 0],\n",
    "    [0, 1, 1], \n",
    "    [0, 1, 0], \n",
    "    [0, 1, 1], \n",
    "    [0, 2, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 3, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 2, 0], \n",
    "    [0, 1, 1], \n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 3, 0], \n",
    "    [0, 0, 1],\n",
    "    [0, 2, 0],\n",
    "    [0, 5, 1],\n",
    "    [0, 2, 0], \n",
    "    [5, 0, 1], \n",
    "    [5, 2, 0], \n",
    "    [5, 0, 1],\n",
    "    [5, 0, 0], \n",
    "    [0, 5, 1], \n",
    "    [0, 4, 0],\n",
    "    [0, 3, 1], \n",
    "    [0, 1, 0],\n",
    "    [3, 0, 1],\n",
    "    [3, 0, 0], \n",
    "    [3, 5, 1], \n",
    "    [3, 2, 0], \n",
    "    [5, 3, 1], \n",
    "    [5, 1, 0], \n",
    "    [5, 5, 1], \n",
    "    [5, 4, 0], \n",
    "    [5, 5, 1], \n",
    "    [5, 2, 0], \n",
    "    [5, 3, 1], \n",
    "    [5, 0, 0], \n",
    "    [3, 5, 1], \n",
    "    [3, 0, 0], \n",
    "    [3, 0, 1], \n",
    "    [3, 5, 0], \n",
    "    [0, 3, 1], \n",
    "    [0, 2, 0], \n",
    "    [0, 5, 1], \n",
    "    [0, 1, 0], \n",
    "    [5, 0, 1],\n",
    "    [5, 2, 0], \n",
    "    [5, 0, 1],\n",
    "    [5, 2, 0],\n",
    "    [0, 5, 1],\n",
    "    [0, 3, 0],\n",
    "    [0, 5, 1],\n",
    "    [0, 1, 0],\n",
    "    [5, 0, 1],\n",
    "    [5, 1, 0], \n",
    "    [5, 2, 1], \n",
    "    [5, 2, 0], \n",
    "    [2, 5, 1],\n",
    "    [2, 3, 0],\n",
    "    [2, 0, 1], \n",
    "    [2, 5, 0],\n",
    "    [0, 2, 1], \n",
    "    [0, 2, 0],\n",
    "    [0, 1, 1],\n",
    "    [0, 3, 0], \n",
    "    [1, 0, 1],\n",
    "    [1, 2, 0],\n",
    "    [1, 3, 1],\n",
    "    [1, 0, 0],\n",
    "    [3, 1, 1],\n",
    "    [3, 4, 0]\n",
    "]\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "def make_diag_mask(size, radius):\n",
    "    \"\"\"–ö–≤–∞–¥—Ä–∞—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ Size x Size —Å –¥–≤—É–º—è –ø–æ–ª–æ—Å–∞–º–∏ —à–∏—Ä–∏–Ω—ã radius –≤–¥–æ–ª—å –≥–ª–∞–≤–Ω–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª–∏\"\"\"\n",
    "    idxs = np.arange(size)\n",
    "    abs_idx_diff = np.abs(np.arange(size)[np.newaxis, :] - np.arange(size)[:, np.newaxis])\n",
    "    mask = ((abs_idx_diff <= radius // 2) & (abs_idx_diff > 0)).astype(int)\n",
    "    return mask\n",
    "\n",
    "def generate_w2v_sgns_samples(text, window_size, vocab_size, ns_rate):\n",
    "    \"\"\"\n",
    "    text - list of integer numbers - ids of tokens in text\n",
    "    window_size - odd integer - width of window\n",
    "    vocab_size - positive integer - number of tokens in vocabulary\n",
    "    ns_rate - positive integer - number of negative tokens to sample per one positive sample\n",
    "\n",
    "    returns list of training samples (CenterWord, CtxWord, Label)\n",
    "    \"\"\"\n",
    "    text = np.array(text)\n",
    "    size = len(text)\n",
    "    context_words_idxs = make_diag_mask(size, window_size)\n",
    "    center_words_idx = np.eye(N=size, dtype=int)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(size):\n",
    "        context = context_words_idxs[i]\n",
    "        center = center_words_idx[i]\n",
    "\n",
    "        context_idx = np.where(context != 0)[0]\n",
    "        center_idx = np.where(center != 0)[0]\n",
    "\n",
    "        center_word = text[center_idx]\n",
    "        context_words = text[context_idx]\n",
    "\n",
    "        positive_examples = [list(i) + [1] for i in product(center_word, context_words)]    \n",
    "\n",
    "        # —á—Ç–æ–±—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞–ª–æ —Å —Å–∞–º–∏–º —Å–æ–±–æ–π\n",
    "#         all_words = np.arange(vocab_size)\n",
    "#         center_word_idx = np.argwhere(all_words == center_word)[0][0]\n",
    "#         all_words = list(all_words)\n",
    "#         del all_words[center_word_idx]\n",
    "#         all_words = np.array(all_words)\n",
    "#         negative_word = np.random.choice(all_words)\n",
    "\n",
    "        # –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω–æ –∏–∑ –¥–≤—É—Ö, –ª–∏–±–æ —É–±—Ä–∞—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Å–∞–º–∏–º —Å–æ–±–æ–π, –ª–∏–±–æ –Ω–µ—Ç\n",
    "        negative_words = np.random.randint(vocab_size, size=ns_rate*len(positive_examples))    \n",
    "        negative_examples = [list(i) + [0] for i in product(center_word, negative_words)]\n",
    "\n",
    "        positive_negative_examples = positive_examples + negative_examples    \n",
    "        result.extend(positive_negative_examples)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = generate_w2v_sgns_samples(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a2771",
   "metadata": {},
   "source": [
    "## 3.4.2\n",
    "\n",
    "–í—ã –æ–±—É—á–∞–µ—Ç–µ Word2Vec Skip Gram Negative Sampling.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –æ–±–Ω–æ–≤–ª—è—é—â—É—é –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–¥–Ω–æ–≥–æ –æ–±—É—á–∞—é—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ $(CenterWord, CtxWord, Label)$.\n",
    "\n",
    "–ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ $P(CtxWord | CenterWord) = \\sigma(W_{CenterWord, :} \\cdot D_{CtxWord,:})$.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å - –±–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è.\n",
    "\n",
    "–¢–µ—Å—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db9722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22745148261727433, -0.24928768665874734)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9836099232994968 - 0.7561584406822225, 0.3847689688960674 - 0.6340566555548147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3b2761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2534980216305478"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.882545488649187 - 0.6290474670186392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b82d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.3970783178926671\n",
      "Center word grad: [0.66427567 0.46839947 0.122916  ]\n",
      "Context word grad: [0.740345   0.28960849 0.02507351]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sample_input = (\n",
    "    [\n",
    "        [0.3449417709491044, 0.6762047256081501, 0.9583446027893963],\n",
    "        [0.6247126159157468, 0.22038323197740317, 0.29717611444948355],\n",
    "        [0.9836099232994968, 0.3847689688960674, 0.033312247867206435],\n",
    "        [0.4217704869846559, 0.0023859008971685025, 0.009686915033163657],\n",
    "        [0.6933070658521228, 0.9705089533296152, 0.9189360293193337],\n",
    "        [0.024858486425111903, 0.11331113152689753, 0.6492144300167894],\n",
    "        [0.7861289466352543, 0.227319130535791, 0.8165251907260063],\n",
    "        [0.7672181161105678, 0.04865001026002924, 0.07514404284170773]\n",
    "    ],\n",
    "    [\n",
    "        [0.4628817426583818, 0.7747296319956671, 0.1374808935513827],\n",
    "        [0.17026823169513283, 0.4094733988461122, 0.3175531656197459],\n",
    "        [0.2910876746161247, 0.6340566555548147, 0.23158010794029804],\n",
    "        [0.8449042648180852, 0.4796593509107806, 0.11278090182290745],\n",
    "        [0.049097778744511156, 0.6254116250148337, 0.13038703647472905],\n",
    "        [0.882545488649187, 0.6223076699449618, 0.1633041302523962],\n",
    "        [0.6704032810194875, 0.941803340812521, 0.7358646489592193],\n",
    "        [0.9875878745059805, 0.17935677165390562, 0.6798846454394736]\n",
    "    ],\n",
    "    2,\n",
    "    5,\n",
    "    0,\n",
    "    0.342405260598321\n",
    ")\n",
    "\n",
    "sample_output = [\n",
    "    [\n",
    "        [0.3449417709491044, 0.6762047256081501, 0.9583446027893963],\n",
    "        [0.6247126159157468, 0.22038323197740317, 0.29717611444948355],\n",
    "        [0.7561584406822225, 0.22438652516534294, -0.008774836618697823],\n",
    "        [0.4217704869846559, 0.0023859008971685025, 0.009686915033163657],\n",
    "        [0.6933070658521228, 0.9705089533296152, 0.9189360293193337],\n",
    "        [0.024858486425111903, 0.11331113152689753, 0.6492144300167894],\n",
    "        [0.7861289466352543, 0.227319130535791, 0.8165251907260063],\n",
    "        [0.7672181161105678, 0.04865001026002924, 0.07514404284170773]\n",
    "    ],\n",
    "    [\n",
    "        [0.4628817426583818, 0.7747296319956671, 0.1374808935513827],\n",
    "        [0.17026823169513283, 0.4094733988461122, 0.3175531656197459],\n",
    "        [0.2910876746161247, 0.6340566555548147, 0.23158010794029804],\n",
    "        [0.8449042648180852, 0.4796593509107806, 0.11278090182290745],\n",
    "        [0.049097778744511156, 0.6254116250148337, 0.13038703647472905],\n",
    "        [0.6290474670186392, 0.5231442006778062, 0.15471882755224034],\n",
    "        [0.6704032810194875, 0.941803340812521, 0.7358646489592193],\n",
    "        [0.9875878745059805, 0.17935677165390562, 0.6798846454394736]\n",
    "    ]\n",
    "]\n",
    "\n",
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "    \n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s * (1 - s)\n",
    "\n",
    "def log_loss(y_true, a_pred):\n",
    "    '''\n",
    "    Compute log loss, a_pred - vector of size n_objects\n",
    "    '''\n",
    "    return np.mean(-y_true * np.log(a_pred) - (1 - y_true) * np.log(1 - a_pred))\n",
    "\n",
    "def log_loss_derivative(y_true, a_pred):\n",
    "    '''\n",
    "    Compute detivative of log loss\n",
    "    '''\n",
    "    return (-y_true / a_pred + (1 - y_true) / (1 - a_pred)) / len(y_true)\n",
    "\n",
    "def update_w2v_weights(center_embeddings, context_embeddings, center_word, context_word, label, learning_rate):\n",
    "    \"\"\"\n",
    "    center_embeddings - VocabSize x EmbSize\n",
    "    context_embeddings - VocabSize x EmbSize\n",
    "    center_word - int - identifier of center word\n",
    "    context_word - int - identifier of context word\n",
    "    label - 1 if context_word is real, 0 if it is negative\n",
    "    learning_rate - float > 0 - size of gradient step\n",
    "    \"\"\"\n",
    "    # –ü–µ—Ä–µ–≤–µ–¥–µ–º –≤ numpy –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "    center_embeddings = np.asarray(center_embeddings)\n",
    "    context_embeddings = np.asarray(context_embeddings)\n",
    "    \n",
    "    # –í—ã–±–µ—Ä–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ —Å–ª–æ–≤–æ\n",
    "    center_embedding = center_embeddings[center_word]\n",
    "    context_embedding = context_embeddings[context_word]\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º \"–æ—Ü–µ–Ω–∫—É\" —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ –µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ —Ñ–æ—Ä–º—É–ª–µ ùëÉ(ùê∂ùë°ùë•ùëäùëúùëüùëë|ùê∂ùëíùëõùë°ùëíùëüùëäùëúùëüùëë)=ùúé(ùëäùê∂ùëíùëõùë°ùëíùëüùëäùëúùëüùëë,:‚ãÖùê∑ùê∂ùë°ùë•ùëäùëúùëüùëë,:)\n",
    "    score = center_embedding.dot(context_embedding)\n",
    "    prob = sigmoid(score)\n",
    "    print(f'LOSS: {log_loss(label, prob)}')\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª–∞ —Ü–µ–ø–æ—á–∫–∏: –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ª–æ—Å—Å–∞ * –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é —Å–∏–≥–º–æ–∏–¥—ã\n",
    "    # * –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é ùëäùê∂ùëíùëõùë°ùëíùëüùëäùëúùëüùëë,:‚ãÖùê∑ùê∂ùë°ùë•ùëäùëúùëüùëë,: –ø–æ ùëäùê∂ùëíùëõùë°ùëíùëüùëäùëúùëüùëë –∏ ùê∑ùê∂ùë°ùë•ùëäùëúùëüùëë\n",
    "    log_loss_deriv = log_loss_derivative(np.array([label]), np.array([prob]))\n",
    "    sigmoid_deriv = sigmoid_derivative(score)\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø–æ —Ü–µ—Ç—Ä–∞–ª—å–Ω–æ–º—É —Å–ª–æ–≤—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤\n",
    "    center_grad = log_loss_deriv * sigmoid_deriv * context_embedding\n",
    "    context_grad = log_loss_deriv * sigmoid_deriv * center_embedding\n",
    "    print(f'Center word grad: {center_grad}')\n",
    "    print(f'Context word grad: {context_grad}')\n",
    "    \n",
    "    center_embeddings[center_word] -= learning_rate * center_grad\n",
    "    context_embeddings[context_word] -= learning_rate * context_grad\n",
    "    \n",
    "    return center_embeddings, context_embeddings\n",
    "\n",
    "result = update_w2v_weights(*sample_input)\n",
    "\n",
    "print(np.allclose(result[0], np.array(sample_output[0])))\n",
    "print(np.allclose(result[1], np.array(sample_output[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747b667",
   "metadata": {},
   "source": [
    "## 3.4.3\n",
    "–í—ã –æ–±—É—á–∞–µ—Ç–µ FastText SkipGram Negative Sampling —Å –æ–∫–Ω–æ–º –∑–∞–¥–∞–Ω–Ω–æ–π —à–∏—Ä–∏–Ω—ã (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ [–ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–µ](https://stepik.org/lesson/261476/step/2?unit=242225) 3.4.1). –û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Ç–∞–∫–∂–µ –æ–ø–∏—Å—ã–≤–∞–ª—Å—è [—Ä–∞–Ω–µ–µ](https://stepik.org/lesson/225313/step/11?unit=198056). –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç Word2Vec - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ N-–≥—Ä–∞–º–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ö–∞–∂–¥—ã–π –æ–±—É—á–∞—é—â–∏–π –ø—Ä–∏–º–µ—Ä –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–∏–¥ –∫–æ—Ä—Ç–µ–∂–∞ –∏–∑ —Ç—Ä—ë—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ $(CenterSubwords, CtxWord, Label)$, –≥–¥–µ CenterSubwordsCenterSubwords - —Å–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ N-–≥—Ä–∞–º–º, –≤—Ö–æ–¥—è—â–∏—Ö –≤ —Ç–æ–∫–µ–Ω –≤ —Ü–µ–Ω—Ç—Ä–µ –æ–∫–Ω–∞ (–≤–∫–ª—é—á–∞—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–∞–º–æ–≥–æ —Ç–æ–∫–µ–Ω–∞), $CtxWord \\in \\mathbb{N}$ - –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–æ—Å–µ–¥–Ω–µ–≥–æ —Ç–æ–∫–µ–Ω–∞, $Label \\in \\{0, 1\\}$ - 1 –µ—Å–ª–∏ CtxWordCtxWord –Ω–∞—Å—Ç–æ—è—â–∏–π –∏ 0, –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤.\n",
    "\n",
    "–ê—Ä–≥—É–º–µ–Ω—Ç ns_rate –∑–∞–¥–∞—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –∫–∞–∂–¥—ã–π –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä.\n",
    "\n",
    "–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç —É–∂–µ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω, —Ç–æ–∫–µ–Ω—ã –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã.\n",
    "\n",
    "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ N-–≥—Ä–∞–º–º, –≤—Ö–æ–¥—è—â–∏—Ö –≤ —Ç–æ–∫–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å (–æ–Ω –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä—É—é –í–∞–º –Ω—É–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å). –í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ —Å–ª–µ–¥—É–µ—Ç —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ —Å–∞–º —Ç–æ–∫–µ–Ω –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ –∏ –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –≤–µ–∫—Ç–æ—Ä –¥–ª—è –Ω–µ–≥–æ (—Ö–æ—Ç—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ FastText –Ω–∞ –Ω–∞—Å—Ç–æ—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Ç–∞–∫). –í—Å–µ n-–≥—Ä–∞–º–º—ã –∏–º–µ—é—Ç –Ω–æ–º–µ—Ä–∞ –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω—ã–µ vocab_size.\n",
    "\n",
    "–¢–µ—Å—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
    "\n",
    "- len(text) < 20\n",
    "- vocab_size < 10\n",
    "- window_size <= 11, –Ω–µ—á—ë—Ç–Ω–æ–µ\n",
    "- ns_rate < 3\n",
    "- ngrams_n < 20\n",
    "–°–ª–æ–≤–∞ –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã 0..vocab_size - 1 (–∫–∞–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç np.random.randint). N-–≥—Ä–∞–º–º—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã vocab_size .. vocab_size + ngrams_n - 1.\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ —Ç–∞–∫–∂–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ -3 // 2 != -(3 // 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472d3462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 10, 12], 2, 1),\n",
       " ([1, 10, 12], 4, 0),\n",
       " ([1, 10, 12], 5, 0),\n",
       " ([2, 20, 20], 1, 1),\n",
       " ([2, 20, 20], 0, 1),\n",
       " ([2, 20, 20], 4, 0),\n",
       " ([2, 20, 20], 4, 0),\n",
       " ([2, 20, 20], 0, 0),\n",
       " ([2, 20, 20], 4, 0),\n",
       " ([0, 17], 2, 1),\n",
       " ([0, 17], 1, 1),\n",
       " ([0, 17], 1, 0),\n",
       " ([0, 17], 5, 0),\n",
       " ([0, 17], 0, 0),\n",
       " ([0, 17], 1, 0),\n",
       " ([1, 10, 12], 0, 1),\n",
       " ([1, 10, 12], 4, 1),\n",
       " ([1, 10, 12], 2, 0),\n",
       " ([1, 10, 12], 0, 0),\n",
       " ([1, 10, 12], 3, 0),\n",
       " ([1, 10, 12], 2, 0),\n",
       " ([4], 1, 1),\n",
       " ([4], 0, 1),\n",
       " ([4], 3, 0),\n",
       " ([4], 1, 0),\n",
       " ([4], 1, 0),\n",
       " ([4], 2, 0),\n",
       " ([0, 17], 4, 1),\n",
       " ([0, 17], 4, 1),\n",
       " ([0, 17], 0, 0),\n",
       " ([0, 17], 3, 0),\n",
       " ([0, 17], 0, 0),\n",
       " ([0, 17], 3, 0),\n",
       " ([4], 0, 1),\n",
       " ([4], 1, 1),\n",
       " ([4], 1, 0),\n",
       " ([4], 2, 0),\n",
       " ([4], 0, 0),\n",
       " ([4], 5, 0),\n",
       " ([1, 10, 12], 4, 1),\n",
       " ([1, 10, 12], 5, 1),\n",
       " ([1, 10, 12], 1, 0),\n",
       " ([1, 10, 12], 5, 0),\n",
       " ([1, 10, 12], 3, 0),\n",
       " ([1, 10, 12], 1, 0),\n",
       " ([5, 7, 11], 1, 1),\n",
       " ([5, 7, 11], 4, 1),\n",
       " ([5, 7, 11], 1, 0),\n",
       " ([5, 7, 11], 2, 0),\n",
       " ([5, 7, 11], 3, 0),\n",
       " ([5, 7, 11], 2, 0),\n",
       " ([4], 5, 1),\n",
       " ([4], 5, 1),\n",
       " ([4], 2, 0),\n",
       " ([4], 4, 0),\n",
       " ([4], 2, 0),\n",
       " ([4], 0, 0),\n",
       " ([5, 7, 11], 4, 1),\n",
       " ([5, 7, 11], 4, 1),\n",
       " ([5, 7, 11], 1, 0),\n",
       " ([5, 7, 11], 3, 0),\n",
       " ([5, 7, 11], 4, 0),\n",
       " ([5, 7, 11], 0, 0),\n",
       " ([4], 5, 1),\n",
       " ([4], 5, 1),\n",
       " ([4], 1, 0),\n",
       " ([4], 4, 0),\n",
       " ([4], 1, 0),\n",
       " ([4], 4, 0),\n",
       " ([5, 7, 11], 4, 1),\n",
       " ([5, 7, 11], 1, 1),\n",
       " ([5, 7, 11], 5, 0),\n",
       " ([5, 7, 11], 2, 0),\n",
       " ([5, 7, 11], 1, 0),\n",
       " ([5, 7, 11], 3, 0),\n",
       " ([1, 10, 12], 5, 1),\n",
       " ([1, 10, 12], 0, 0),\n",
       " ([1, 10, 12], 3, 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [1, 2, 0, 1, 4, 0, 4, 1, 5, 4, 5, 4, 5, 1],\n",
    "    3,\n",
    "    6,\n",
    "    2,\n",
    "    [[17], [10, 12], [20, 20], [7, 13], [], [7, 11]]\n",
    ")\n",
    "sample_output = [\n",
    "    ([1, 10, 12], 2, 1),\n",
    "    ([1, 10, 12], 5, 0),\n",
    "    ([1, 10, 12], 2, 0),\n",
    "    ([2, 20], 1, 1),\n",
    "    ([2, 20], 0, 0),\n",
    "    ([2, 20], 5, 0),\n",
    "    ([2, 20], 0, 1),\n",
    "    ([2, 20], 1, 0),\n",
    "    ([2, 20], 0, 0),\n",
    "    ([0, 17], 2, 1),\n",
    "    ([0, 17], 1, 0),\n",
    "    ([0, 17], 3, 0),\n",
    "    ([0, 17], 1, 1),\n",
    "    ([0, 17], 1, 0),\n",
    "    ([0, 17], 3, 0),\n",
    "    ([1, 10, 12], 0, 1),\n",
    "    ([1, 10, 12], 4, 0),\n",
    "    ([1, 10, 12], 3, 0),\n",
    "    ([1, 10, 12], 4, 1),\n",
    "    ([1, 10, 12], 5, 0),\n",
    "    ([1, 10, 12], 3, 0),\n",
    "    ([4], 1, 1),\n",
    "    ([4], 5, 0),\n",
    "    ([4], 3, 0),\n",
    "    ([4], 0, 1), \n",
    "    ([4], 5, 0), \n",
    "    ([4], 1, 0), \n",
    "    ([0, 17], 4, 1),\n",
    "    ([0, 17], 2, 0),\n",
    "    ([0, 17], 4, 0), \n",
    "    ([0, 17], 4, 1),\n",
    "    ([0, 17], 1, 0), \n",
    "    ([0, 17], 3, 0), \n",
    "    ([4], 0, 1),\n",
    "    ([4], 5, 0), \n",
    "    ([4], 0, 0), \n",
    "    ([4], 1, 1), \n",
    "    ([4], 5, 0),\n",
    "    ([4], 5, 0),\n",
    "    ([1, 10, 12], 4, 1),\n",
    "    ([1, 10, 12], 0, 0),\n",
    "    ([1, 10, 12], 3, 0),\n",
    "    ([1, 10, 12], 5, 1),\n",
    "    ([1, 10, 12], 4, 0),\n",
    "    ([1, 10, 12], 3, 0),\n",
    "    ([11, 5, 7], 1, 1), \n",
    "    ([11, 5, 7], 3, 0),\n",
    "    ([11, 5, 7], 0, 0),\n",
    "    ([11, 5, 7], 4, 1),\n",
    "    ([11, 5, 7], 1, 0),\n",
    "    ([11, 5, 7], 4, 0),\n",
    "    ([4], 5, 1),\n",
    "    ([4], 0, 0),\n",
    "    ([4], 0, 0), \n",
    "    ([4], 5, 1), \n",
    "    ([4], 0, 0),\n",
    "    ([4], 1, 0), \n",
    "    ([11, 5, 7], 4, 1),\n",
    "    ([11, 5, 7], 1, 0),\n",
    "    ([11, 5, 7], 4, 0),\n",
    "    ([11, 5, 7], 4, 1),\n",
    "    ([11, 5, 7], 4, 0), \n",
    "    ([11, 5, 7], 0, 0),\n",
    "    ([4], 5, 1), \n",
    "    ([4], 5, 0), \n",
    "    ([4], 0, 0),\n",
    "    ([4], 5, 1),\n",
    "    ([4], 5, 0), \n",
    "    ([4], 2, 0), \n",
    "    ([11, 5, 7], 4, 1),\n",
    "    ([11, 5, 7], 4, 0),\n",
    "    ([11, 5, 7], 0, 0),\n",
    "    ([11, 5, 7], 1, 1),\n",
    "    ([11, 5, 7], 0, 0),\n",
    "    ([11, 5, 7], 0, 0), \n",
    "    ([1, 10, 12], 5, 1),\n",
    "    ([1, 10, 12], 3, 0),\n",
    "    ([1, 10, 12], 5, 0)\n",
    "]\n",
    "\n",
    "def read_list():\n",
    "    return ast.literal_eval(sys.stdin.readline())\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "def make_diag_mask(size, radius):\n",
    "    \"\"\"–ö–≤–∞–¥—Ä–∞—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ Size x Size —Å –¥–≤—É–º—è –ø–æ–ª–æ—Å–∞–º–∏ —à–∏—Ä–∏–Ω—ã radius –≤–¥–æ–ª—å –≥–ª–∞–≤–Ω–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª–∏\"\"\"\n",
    "    idxs = np.arange(size)\n",
    "    abs_idx_diff = np.abs(np.arange(size)[np.newaxis, :] - np.arange(size)[:, np.newaxis])\n",
    "    mask = ((abs_idx_diff <= radius // 2) & (abs_idx_diff > 0)).astype(int)\n",
    "    return mask\n",
    "\n",
    "def generate_ft_sgns_samples(text, window_size, vocab_size, ns_rate, token2subwords):\n",
    "    \"\"\"\n",
    "    text - list of integer numbers - ids of tokens in text\n",
    "    window_size - odd integer - width of window\n",
    "    vocab_size - positive integer - number of tokens in vocabulary\n",
    "    ns_rate - positive integer - number of negative tokens to sample per one positive sample\n",
    "    token2subwords - list of lists of int - i-th sublist contains list of identifiers of n-grams for token #i (list of subword units)\n",
    "\n",
    "    returns list of training samples (CenterSubwords, CtxWord, Label)\n",
    "    \"\"\"\n",
    "    text = np.array(text)\n",
    "    size = len(text)\n",
    "    context_words_idxs = make_diag_mask(size, window_size)\n",
    "    center_words_idx = np.eye(N=size, dtype=int)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i, word in enumerate(text):\n",
    "        context = context_words_idxs[i]\n",
    "        center = center_words_idx[i]\n",
    "\n",
    "        context_idx = np.where(context != 0)[0]\n",
    "        center_idx = np.where(center != 0)[0]\n",
    "\n",
    "        center_word = text[center_idx].tolist()\n",
    "        context_words = text[context_idx]\n",
    "        \n",
    "        center_word.extend(token2subwords[word])\n",
    "\n",
    "        positive_examples = [tuple(list(j) + [1]) for j in product([center_word], context_words)]    \n",
    "\n",
    "        # —á—Ç–æ–±—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞–ª–æ —Å —Å–∞–º–∏–º —Å–æ–±–æ–π\n",
    "#         all_words = np.arange(vocab_size)\n",
    "#         center_word_idx = np.argwhere(all_words == center_word)[0][0]\n",
    "#         all_words = list(all_words)\n",
    "#         del all_words[center_word_idx]\n",
    "#         all_words = np.array(all_words)\n",
    "#         negative_word = np.random.choice(all_words)\n",
    "\n",
    "        # –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω–æ –∏–∑ –¥–≤—É—Ö, –ª–∏–±–æ —É–±—Ä–∞—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Å–∞–º–∏–º —Å–æ–±–æ–π, –ª–∏–±–æ –Ω–µ—Ç\n",
    "        negative_words = np.random.randint(vocab_size, size=ns_rate*len(positive_examples))    \n",
    "        negative_examples = [tuple(list(j) + [0]) for j in product([center_word], negative_words)]\n",
    "\n",
    "        positive_negative_examples = positive_examples + negative_examples\n",
    "        result.extend(positive_negative_examples)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = generate_ft_sgns_samples(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c7e05",
   "metadata": {},
   "source": [
    "# 3.4.4\n",
    "\n",
    "–í—ã –æ–±—É—á–∞–µ—Ç–µ FastText SkipGram Negative Sampling.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –æ–±–Ω–æ–≤–ª—è—é—â—É—é –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–¥–Ω–æ–≥–æ –æ–±—É—á–∞—é—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ (CenterSubwords, CtxWord, Label)(CenterSubwords,CtxWord,Label).\n",
    "\n",
    "–ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ \n",
    "$P(CtxWord | CenterSubwords) = \\sigma\\left(\\left(\\sum_{w \\in CenterSubwords}^{len(CenterSubwords)} \\frac {W_{w, :}} {len(CenterSubwords)} \\right) \\cdot D_{CtxWord,:}\\right)$\n",
    " \n",
    "–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å - –±–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è.\n",
    "\n",
    "–¢–µ—Å—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a265b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.17318613700389962\n",
      "Center word grad: [[-0.1514603  -0.09180425 -0.053249   -0.12701713 -0.11297623]]\n",
      "Context word grad: [[-0.05916706 -0.13889399 -0.04673337 -0.12457505 -0.01852165]]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.07217140995735816, 0.9807495045952024, 0.5888650678318127, 0.9419020475323008, 0.9698687137771355],\n",
    "        [0.17481764801167854, 0.9598681333667267, 0.8615416075076997, 0.6649845254089604, 0.14272822189820067],\n",
    "        [0.695257160390079, 0.6252124583357915, 0.788572884360212, 0.5407620598434707, 0.4742760619803522],\n",
    "        [0.3720755825170682, 0.8734430653555122, 0.29388553936147677, 0.7833976055802006, 0.11647446813597206],\n",
    "        [0.4793503066165381, 0.7731679392102295, 0.6466062364447424, 0.5834632727525674, 0.16975097768580916],\n",
    "        [0.46855676928071344, 0.7440440871653314, 0.5968916205486556, 0.6949993371605877, 0.9995564750677164],\n",
    "        [0.3995517204225809, 0.30217048674177027, 0.6934836340605662, 0.5025452046745376, 0.43990420866402447],\n",
    "        [0.6233285824044058, 0.7510765715859197, 0.8764982899024905, 0.42892241183749247, 0.9241569354174014],\n",
    "        [0.21063022873083803, 0.979366603599722, 0.07879437255385402, 0.7103116511451802, 0.298121842692622],\n",
    "        [0.7991181799927396, 0.8700912396205017, 0.4936455488806514, 0.9306352063022928, 0.671689987782089], \n",
    "        [0.11245515636577097, 0.2591385008756272, 0.38393130144123977, 0.5927928993875077, 0.3343301767582757],\n",
    "        [0.027340724019638274, 0.15461071231349877, 0.7955192467457007, 0.050624838697975516, 0.26136570172628426],\n",
    "        [0.7825083895933859, 0.9046538942978853, 0.4559636175207443, 0.733829258685726, 0.022174763292638677],\n",
    "        [0.6968176063951074, 0.47974647096747125, 0.8885207189970179, 0.016167994434510558, 0.13260182909882334],\n",
    "        [0.5947903955259933, 0.07459974351651177, 0.11391699485528617, 0.823474357110585, 0.4918622459339238],\n",
    "        [0.6272760016913231, 0.2711994820963495, 0.24338892914238242, 0.7731707300677505, 0.03720128542002399],\n",
    "        [0.8640858092433228, 0.027663971153230382, 0.9271422334467209, 0.37457369227183035, 0.17413436429736662],\n",
    "        [0.4878584763813121, 0.5022845803948351, 0.13899660663745628, 0.8353408935052742, 0.48314336609381436],\n",
    "        [0.8197910105251979, 0.5371430936015362, 0.12965724315376936, 0.06244349080403733, 0.9558816248633216],\n",
    "        [0.5929477505385994, 0.36687167726065173, 0.42925321480480627, 0.8435274356179648, 0.8550018469714032], \n",
    "        [0.45785273815309, 0.008764229829187009, 0.6840407156586629, 0.04831125277736026, 0.14609911971743395],\n",
    "        [0.1579479219010974, 0.1298470924838635, 0.8283362978065627, 0.9140741421274726, 0.7516395431217443],\n",
    "        [0.01139316661353773, 0.6980229640742956, 0.45528806869472405, 0.7653990849713008, 0.24848012670857944],\n",
    "        [0.8750941097872984, 0.6964598870452183, 0.6675389863133752, 0.391939718013135, 0.30592620271209714], \n",
    "        [0.024161748164975072, 0.6512328549928654, 0.27784751504029503, 0.32588414662648524, 0.4073676483413957],\n",
    "        [0.7372935688667617, 0.9743689028772393, 0.26179932035274445, 0.3556999822154028, 0.8234406534181563],\n",
    "        [0.9358431512408416, 0.0030942521035778325, 0.7052198210371732, 0.3494249594704901, 0.06494462197366668],\n",
    "        [0.027642224051125597, 0.45820907093457997, 0.6172763215932299, 0.03520578036716404, 0.05004091043245007]\n",
    "    ],\n",
    "    [\n",
    "        [0.3619192935809462, 0.7910582560833153, 0.173840770588212, 0.8486217599360419, 0.09895998679198104],\n",
    "        [0.9524670374363299, 0.577316446205222, 0.3348594666828074, 0.7987547183235284, 0.710457681490417],\n",
    "        [0.8400820704952479, 0.9414962586451427, 0.08399082278691339, 0.425927381574433, 0.6304514720560764],\n",
    "        [0.5331686510681622, 0.2751366715811131, 0.8329999135745643, 0.2770290564458684, 0.020564166091874392],\n",
    "        [0.9852792048968001, 0.922320208232837, 0.7297936992308128, 0.20212997935663524, 0.5277458149323955],\n",
    "        [0.43383566311415755, 0.14151987203148808, 0.3267585826852797, 0.8796734627573763, 0.14253685112772174],\n",
    "        [0.24559727482999572, 0.3015598034026842, 0.12351719983998721, 0.6141130319406622, 0.9210871618079258],\n",
    "        [0.21915908704207665, 0.9809645232509783, 0.8685879466971278, 0.9956335594634693, 0.0441562419906687],\n",
    "        [0.24988758739587902, 0.42298807118368675, 0.01922872769211703, 0.02806386746602596, 0.2821901214584819],\n",
    "        [0.43997555452635384, 0.5078839449569567, 0.812607950040521, 0.9998014106280365, 0.1559607489614684],\n",
    "        [0.9092151190046189, 0.5930002929595868, 0.315159378929991, 0.4052299042409616, 0.984475831988958], \n",
    "        [0.7836990450026143, 0.002466529016497798, 0.8465916260137056, 0.7227126698344118, 0.5087557482398855],\n",
    "        [0.4125921074144525, 0.5582795115000383, 0.889307828978137, 0.928416977596577, 0.8437462138575066], \n",
    "        [0.11810981794872477, 0.07787452990697508, 0.3907338451314212, 0.6841828899516664, 0.4547615738832046],\n",
    "        [0.4977766315279062, 0.09878866849137813, 0.0622140049250518, 0.9008881823827194, 0.3694055807903669],\n",
    "        [0.12415427540834822, 0.01064247175537103, 0.1439469061372417, 0.43996173718103593, 0.3846553735294024],\n",
    "        [0.36544315427420426, 0.6651402425072226, 0.3837201693785094, 0.54713466624535, 0.6925194086063208], \n",
    "        [0.8217730539154436, 0.7380601103419114, 0.4790971996703556, 0.935248458815274, 0.6385239169547122], \n",
    "        [0.4884363834477089, 0.783319748626155, 0.018212966919229467, 0.03662832627793777, 0.03532160993715294], \n",
    "        [0.6820505211290306, 0.25769913167047753, 0.9677388106523852, 0.4471332422618759, 0.7731319006564568], \n",
    "        [0.3695513424667971, 0.5118113495291988, 0.1721439269100805, 0.09451631327113852, 0.8369170475041434], \n",
    "        [0.7918542552021289, 0.0245240901264403, 0.6658133706965796, 0.9740885323982209, 0.02660284500887522], \n",
    "        [0.5604137104962275, 0.5643917632639455, 0.6756476068355826, 0.9466913679034125, 0.21062462975598062], \n",
    "        [0.7306868573812846, 0.7573083135261555, 0.9450278665003865, 0.9649869335038909, 0.1262321882978371], \n",
    "        [0.6830284536315845, 0.7383035166437748, 0.7985226892860073, 0.005247820534787007, 0.6886083391552933],\n",
    "        [0.6905561126225058, 0.3220803445510755, 0.8885006766287556, 0.32709316933290455, 0.9126547743770385],\n",
    "        [0.26866358146648694, 0.9355232286537734, 0.5254946965960933, 0.6487428023364232, 0.9405298594379049], \n",
    "        [0.33881123962516546, 0.6820622877451537, 0.3053828831926755, 0.9229486901650673, 0.5450270097149575]\n",
    "    ],\n",
    "    [3],\n",
    "    1,\n",
    "    1,\n",
    "    0.8562235244377375\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [0.07217140995735816, 0.9807495045952024, 0.5888650678318127, 0.9419020475323008, 0.9698687137771355],\n",
    "        [0.17481764801167854, 0.9598681333667267, 0.8615416075076997, 0.6649845254089604, 0.14272822189820067],\n",
    "        [0.695257160390079, 0.6252124583357915, 0.788572884360212, 0.5407620598434707, 0.4742760619803522], \n",
    "        [0.5017594511598129, 0.9520480219915879, 0.3394785828834429, 0.8921526573535964, 0.21320737019064417],\n",
    "        [0.4793503066165381, 0.7731679392102295, 0.6466062364447424, 0.5834632727525674, 0.16975097768580916],\n",
    "        [0.46855676928071344, 0.7440440871653314, 0.5968916205486556, 0.6949993371605877, 0.9995564750677164], \n",
    "        [0.3995517204225809, 0.30217048674177027, 0.6934836340605662, 0.5025452046745376, 0.43990420866402447],\n",
    "        [0.6233285824044058, 0.7510765715859197, 0.8764982899024905, 0.42892241183749247, 0.9241569354174014], \n",
    "        [0.21063022873083803, 0.979366603599722, 0.07879437255385402, 0.7103116511451802, 0.298121842692622], \n",
    "        [0.7991181799927396, 0.8700912396205017, 0.4936455488806514, 0.9306352063022928, 0.671689987782089],\n",
    "        [0.11245515636577097, 0.2591385008756272, 0.38393130144123977, 0.5927928993875077, 0.3343301767582757],\n",
    "        [0.027340724019638274, 0.15461071231349877, 0.7955192467457007, 0.050624838697975516, 0.26136570172628426],\n",
    "        [0.7825083895933859, 0.9046538942978853, 0.4559636175207443, 0.733829258685726, 0.022174763292638677],\n",
    "        [0.6968176063951074, 0.47974647096747125, 0.8885207189970179, 0.016167994434510558, 0.13260182909882334],\n",
    "        [0.5947903955259933, 0.07459974351651177, 0.11391699485528617, 0.823474357110585, 0.4918622459339238],\n",
    "        [0.6272760016913231, 0.2711994820963495, 0.24338892914238242, 0.7731707300677505, 0.03720128542002399],\n",
    "        [0.8640858092433228, 0.027663971153230382, 0.9271422334467209, 0.37457369227183035, 0.17413436429736662],\n",
    "        [0.4878584763813121, 0.5022845803948351, 0.13899660663745628, 0.8353408935052742, 0.48314336609381436], \n",
    "        [0.8197910105251979, 0.5371430936015362, 0.12965724315376936, 0.06244349080403733, 0.9558816248633216], \n",
    "        [0.5929477505385994, 0.36687167726065173, 0.42925321480480627, 0.8435274356179648, 0.8550018469714032],\n",
    "        [0.45785273815309, 0.008764229829187009, 0.6840407156586629, 0.04831125277736026, 0.14609911971743395], \n",
    "        [0.1579479219010974, 0.1298470924838635, 0.8283362978065627, 0.9140741421274726, 0.7516395431217443], \n",
    "        [0.01139316661353773, 0.6980229640742956, 0.45528806869472405, 0.7653990849713008, 0.24848012670857944],\n",
    "        [0.8750941097872984, 0.6964598870452183, 0.6675389863133752, 0.391939718013135, 0.30592620271209714],\n",
    "        [0.024161748164975072, 0.6512328549928654, 0.27784751504029503, 0.32588414662648524, 0.4073676483413957],\n",
    "        [0.7372935688667617, 0.9743689028772393, 0.26179932035274445, 0.3556999822154028, 0.8234406534181563],\n",
    "        [0.9358431512408416, 0.0030942521035778325, 0.7052198210371732, 0.3494249594704901, 0.06494462197366668], \n",
    "        [0.027642224051125597, 0.45820907093457997, 0.6172763215932299, 0.03520578036716404, 0.05004091043245007]\n",
    "    ],\n",
    "    [\n",
    "        [0.3619192935809462, 0.7910582560833153, 0.173840770588212, 0.8486217599360419, 0.09895998679198104],\n",
    "        [1.0031272693097524, 0.6962407462622227, 0.37487367419295825, 0.9054188108159625, 0.726316350643562],\n",
    "        [0.8400820704952479, 0.9414962586451427, 0.08399082278691339, 0.425927381574433, 0.6304514720560764], \n",
    "        [0.5331686510681622, 0.2751366715811131, 0.8329999135745643, 0.2770290564458684, 0.020564166091874392],\n",
    "        [0.9852792048968001, 0.922320208232837, 0.7297936992308128, 0.20212997935663524, 0.5277458149323955], \n",
    "        [0.43383566311415755, 0.14151987203148808, 0.3267585826852797, 0.8796734627573763, 0.14253685112772174], \n",
    "        [0.24559727482999572, 0.3015598034026842, 0.12351719983998721, 0.6141130319406622, 0.9210871618079258], \n",
    "        [0.21915908704207665, 0.9809645232509783, 0.8685879466971278, 0.9956335594634693, 0.0441562419906687],\n",
    "        [0.24988758739587902, 0.42298807118368675, 0.01922872769211703, 0.02806386746602596, 0.2821901214584819],\n",
    "        [0.43997555452635384, 0.5078839449569567, 0.812607950040521, 0.9998014106280365, 0.1559607489614684],\n",
    "        [0.9092151190046189, 0.5930002929595868, 0.315159378929991, 0.4052299042409616, 0.984475831988958],\n",
    "        [0.7836990450026143, 0.002466529016497798, 0.8465916260137056, 0.7227126698344118, 0.5087557482398855],\n",
    "        [0.4125921074144525, 0.5582795115000383, 0.889307828978137, 0.928416977596577, 0.8437462138575066],\n",
    "        [0.11810981794872477, 0.07787452990697508, 0.3907338451314212, 0.6841828899516664, 0.4547615738832046],\n",
    "        [0.4977766315279062, 0.09878866849137813, 0.0622140049250518, 0.9008881823827194, 0.3694055807903669], \n",
    "        [0.12415427540834822, 0.01064247175537103, 0.1439469061372417, 0.43996173718103593, 0.3846553735294024],\n",
    "        [0.36544315427420426, 0.6651402425072226, 0.3837201693785094, 0.54713466624535, 0.6925194086063208],\n",
    "        [0.8217730539154436, 0.7380601103419114, 0.4790971996703556, 0.935248458815274, 0.6385239169547122],\n",
    "        [0.4884363834477089, 0.783319748626155, 0.018212966919229467, 0.03662832627793777, 0.03532160993715294],\n",
    "        [0.6820505211290306, 0.25769913167047753, 0.9677388106523852, 0.4471332422618759, 0.7731319006564568],\n",
    "        [0.3695513424667971, 0.5118113495291988, 0.1721439269100805, 0.09451631327113852, 0.8369170475041434],\n",
    "        [0.7918542552021289, 0.0245240901264403, 0.6658133706965796, 0.9740885323982209, 0.02660284500887522],\n",
    "        [0.5604137104962275, 0.5643917632639455, 0.6756476068355826, 0.9466913679034125, 0.21062462975598062],\n",
    "        [0.7306868573812846, 0.7573083135261555, 0.9450278665003865, 0.9649869335038909, 0.1262321882978371], \n",
    "        [0.6830284536315845, 0.7383035166437748, 0.7985226892860073, 0.005247820534787007, 0.6886083391552933], \n",
    "        [0.6905561126225058, 0.3220803445510755, 0.8885006766287556, 0.32709316933290455, 0.9126547743770385],\n",
    "        [0.26866358146648694, 0.9355232286537734, 0.5254946965960933, 0.6487428023364232, 0.9405298594379049],\n",
    "        [0.33881123962516546, 0.6820622877451537, 0.3053828831926755, 0.9229486901650673, 0.5450270097149575]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s * (1 - s)\n",
    "\n",
    "def log_loss(y_true, a_pred):\n",
    "    '''\n",
    "    Compute log loss, a_pred - vector of size n_objects\n",
    "    '''\n",
    "    return np.mean(-y_true * np.log(a_pred) - (1 - y_true) * np.log(1 - a_pred))\n",
    "\n",
    "def log_loss_derivative(y_true, a_pred):\n",
    "    '''\n",
    "    Compute detivative of log loss\n",
    "    '''\n",
    "    return (-y_true / a_pred + (1 - y_true) / (1 - a_pred)) / len(y_true)\n",
    "\n",
    "def update_ft_weights(center_embeddings, context_embeddings, center_subwords, context_word, label, learning_rate):\n",
    "    \"\"\"\n",
    "    center_embeddings - VocabSize x EmbSize\n",
    "    context_embeddings - VocabSize x EmbSize\n",
    "    center_subwords - list of ints - list of identifiers of n-grams contained in center word\n",
    "    context_word - int - identifier of context word\n",
    "    label - 1 if context_word is real, 0 if it is negative\n",
    "    learning_rate - float > 0 - size of gradient step\n",
    "    \"\"\"\n",
    "    # –ü–µ—Ä–µ–≤–µ–¥–µ–º –≤ numpy –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "    center_embeddings = np.asarray(center_embeddings)\n",
    "    context_embeddings = np.asarray(context_embeddings)\n",
    "    \n",
    "    # –í—ã–±–µ—Ä–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ —Å–ª–æ–≤–æ\n",
    "    center_embedding = center_embeddings[center_subwords]\n",
    "    context_embedding = context_embeddings[[context_word]]\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º \"–æ—Ü–µ–Ω–∫—É\" —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ –µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ —Ñ–æ—Ä–º—É–ª–µ\n",
    "    # ùëÉ(ùê∂ùë°ùë•ùëäùëúùëüùëë|ùê∂ùëíùëõùë°ùëíùëüùëÜùë¢ùëèùë§ùëúùëüùëëùë†)=ùúé((‚àëùëôùëíùëõ(ùê∂ùëíùëõùë°ùëíùëüùëÜùë¢ùëèùë§ùëúùëüùëëùë†)ùë§‚ààùê∂ùëíùëõùë°ùëíùëüùëÜùë¢ùëèùë§ùëúùëüùëëùë†ùëäùë§,:ùëôùëíùëõ(ùê∂ùëíùëõùë°ùëíùëüùëÜùë¢ùëèùë§ùëúùëüùëëùë†))‚ãÖùê∑ùê∂ùë°ùë•ùëäùëúùëüùëë,:)\n",
    "    score = np.mean(center_embedding, axis=0, keepdims=True).dot(context_embedding.T)\n",
    "    prob = sigmoid(score)\n",
    "    print(f'LOSS: {log_loss(label, prob)}')\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª–∞ —Ü–µ–ø–æ—á–∫–∏: –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ª–æ—Å—Å–∞ * –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é —Å–∏–≥–º–æ–∏–¥—ã\n",
    "    # * –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é ùëäùê∂ùëíùëõùë°ùëíùëüùëäùëúùëüùëë,:‚ãÖùê∑ùê∂ùë°ùë•ùëäùëúùëüùëë,: –ø–æ ùëäùê∂ùëíùëõùë°ùëíùëüùëäùëúùëüùëë –∏ ùê∑ùê∂ùë°ùë•ùëäùëúùëüùëë\n",
    "    log_loss_deriv = log_loss_derivative(np.array([label]), np.array(prob))\n",
    "    sigmoid_deriv = sigmoid_derivative(score)\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø–æ —Ü–µ—Ç—Ä–∞–ª—å–Ω–æ–º—É —Å–ª–æ–≤—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤\n",
    "    center_grad = log_loss_deriv * sigmoid_deriv * context_embedding / len(center_subwords)\n",
    "    context_grad = log_loss_deriv * sigmoid_deriv * np.mean(center_embedding, axis=0, keepdims=True)\n",
    "    print(f'Center word grad: {center_grad}')\n",
    "    print(f'Context word grad: {context_grad}')\n",
    "    \n",
    "    center_embeddings[center_subwords] -= learning_rate * center_grad\n",
    "    context_embeddings[[context_word]] -= learning_rate * context_grad\n",
    "    \n",
    "    return center_embeddings, context_embeddings\n",
    "\n",
    "\n",
    "result = update_ft_weights(*sample_input)\n",
    "\n",
    "print(np.allclose(result[0], np.array(sample_output[0])))\n",
    "print(np.allclose(result[1], np.array(sample_output[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c314d5",
   "metadata": {},
   "source": [
    "## 3.4.5\n",
    "\n",
    "–í—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å –æ–±—É—á–∞—Ç—å GloVe –∏ —Å—Ç—Ä–æ–∏—Ç–µ –º–∞—Ç—Ä–∏—Ü—É —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤, —Ç–æ –µ—Å—Ç—å –º–∞—Ç—Ä–∏—Ü—É, –≤ ij —è—á–µ–π–∫–µ –∫–æ—Ç–æ—Ä–æ–π —Å—Ç–æ–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É–ø–æ—Ç—Ä–µ–±–ª—è–ª–æ—Å—å –∏ —Å–ª–æ–≤–æ i –∏ —Å–ª–æ–≤–æ j. –ù–∞ –≥–ª–∞–≤–Ω–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª–∏ –¥–æ–ª–∂–Ω—ã —Å—Ç–æ—è—Ç—å –Ω—É–ª–∏ (—Ç–æ –µ—Å—Ç—å –Ω–µ –Ω—É–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–º–µ—Å—Ç–Ω—ã—Ö —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–π —Å–ª–æ–≤–∞ —Å —Å–∞–º–∏–º —Å–æ–±–æ–π).\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä–æ–∏—Ç —Ç–∞–∫—É—é –º–∞—Ç—Ä–∏—Ü—É. –î–æ–∫—É–º–µ–Ω—Ç—ã —É–∂–µ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∏ —Ç–æ–∫–µ–Ω—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∏—Ö —á–∏—Å–ª–æ–≤—ã–º–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏.\n",
    "\n",
    "–î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `scipy.sparse.dok_matrix`.\n",
    "\n",
    "–¢–µ—Å—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1c1911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 1.],\n",
       "        [0., 0., 2.],\n",
       "        [1., 2., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from itertools import combinations\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0, 2, 2, 2, 0, 0],\n",
    "        [1, 1, 2, 1, 1],\n",
    "        [2, 2, 1, 1]\n",
    "    ],\n",
    "    3\n",
    ")\n",
    "\n",
    "sample_output = [[0.0, 0.0, 1.0], [0.0, 0.0, 2.0], [1.0, 2.0, 0.0]]\n",
    "\n",
    "def generate_coocurrence_matrix(texts, vocab_size):\n",
    "    \"\"\"\n",
    "    texts - list of lists of ints - i-th sublist contains identifiers of tokens in i-th document\n",
    "    vocab_size - int - size of vocabulary\n",
    "    returns scipy.sparse.dok_matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab = np.arange(vocab_size)\n",
    "    coocurence = scipy.sparse.dok_matrix((vocab_size, vocab_size))\n",
    "    combs = list(combinations(vocab, 2))\n",
    "    \n",
    "    for doc in texts:\n",
    "        for i, j in combs:\n",
    "            if i in doc and j in doc:\n",
    "                coocurence[i, j] += 1\n",
    "                coocurence[j, i] += 1\n",
    "    return coocurence\n",
    "\n",
    "\n",
    "result = generate_coocurrence_matrix(*sample_input)\n",
    "\n",
    "result.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a3baa",
   "metadata": {},
   "source": [
    "## 3.4.6\n",
    "\n",
    "–í—ã –æ–±—É—á–∞–µ—Ç–µ GloVe. –ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ $X \\in \\mathbb{R}^{|Vocab| \\times |Vocab|}$ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º —Å–ø—É—Å–∫–æ–º (–¥–µ–ª–∞–µ—Ç –æ–¥–∏–Ω –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —à–∞–≥). –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –í—ã –¥–æ–ª–∂–Ω—ã –∏–∑–º–µ–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –º–∞—Å—Å–∏–≤–æ–≤ w –∏ d (inplace), –∞ –Ω–µ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–µ –º–∞—Å—Å–∏–≤—ã —Å –Ω–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: $GloVeLoss(W, D, X) = \\sum_{ij} f(x_{ij})(\\ln(1+x_{ij}) - W_{i,:} \\cdot D_{:,j})^2 \\rightarrow \\min_{W,D}$\n",
    "\n",
    "–í–æ–∑–º–æ–∂–Ω–æ, –±—É–¥–µ—Ç –ø–æ–ª–µ–∑–Ω–æ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å [—Ñ—Ä–∞–≥–º–µ–Ω—Ç –ª–µ–∫—Ü–∏–∏ –ø—Ä–æ GloVe](https://stepik.org/lesson/225313/step/5?unit=198056).\n",
    "\n",
    "–¢–µ—Å—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468ebb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [72, 67, 24, 81, 52, 43, 49, 12, 84, 77, 22, 66, 66, 0, 59, 4, 71, 78, 37, 69, 39, 63, 68, 36, 97, 17],\n",
    "        [72, 38, 34, 43, 11, 46, 91, 96, 43, 4, 80, 77, 19, 18, 39, 8, 43, 58, 59, 43, 40, 55, 14, 96, 90, 43],\n",
    "        [83, 82, 22, 93, 5, 17, 68, 30, 2, 67, 7, 8, 34, 2, 88, 66, 31, 52, 96, 13, 9, 83, 3, 9, 91, 15],\n",
    "        [73, 25, 40, 82, 42, 30, 79, 77, 15, 76, 65, 6, 7, 44, 98, 88, 65, 74, 33, 48, 61, 54, 64, 28, 49, 38],\n",
    "        [47, 41, 2, 54, 5, 13, 36, 0, 97, 15, 80, 90, 38, 27, 24, 31, 32, 20, 77, 20, 8, 11, 24, 19, 77, 23],\n",
    "        [55, 26, 42, 5, 98, 87, 36, 1, 11, 19, 57, 68, 92, 49, 98, 9, 98, 24, 0, 13, 14, 90, 10, 51, 30, 30],\n",
    "        [98, 12, 2, 66, 27, 12, 12, 60, 46, 71, 89, 82, 75, 49, 5, 77, 52, 96, 29, 32, 51, 71, 45, 16, 74, 12],\n",
    "        [18, 92, 95, 62, 51, 65, 1, 49, 51, 62, 16, 64, 97, 48, 78, 14, 90, 50, 43, 49, 59, 11, 75, 50, 60, 2],\n",
    "        [47, 45, 88, 78, 93, 30, 79, 20, 69, 68, 6, 76, 41, 3, 57, 98, 62, 6, 65, 53, 7, 9, 76, 96, 19, 88], \n",
    "        [45, 73, 39, 70, 21, 62, 82, 13, 14, 72, 8, 23, 99, 49, 33, 80, 21, 67, 37, 31, 38, 48, 40, 61, 61, 67],\n",
    "        [61, 86, 91, 61, 13, 88, 79, 56, 78, 87, 91, 94, 37, 14, 15, 44, 91, 3, 6, 23, 15, 85, 18, 58, 11, 4],\n",
    "        [50, 28, 55, 44, 21, 62, 98, 64, 85, 84, 4, 31, 59, 16, 51, 11, 37, 44, 6, 60, 47, 54, 70, 29, 32, 74],\n",
    "        [39, 6, 17, 54, 15, 71, 24, 94, 5, 16, 15, 74, 43, 98, 75, 10, 79, 78, 99, 47, 99, 4, 22, 90, 12, 19], \n",
    "        [74, 51, 67, 72, 21, 9, 57, 50, 0, 43, 80, 91, 58, 46, 92, 98, 11, 4, 36, 31, 90, 90, 91, 52, 68, 63],\n",
    "        [95, 76, 24, 52, 3, 71, 19, 75, 34, 92, 83, 15, 77, 12, 96, 58, 63, 68, 75, 9, 28, 44, 30, 94, 67, 49],\n",
    "        [22, 93, 33, 77, 2, 9, 3, 3, 47, 56, 84, 70, 15, 81, 16, 49, 20, 95, 18, 22, 98, 3, 77, 27, 1, 13],\n",
    "        [45, 63, 34, 0, 75, 45, 30, 23, 7, 7, 80, 62, 34, 11, 41, 16, 45, 6, 11, 21, 18, 55, 7, 24, 18, 70],\n",
    "        [13, 7, 21, 85, 29, 53, 56, 83, 63, 89, 18, 67, 93, 73, 37, 3, 55, 65, 16, 72, 6, 80, 0, 39, 51, 24],\n",
    "        [72, 23, 9, 56, 60, 88, 69, 6, 8, 92, 3, 44, 29, 5, 58, 58, 55, 24, 48, 57, 28, 69, 64, 72, 58, 98],\n",
    "        [20, 56, 52, 74, 27, 95, 85, 20, 7, 52, 8, 93, 76, 53, 62, 54, 34, 25, 89, 38, 85, 29, 38, 18, 1, 28],\n",
    "        [30, 97, 74, 11, 36, 92, 55, 74, 34, 29, 12, 40, 61, 69, 54, 72, 14, 64, 73, 75, 75, 4, 37, 47, 17, 29], \n",
    "        [7, 18, 25, 6, 51, 63, 63, 53, 38, 96, 19, 56, 36, 35, 75, 99, 32, 28, 68, 14, 55, 9, 3, 19, 9, 59],\n",
    "        [0, 98, 57, 98, 13, 25, 55, 56, 58, 37, 30, 90, 51, 71, 10, 36, 58, 94, 32, 80, 95, 44, 40, 82, 99, 6], \n",
    "        [74, 28, 93, 37, 81, 54, 92, 89, 52, 96, 93, 8, 65, 82, 7, 14, 75, 0, 45, 59, 15, 17, 85, 87, 10, 52],\n",
    "        [10, 74, 13, 23, 56, 25, 66, 59, 86, 39, 47, 72, 92, 28, 23, 75, 23, 18, 5, 20, 36, 52, 42, 56, 20, 7], \n",
    "        [32, 37, 58, 20, 3, 33, 76, 92, 36, 73, 90, 53, 82, 78, 6, 66, 11, 33, 64, 68, 51, 76, 94, 94, 74, 88]\n",
    "    ],\n",
    "    [\n",
    "        [0.7236403458959406, 0.0956019387576047, 0.0025299248050427714, 0.8219024304497274, 0.43253754513562515, 0.8013795226500925],\n",
    "        [0.1645225418615962, 0.17254764305062675, 0.915834884927677, 0.15659274788174238, 0.4408801726853846, 0.6712507398638423],\n",
    "        [0.7220314060070252, 0.1109087497279424, 0.8673890374761482, 0.6019681601593759, 0.21136092547712715, 0.46410460250177055],\n",
    "        [0.2051472970020488, 0.7021578939163269, 0.4920315519905448, 0.8786530949689468, 0.8406582658875078, 0.7656322995670249], \n",
    "        [0.5314722945128192, 0.20582039242966288, 0.6649783801689887, 0.9122470167268962, 0.06046820688028054, 0.7640361944809368],\n",
    "        [0.8531299103217095, 0.8837919293919477, 0.5584731093192602, 0.5488851769744959, 0.5426259488733682, 0.8101919492091457], \n",
    "        [0.014691936047236509, 0.8299297933323541, 0.04420642840864686, 0.19514486051010316, 0.5605834763387445, 0.021425480951998255],\n",
    "        [0.6251450063221531, 0.916013278510962, 0.9266733043623226, 0.4314909906070713, 0.5861250222822415, 0.6933275681854775], \n",
    "        [0.613436662402963, 0.25971014970117345, 0.8516017571376222, 0.3946078968050868, 0.5030576607821642, 0.4947379037657953], \n",
    "        [0.1831704150579163, 0.7027400367924451, 0.9687380255252486, 0.05161874874595729, 0.5662001008903554, 0.1163342848387866],\n",
    "        [0.7871817922619593, 0.2744881375377821, 0.47927673745333677, 0.29916960674176196, 0.36165825794500894, 0.4473132902029585],\n",
    "        [0.9460136327515588, 0.9784510345542305, 0.7292583652396575, 0.9967710630754123, 0.5222338378761943, 0.15774056366446398], \n",
    "        [0.5663154377790205, 0.31992559317458047, 0.895903341426127, 0.10800834113175917, 0.7025174488794499, 0.09983260287294515],\n",
    "        [0.2870859802344229, 0.6124244361792336, 0.03043370710190285, 0.4177754705816856, 0.41076530192454186, 0.059229404317664214],\n",
    "        [0.453421549409623, 0.10006035499361832, 0.4729640823042591, 0.4187735846604017, 0.19252902582118436, 0.4571615927038022],\n",
    "        [0.4717366823003555, 0.311470963714212, 0.7563429074261462, 0.9450429903711869, 0.23851560864324461, 0.4264206092799121],\n",
    "        [0.14209483434392234, 0.9545183136517666, 0.02853067102355411, 0.8397788414889452, 0.28747164060068653, 0.5890799959267197],\n",
    "        [0.7137144457967627, 0.7108041311984524, 0.3391605131543025, 0.18466650700703768, 0.07037926283668172, 0.1691030355977058],\n",
    "        [0.4181167385409663, 0.5733773938988352, 0.9308794863064511, 0.955104551017489, 0.7472618752255964, 0.9106883383537705], \n",
    "        [0.29209827546854006, 0.7950653331872178, 0.9314779081831699, 0.2137419943082265, 0.9590688802321072, 0.21779623076769017],\n",
    "        [0.6414528631722118, 0.7772400748403205, 0.7240597746441493, 0.4846785371953165, 0.20903895145878393, 0.9928711008461597],\n",
    "        [0.4987552039133927, 0.966261456826001, 0.6392910461562884, 0.3891694028095307, 0.14376415691424704, 0.5654942409405452],\n",
    "        [0.39062876410463865, 0.4372793328535669, 0.9066881332880398, 0.928194141998039, 0.26891611788606773, 0.970014111003586], \n",
    "        [0.05753018657343756, 0.5987554892139141, 0.6695393400712614, 0.4342378657370556, 0.5068004463455815, 0.28913437767829675],\n",
    "        [0.31284712702847906, 0.6696586256781413, 0.6349611781499843, 0.11008282689008553, 0.9000387199581723, 0.5893732652223279],\n",
    "        [0.38771861901614457, 0.9275236976874062, 0.1507893346167909, 0.2649576462980838, 0.8917999241041804, 0.7060665522096253]\n",
    "    ],\n",
    "    [\n",
    "        [0.7146175764456325, 0.31161087332596693, 0.799868898982844, 0.3303984762074823, 0.15755367025489198, 0.8822561515814714],\n",
    "        [0.48324415449065805, 0.32294633607735035, 0.273076894762348, 0.46575965932905583, 0.35173647464295466, 0.0698782343365999],\n",
    "        [0.05951092454514029, 0.9631544906381114, 0.14919875559361273, 0.9071033838543416, 0.9235221236014998, 0.15343960980130578],\n",
    "        [0.37667471994346735, 0.3832592710693109, 0.1372971042292026, 0.5063394603470396, 0.3657347277059969, 0.21520394748123772],\n",
    "        [0.5589413502705171, 0.9228726685280682, 0.9028006349689756, 0.7902921185261006, 0.09337560160131464, 0.8806823905125992], \n",
    "        [0.19078196327854235, 0.9862705503057667, 0.00800242331367751, 0.7036641885324555, 0.7452071471082209, 0.85314563397203], \n",
    "        [0.42059808696733225, 0.3678976649279547, 0.15153142787888962, 0.9831212856723789, 0.7218055186807681, 0.8943329971799489],\n",
    "        [0.058672278269596756, 0.6364681756816949, 0.24610924719747507, 0.8429515887557353, 0.23639035927773622, 0.9193123017124043],\n",
    "        [0.3667295853360063, 0.46010540148263646, 0.818107188288508, 0.027140526241385965, 0.4420026102807323, 0.3050634480740779],\n",
    "        [0.9602073143407148, 0.5408373879572825, 0.4027285042008486, 0.854769594232319, 0.8977332204421882, 0.7804511190784789], \n",
    "        [0.9554030213710992, 0.6286064807931032, 0.7899715293283952, 0.20778805629585584, 0.34452317136784105, 0.8373278109724016],\n",
    "        [0.9511367017094053, 0.8108673965379353, 0.5917802839407773, 0.08638924272725734, 0.5614389008614823, 0.10285577516634681], \n",
    "        [0.15293610366355237, 0.4726630546010566, 0.7151593451811216, 0.6787398883364194, 0.05726564336395312, 0.11175850750236216],\n",
    "        [0.5284613368117816, 0.2171952870224766, 0.14730305464381344, 0.16327154211081985, 0.22473713798444594, 0.8780618686814565],\n",
    "        [0.6229749344457463, 0.2450307938022901, 0.856716114606889, 0.5130970556519491, 0.09638792050417233, 0.5580480219996736],\n",
    "        [0.02557257524793899, 0.16614696997999867, 0.9057474930205891, 0.9639638373151679, 0.8305505098688646, 0.13212730388642224],\n",
    "        [0.9945224728362285, 0.601015567237635, 0.627777689771871, 0.062014306890884385, 0.5482657713187832, 0.050645865034282034],\n",
    "        [0.222530564647055, 0.16270913407631815, 0.3463743065572499, 0.3642479732760492, 0.6787809827842912, 0.6698646733332234], \n",
    "        [0.0514618465561959, 0.09146560753484756, 0.5663782403169225, 0.09809277695721963, 0.7435268283749681, 0.6941669527997202], \n",
    "        [0.7220783710745816, 0.242189075941737, 0.19197963437514165, 0.2789768605860322, 0.1257100212184865, 0.25803379668907667],\n",
    "        [0.5231678066470311, 0.4611093289035184, 0.8420569136872692, 0.9566490894261072, 0.07691192438283945, 0.37613366065780873], \n",
    "        [0.010481514678729265, 0.5145103851754453, 0.9425491945781952, 0.24440293940943314, 0.2766636476384883, 0.9944680222564074],\n",
    "        [0.7081598239606982, 0.3291415847107684, 0.7986116830970068, 0.32005951294163504, 0.988878016430301, 0.16702718654180948],\n",
    "        [0.3281899603978248, 0.8371583970360936, 0.914781121298489, 0.9898376984561366, 0.2605393835200668, 0.7046307961318979],\n",
    "        [0.6669241697435273, 0.7506837943872975, 0.3223310011040579, 0.8024412673323509, 0.47139557621217376, 0.34991596973647043],\n",
    "        [0.6981065171211724, 0.7907802796637423, 0.05700463849852977, 0.29301210116680565, 0.3246921756526622, 0.9147896908728982]\n",
    "    ],\n",
    "    0.5878728651551414,\n",
    "    97,\n",
    "    0.8066056621137515\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [37.894949622265095, 35.32608453541813, 39.58755103784916, 33.56742861491748, 31.889707572091282, 33.00715086688418],\n",
    "        [33.84381119427707, 38.036945787753176, 34.69008748288071, 36.55796979484229, 30.50706391340045, 40.418661343576375],\n",
    "        [22.292630735670524, 22.26123383895233, 27.281358895160945, 29.762116352667036, 26.093786102891865, 28.873616599806525],\n",
    "        [28.627244763428482, 25.010240783610097, 30.24910190951392, 29.94251520200709, 25.793350857840288, 31.500830971429988],\n",
    "        [24.86914949950388, 21.18902354047288, 25.17742133333728, 16.734270195198985, 21.32882188455089, 20.133684294288226], \n",
    "        [20.607435095197772, 23.38444651793354, 24.170604089788068, 19.190985999049406, 14.732626697936645, 22.085786623565003],\n",
    "        [41.83248643873107, 39.23972477624278, 48.25206831443954, 39.18447489715208, 36.223555643455576, 43.838987581052415], \n",
    "        [25.957662536809675, 27.78414465308494, 26.831852326280252, 27.670481277635595, 24.681666254723726, 21.151581083066553],\n",
    "        [32.851892878431265, 36.440775336903165, 35.75352506946652, 37.30323390355503, 34.53270452844875, 31.563665533166038],\n",
    "        [30.835038636245486, 34.52475728758245, 33.16493620256741, 41.27828441760409, 33.625782386520584, 37.29511586329691], \n",
    "        [33.83703170479853, 40.43002001773247, 36.184443329518004, 37.12624122167327, 35.08771179980609, 35.139255640003434], \n",
    "        [21.254977902045137, 23.060454293882493, 21.303095809926, 23.591298842309634, 20.611990194926875, 24.660270597555062], \n",
    "        [29.841626803079436, 31.839284837338443, 32.251032295284844, 33.58647928947483, 26.771111486581926, 37.72191514982901],\n",
    "        [44.55346815719802, 45.05766658559051, 52.471710160526506, 49.79668060973384, 39.22443377310308, 47.134158002890395], \n",
    "        [39.17357712318688, 41.7702595729068, 45.89022396002535, 45.0492861943433, 37.91715762872248, 46.34889394407784],\n",
    "        [27.66000266779389, 21.58602345742282, 26.20679184375472, 22.50135429223267, 24.80834623255724, 21.774444708488712],\n",
    "        [24.235631356398315, 25.330637975611467, 24.35882534462737, 19.614644539141796, 16.096340205031563, 23.969425116432753],\n",
    "        [32.714784659285534, 37.00623479448081, 32.80393996121548, 35.850620589216966, 29.775563785011812, 40.1682995737016], \n",
    "        [22.473439079254767, 21.63905155108375, 21.309990260094732, 21.384623495336577, 20.03459479396905, 23.052219798176157],\n",
    "        [25.833857096031426, 28.006935843177743, 27.529323359718862, 31.562166519759444, 27.60438145889944, 28.783954098290046],\n",
    "        [21.724755945837586, 25.46457829943065, 25.453384408355255, 30.825724432379566, 26.016894561298137, 26.62071479383954],\n",
    "        [21.81725003511163, 24.05930480422645, 25.802129103735567, 28.29934558071534, 24.882668372989844, 27.55650443868176],\n",
    "        [29.608735571248964, 29.25708252569204, 28.139612290451367, 30.385015579072235, 27.487966113975027, 24.962848111956525],\n",
    "        [39.403771170848984, 41.917746619056196, 37.84557861173111, 40.69821075997771, 35.62873141884051, 45.079155106826896],\n",
    "        [23.04120185595438, 26.786780888021532, 31.2639541627983, 29.00755536709279, 22.203982913169703, 24.495657931209138],\n",
    "        [32.403129266441965, 35.840017821814904, 37.17203998680061, 38.03281061366912, 32.78714804739385, 39.28183659620253]\n",
    "    ],\n",
    "    [\n",
    "        [25.737584343831532, 31.976583863756073, 31.991796072794237, 30.397770296625676, 29.155071762578395, 28.039906267294363],\n",
    "        [39.18090234664077, 43.45477045037197, 51.786860206912635, 43.09517606909757, 36.467098828996626, 45.87756004198227],\n",
    "        [25.861638022497715, 30.92652100750488, 33.60725677532385, 25.184249360983333, 25.33461010279592, 26.93195963760828],\n",
    "        [40.44255724281372, 42.96387247113741, 54.334811744166686, 43.93191831350745, 40.27560778331666, 40.23238565434164], \n",
    "        [12.60992409857056, 19.726007962924154, 16.071644794959607, 14.161701223195637, 15.198176415121148, 15.276991028259971], \n",
    "        [29.04588467665483, 33.80505200039617, 38.04855856282448, 24.880963308310946, 27.92967131290679, 28.76950184954046], \n",
    "        [30.237437485971547, 38.66537897520929, 42.70573743205196, 29.776069477137508, 33.905932759342974, 31.963285050639865],\n",
    "        [28.028933057301142, 38.08684708617139, 37.544542228274906, 25.321920916303146, 31.533875714831566, 29.298469894937988],\n",
    "        [30.71424884632851, 30.95498799285244, 34.15309776359906, 31.217888494294368, 24.993625601516545, 31.928661444788062], \n",
    "        [26.146184710215547, 32.46478475669627, 31.62669482728407, 25.64499465851579, 26.152486540238574, 24.145438152077382], \n",
    "        [18.513444310864926, 28.714219341908812, 22.747896951556424, 25.100699161335342, 23.409036420228585, 24.514405065630598],\n",
    "        [34.97755034206531, 41.735458041689185, 42.23493985650944, 36.009265517304414, 34.352119472664846, 37.644071472340144],\n",
    "        [40.092702168388236, 53.62113178600554, 48.84356458863764, 36.39043705817393, 42.28637968655391, 40.280349955856444], \n",
    "        [27.09610113742262, 41.26880485353593, 39.346977655994735, 27.591514389672355, 31.995616644580924, 28.87474376777405], \n",
    "        [32.46320730114356, 36.48181104762826, 38.714631286168924, 32.33019087297395, 30.27052570417721, 32.240695698900474], \n",
    "        [24.62678794161355, 36.21315596132247, 34.91748692038032, 27.31267275243153, 29.942035228767967, 28.65251738118413],\n",
    "        [31.908551549750985, 35.150861854275824, 38.81804750019257, 33.07677850315476, 30.681610274970396, 34.06666656257596],\n",
    "        [30.48008982537277, 35.58865452115646, 40.57350768906002, 33.041098811455335, 29.65449752756178, 32.70055131481196],\n",
    "        [30.57739739495991, 34.19410957043535, 44.6772377886788, 31.000103986208202, 31.17905081422838, 34.40131935305819],\n",
    "        [32.07230397160679, 40.95180323381044, 41.63975849206306, 34.856807118616764, 34.237546314068695, 36.52332793161486],\n",
    "        [22.165179600850514, 32.94179603315074, 32.363977866166756, 25.282871906957595, 28.351785486262752, 24.632822374929177], \n",
    "        [28.16174839655334, 35.544107679226634, 28.118950582145626, 28.3788129267007, 28.77498009421306, 28.156490872467124],\n",
    "        [22.230950864818148, 30.475956010093874, 28.654962541126377, 28.12410255465114, 28.61378026798125, 25.497683394160806],\n",
    "        [22.53316383674741, 26.507404577732675, 32.26317495605627, 20.718985703375136, 26.011612018642545, 25.31060496066265],\n",
    "        [24.59110367631163, 27.543472573592013, 30.621636332862288, 28.235921081852787, 24.45902884286537, 29.64689202372981], \n",
    "        [21.024604742056106, 30.902045272493908, 29.293039097395038, 24.61451220740829, 24.812533834540638, 23.893380083955623]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def f(x, x_max, alpha):\n",
    "    \"\"\"–í–µ—Å–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è ùëì(ùë•ùëñùëó)\"\"\"\n",
    "    return np.where(x <= x_max, (x/x_max)**alpha, 1)\n",
    "\n",
    "def update_glove_weights(x, w, d, alpha, max_x, learning_rate):\n",
    "    \"\"\"\n",
    "    x - square integer matrix VocabSize x VocabSize - coocurrence matrix\n",
    "    w - VocabSize x EmbSize - first word vectors\n",
    "    d - VocabSize x EmbSize - second word vectors\n",
    "    alpha - float - power in weight smoothing function f\n",
    "    max_x - int - maximum coocurrence count in weight smoothing function f\n",
    "    learning_rate - positive float - size of gradient step\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    w = np.asarray(w)\n",
    "    d = np.asarray(d)\n",
    "    \n",
    "    f_x = f(x, max_x, alpha)\n",
    "    gloveloss = np.sum(f_x * (np.log(1+x) - w.dot(d.T)) ** 2)\n",
    "    glove_loss_deriv = -2 * (f_x * (np.log(1+x) - w.dot(d.T)))\n",
    "    \n",
    "    w_grad = glove_loss_deriv.dot(d)\n",
    "    d_grad = glove_loss_deriv.T.dot(w)\n",
    "    \n",
    "    w -= learning_rate * w_grad\n",
    "    d -= learning_rate * d_grad\n",
    "    return w, d\n",
    "\n",
    "result = update_glove_weights(*sample_input)\n",
    "\n",
    "print(np.allclose(result[0], sample_output[0]))\n",
    "print(np.allclose(result[1], sample_output[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f9d9ae",
   "metadata": {},
   "source": [
    "## 3.4.7\n",
    "\n",
    "–í—ã –æ–±—É—á–∏–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—É—é –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –ø–æ–ª—É—á–∏–ª–∏ –º–∞—Ç—Ä–∏—Ü—É –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –ø–æ–ª—É—á–∏—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ –Ω–µ–≥–æ —Å–ª–æ–≤ –≤–º–µ—Å—Ç–µ —Å –æ—Ü–µ–Ω–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ (–Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ –≤–Ω–∞—á–∞–ª–µ). –°–∞–º–æ —Å–ª–æ–≤–æ —Ç–æ–∂–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –≤—ã–¥–∞—á–µ.\n",
    "\n",
    "–î–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —ç–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ $sim(a, b) = - \\sqrt{\\sum_i {(a_i - b_i) ^ 2}}$.\n",
    "–ü–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–æ—Ä–º–∏—Ä—É–π—Ç–µ –≤–µ–∫—Ç–æ—Ä—ã –ø–æ L2-–Ω–æ—Ä–º–µ.\n",
    "\n",
    "–¢–µ—Å—Ç—ã (–≤–∫–ª—é—á–∞—è —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞) –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥:\n",
    "\n",
    "- embeddings - –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ VocabSize x EmbSize - –∑–∞—Ä–∞–Ω–µ–µ –≤—ã—É—á–µ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤ (—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)\n",
    "- query_word_id - —Ü–µ–ª–æ–µ –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ - –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–Ω–æ–º–µ—Ä) —Å–ª–æ–≤–∞-–∑–∞–ø—Ä–æ—Å–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞\n",
    "- get_n - —Ü–µ–ª–æ–µ –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ - –Ω–∞–∏–±–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "–§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏–∑ –Ω–µ –±–æ–ª–µ–µ —á–µ–º get_n –ø–∞—Ä (–Ω–æ–º–µ—Ä —Å–ª–æ–≤–∞, –æ—Ü–µ–Ω–∫–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞), –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å–æ —Å–ª–æ–≤–æ–º-–∑–∞–ø—Ä–æ—Å–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0825d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -0.0), (2, -0.502892189275798), (1, -0.542231021984391)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.7299015792584768, 0.2915364327741303, 0.5307571134639943, 0.3101345732086396, 0.8327085262119636, 0.39018382511314353, 0.678094726221033, 0.12372148102696612, 0.5966533433209616],\n",
    "        [0.5411155947267721, 0.046791742239819856, 0.5358832195593092, 0.09894162419462038, 0.6350557173679914, 0.15126161842015717, 0.11375720216711405, 0.46954553941325416, 0.8281402097264261],\n",
    "        [0.5323869209381028, 0.2005012376766715, 0.5925043884236925, 0.4621530177251649, 0.3886830034303448, 0.6403738184472031, 0.23320289120963578, 0.43574647265888766, 0.5305633832484254]\n",
    "    ],\n",
    "    0,\n",
    "    8\n",
    ")\n",
    "\n",
    "sample_output = [[0.0, -0.0], [2.0, -0.502892189275798], [1.0, -0.542231021984391]]\n",
    "\n",
    "def negative_euclidean(a, b):\n",
    "    return -np.sqrt(np.sum((a-b)**2, axis=1))\n",
    "\n",
    "def l2_norm_vector(x):\n",
    "    return x / np.sqrt(np.sum(x**2, axis=1, keepdims=True))\n",
    "\n",
    "def get_nearest(embeddings, query_word_id, get_n):\n",
    "    \"\"\"\n",
    "    embeddings - VocabSize x EmbSize - word embeddings\n",
    "    query_word_id - integer - id of query word to find most similar to\n",
    "    get_n - integer - number of most similar words to retrieve\n",
    "\n",
    "    returns list of `get_n` tuples (word_id, similarity) sorted by descending order of similarity value\n",
    "    \"\"\"\n",
    "    embeddings = np.asarray(embeddings)\n",
    "    \n",
    "    # –ù–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    embeddings = l2_norm_vector(embeddings)\n",
    "    \n",
    "    distances = negative_euclidean(embeddings[query_word_id], embeddings)\n",
    "    \n",
    "    similars = [(word, distance) for word, distance in enumerate(distances)]\n",
    "    similars = sorted(similars, key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "    return similars[:get_n]\n",
    "\n",
    "\n",
    "result = get_nearest(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c9d02",
   "metadata": {},
   "source": [
    "## 3.6.6\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–≤—ë—Ä—Ç–∫—É –∫ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–æ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 2 (—á–∞—Å—Ç—å 1)\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –º–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω—É—é —Å–≤–µ—Ä—Ç–∫—É, –ø—Ä–∏–Ω–∏–º–∞—é—â—É—é –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É $X^{InLen, InChannels}$\n",
    " , –≥–¥–µ InLen - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫, —Ä–∞–≤–Ω–æ–µ –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, InChannels - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤, —Ä–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤–æ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –º–∞—Ç—Ä–∏—Ü–∞ $Y^{OutLen}$\n",
    " , –≥–¥–µ $OutLen = InLen - K + 1$ - –¥–ª–∏–Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, K - —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ —Å–≤—ë—Ä—Ç–∫–∏.\n",
    "\n",
    "–Ø–¥—Ä–æ —Å–≤–µ—Ä—Ç–∫–∏ —Å –æ–¥–Ω–∏–º –≤—ã—Ö–æ–¥–Ω—ã–º –∫–∞–Ω–∞–ª–æ–º –∑–∞–¥–∞—ë—Ç—Å—è –¥–≤—É–º–µ—Ä–Ω—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º $Kernel^{InChannels, K}$\n",
    "\n",
    "–ú–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω–∞—è —Å–≤—ë—Ä—Ç–∫–∞ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–µ–π —Ñ–æ—Ä–º—É–ª–æ–π (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –æ–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω–æ–π, –Ω–æ –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –∫–∞–Ω–∞–ª –≤–ª–∏—è—é—Ç –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã):\n",
    "\n",
    "$Y[pos] = Bias+ \\sum_{k=0}^{K-1} \\sum_{ic=0}^{InChannels - 1} X[pos + k,ic] Kernel[ic,k]$\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–µ–π, –∫—Ä–æ–º–µ —è–¥—Ä–∞ —Å–≤—ë—Ä—Ç–∫–∏, –µ—Å—Ç—å –µ—â—ë –æ–±—É—á–∞–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–¥–≤–∏–≥–∞ $Bias$.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä:\n",
    "\n",
    "![](https://ucarecdn.com/9bfefed6-b35d-4fdc-a154-6ef680a01aaa/)\n",
    " \n",
    "\n",
    "–î–ª—è –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
    "\n",
    "$X^{5, 2} = \\left( \\begin{matrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ \\end{matrix} \\right)$\n",
    "\n",
    "–Ø–¥—Ä–∞, –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ª–µ–¥—É—é—â–µ–π –º–∞—Ç—Ä–∏—Ü–µ–π –∏ –Ω—É–ª–µ–≤–æ–≥–æ —Å–º–µ—â–µ–Ω–∏—è:\n",
    "\n",
    "$Kernel^{2, 3}= \\left( \\begin{matrix} 1 & 1 & 0\\\\ 0 & 1 & 1\\\\ \\end{matrix} \\right), Bias=0$\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞–π—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π –≤–µ–∫—Ç–æ—Ä YY:\n",
    "\n",
    "$Y[pos] = Bias + \\sum_{k=0}^{2} \\sum_{ic=0}^{1} X[pos + k,ic] Kernel[ic, k]$\n",
    "\n",
    "–í –æ—Ç–≤–µ—Ç –≤–ø–∏—à–∏—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤–µ–∫—Ç–æ—Ä–∞ YY , —Å–æ—Å—Ç–æ—è—â–µ–≥–æ –∏–∑ —Ç—Ä–µ—Ö —á–∏—Å–µ–ª, —á–∏—Å–ª–∞ —Ä–∞–∑–¥–µ–ª—è–π—Ç–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É.\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä —Å–¥–≤–∏–≥–∞ —Å—á–∏—Ç–∞–π—Ç–µ –Ω—É–ª–µ–≤—ã–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d597faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output len: 3\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_in = np.array([\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 1]\n",
    "])\n",
    "\n",
    "kernel_size = kernel.shape[1]\n",
    "output_len = x_in.shape[0] - kernel_size + 1\n",
    "print(f'Output len: {output_len}')\n",
    "\n",
    "for i in range(output_len):\n",
    "    print(np.sum(x_in[0+i:kernel_size+i, :] * kernel.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0cc7d",
   "metadata": {},
   "source": [
    "## 3.6.7\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–≤—ë—Ä—Ç–∫—É –∫ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–æ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 2. (—á–∞—Å—Ç—å 2)\n",
    "\n",
    "–£—Å–ª–æ–∂–Ω–∏–º –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ –º–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω—É—é —Å–≤–µ—Ä—Ç–∫—É: —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å –±—É–¥–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤.\n",
    "\n",
    "–ü–æ –ø—Ä–µ–∂–Ω–µ–º—É –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É X^{InLen, InChannels}X \n",
    "InLen,InChannels\n",
    " , –≥–¥–µ InLen - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫, —Ä–∞–≤–Ω–æ–µ –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, InChannels - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤, —Ä–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤–æ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ù–æ –Ω–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —è–¥—Ä–æ –º–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω–æ–π —Å–≤—ë—Ä—Ç–∫–∏ –∑–∞–¥–∞–µ—Ç—Å—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º Kernel^{OutChannels, InChannels, K}Kernel \n",
    "OutChannels,InChannels,K\n",
    " , –≥–¥–µ –Ω–æ–≤—ã–º –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –±—É–¥–µ—Ç OutChannels - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–¢–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–≤–µ—Ä—Ç–∫–∏ –±—É–¥–µ—Ç –º–∞—Ç—Ä–∏—Ü–∞ Y^{OutLen, OutChannels}Y \n",
    "OutLen,OutChannels\n",
    " , –≥–¥–µ OutLen = InLen - K + 1OutLen=InLen‚àíK+1 - –¥–ª–∏–Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, K - —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ —Å–≤—ë—Ä—Ç–∫–∏, OutChannels - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–°–≤—ë—Ä—Ç–∫–∞ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–µ–π —Ñ–æ—Ä–º—É–ª–æ–π:\n",
    "\n",
    "$Y[pos,oc] = Bias[oc] + \\sum_{k=0}^{K-1} \\sum_{ic=0}^{InChannels - 1} X[pos + k,ic] Kernel[oc,ic,k]$\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ,  —Ç–µ–ø–µ—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–¥–≤–∏–≥–∞ - —ç—Ç–æ –≤–µ–∫—Ç–æ—Ä –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $Bias^{OutChannels}$Bias \n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ —à–∞–≥–∞:\n",
    "\n",
    "![](https://ucarecdn.com/e8d1ab37-c4c1-4ef5-bed7-f832497f4df1/)\n",
    "\n",
    "–í—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:\n",
    "\n",
    "$X^{5, 2} =\\left( \\begin{matrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ \\end{matrix} \\right)$\n",
    "\n",
    "–Ø–¥—Ä–æ (–∫–∞–∂–¥–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ä–µ–∑—É –ø–æ –ø–µ—Ä–≤–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é - OutChannels, - –∏ –∏–º–µ–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É InChannels x KernelSize):\n",
    "\n",
    "$Kernel^{2,2, 3}=\\left( \\begin{matrix} 1 & 1 & 0\\\\ 0 & 1 & 1\\\\ \\end{matrix} \\right) \\left( \\begin{matrix} 1 & 0 & 0\\\\ 0 & 0 & 1\\\\ \\end{matrix} \\right)$\n",
    "\n",
    "–í –æ—Ç–≤–µ—Ç –≤–ø–∏—à–∏—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–∞—Ç—Ä–∏—Ü—ã, –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ, —á–∏—Å–ª–∞ —Ä–∞–∑–¥–µ–ª—è—Ç—å –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—á–∫—É.\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä —Å–¥–≤–∏–≥–∞ —Å—á–∏—Ç–∞–π—Ç–µ –Ω—É–ª–µ–≤—ã–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f842dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output len: 3, out channels: 2\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_in = np.array([\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1]\n",
    "    ],\n",
    "    [\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ]\n",
    "])\n",
    "\n",
    "kernel_size = kernel.shape[2]\n",
    "out_channels = kernel.shape[0]\n",
    "\n",
    "output_len = x_in.shape[0] - kernel_size + 1\n",
    "print(f'Output len: {output_len}, out channels: {out_channels}')\n",
    "\n",
    "for ker in kernel:\n",
    "    for i in range(output_len):\n",
    "        print(np.sum(x_in[i:kernel_size+i, :] * ker.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02cca2",
   "metadata": {},
   "source": [
    "## 3.8.1\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –ø—Ä–∏–º–µ–Ω—è—é—â—É—é —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ—Å–æ–±–∏—è –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏ —Ñ–æ—Ä–º—É–ª—É –∏–∑ –∑–∞–¥–∞—á–∏ 3.6.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819f73a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output len: 12, out channels: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.53637401, 3.40559783, 3.64203285],\n",
       "       [3.53791755, 3.31563793, 3.19785548],\n",
       "       [3.11553433, 2.6461514 , 2.82923446],\n",
       "       [3.95582621, 2.68487692, 2.35547493],\n",
       "       [3.31545625, 2.55379287, 2.97932928],\n",
       "       [3.23359714, 1.88961059, 2.29726403],\n",
       "       [2.55036376, 2.44108517, 2.06635398],\n",
       "       [3.80066148, 2.76372775, 3.03033055],\n",
       "       [2.87705358, 2.37783992, 2.69971685],\n",
       "       [3.48545989, 1.96369042, 1.96099252],\n",
       "       [3.37079171, 2.66791052, 2.27237898],\n",
       "       [4.17954021, 2.6157867 , 3.36235457]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.6685863697825855, 0.9865099796400376],\n",
    "        [0.32297881307708, 0.9908870158650515],\n",
    "        [0.8359169063921157, 0.5443776713017927],\n",
    "        [0.5363888029267118, 0.34755850459471804],\n",
    "        [0.5966372342560426, 0.9834742307894673],\n",
    "        [0.7371274295314912, 0.03279590013405109],\n",
    "        [0.08580648148402137, 0.2850655085982621],\n",
    "        [0.584942134340805, 0.7981720699451806],\n",
    "        [0.19604496972304086, 0.991819073359733],\n",
    "        [0.5622511488322055, 0.07928952553499002],\n",
    "        [0.24152151330089744, 0.2865696384305756],\n",
    "        [0.882594506643994, 0.5949729821472712],\n",
    "        [0.10820233432771786, 0.8549971123651271],\n",
    "        [0.18754460128195194, 0.6303661925298489],\n",
    "        [0.3551051497971416, 0.9452980688158904],\n",
    "        [0.6525044770663634, 0.8054232618991838]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [0.8638059436915633, 0.4002290439648929, 0.8174398057982054, 0.34082478315585973, 0.5565832130592809],\n",
    "            [0.08497737591188492, 0.7853885140384725, 0.1645895575029136, 0.6294907704137637, 0.8169862258229014]\n",
    "        ],\n",
    "        [\n",
    "            [0.21527072709338957, 0.9185427760457524, 0.5167378860756242, 0.12177789993763499, 0.4201289643444214],\n",
    "            [0.8389450071463863, 0.6238637143288427, 0.5098771768082815, 0.1436853463091461, 0.12036561608743845]\n",
    "        ],\n",
    "        [\n",
    "            [0.8347050184618267, 0.12339875692133984, 0.13629086964943626, 0.623950910768403, 0.7092189295761365],\n",
    "            [0.9578703072530402, 0.31612669923975534, 0.44018179806384916, 0.26615330385390035, 0.2745979551030847]\n",
    "        ]\n",
    "    ],\n",
    "    [0.6574440445518804, 0.3253787051567585, 0.3119672663686287]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [4.536374007375313, 3.40559782717228, 3.6420328514923983],\n",
    "        [3.5379175544464094, 3.3156379278173618, 3.197855475391681],\n",
    "        [3.11553432527298, 2.6461513962620473, 2.829234462423411],\n",
    "        [3.955826212094638, 2.6848769190617205, 2.355474927521796],\n",
    "        [3.315456250217841, 2.5537928749371677, 2.979329283784809],\n",
    "        [3.2335971417998324, 1.8896105910662777, 2.297264030641381],\n",
    "        [2.5503637613247276, 2.441085171765234, 2.066353981430436],\n",
    "        [3.8006614791608166, 2.7637277539201435, 3.030330546451793],\n",
    "        [2.8770535772488457, 2.377839924681041, 2.6997168451820808],\n",
    "        [3.4854598947993667, 1.9636904181843315, 1.9609925225671008],\n",
    "        [3.3707917076650484, 2.6679105220798633, 2.272378980117733],\n",
    "        [4.179540206172764, 2.615786698404636, 3.36235456621979]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def apply_convolution(data, kernel, bias):\n",
    "    \"\"\"\n",
    "    data - InLen x InChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns OutLen x OutChannels\n",
    "    \"\"\"\n",
    "    data = np.asarray(data)\n",
    "    kernel = np.asarray(kernel)\n",
    "    bias = np.asarray(bias)\n",
    "    \n",
    "    kernel_size = kernel.shape[2]\n",
    "    \n",
    "    out_channels = kernel.shape[0]\n",
    "    output_len = data.shape[0] - kernel_size + 1\n",
    "    print(f'Output len: {output_len}, out channels: {out_channels}')\n",
    "    \n",
    "    output = np.zeros(shape=(output_len, out_channels))\n",
    "\n",
    "    for kernel_i, ker in enumerate(kernel):\n",
    "        for i in range(output_len):\n",
    "            output[i:kernel_size+i, kernel_i] = bias[kernel_i] + np.sum(data[i:kernel_size+i, :] * ker.T)\n",
    "    return output\n",
    "\n",
    "\n",
    "result = apply_convolution(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c631789",
   "metadata": {},
   "source": [
    "## 3.8.2\n",
    "\n",
    "–í—ã –ø—Ä–∏–º–µ–Ω—è–µ—Ç–µ —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –∫ –¥–∞–Ω–Ω—ã–º: $y = convolve(x, kernel, bias)$, –≥–¥–µ $x \\in \\mathbb{R}^{InLen \\times InChannels}$ - –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, $kernel \\in \\mathbb{R}^{OutChannels \\times InChannels \\times KernelSize}$ - —è–¥—Ä–æ —Å–≤—ë—Ä—Ç–∫–∏, $bias \\in \\mathbb{R}^{OutChannels}$ - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–¥–≤–∏–≥–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ —è–¥—Ä—É —Å–≤—ë—Ä—Ç–∫–∏: $\\frac{\\partial y} {\\partial kernel}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80907162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.43015332, 3.25308579, 3.39093181],\n",
       "        [1.89280476, 1.69317539, 1.67862206],\n",
       "        [2.64302071, 2.89671496, 3.49165859]],\n",
       "\n",
       "       [[2.43015332, 3.25308579, 3.39093181],\n",
       "        [1.89280476, 1.69317539, 1.67862206],\n",
       "        [2.64302071, 2.89671496, 3.49165859]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.1559846921787793, 0.31890243279158936, 0.4294841981370352],\n",
    "        [0.6287087193276831, 0.041166388481120975, 0.0670771539905104],\n",
    "        [0.15852860049868056, 0.5535509628878403, 0.7578893631796608],\n",
    "        [0.505354018460584, 0.39104507392557886, 0.267830936523598],\n",
    "        [0.35352084058390487, 0.09557605719492113, 0.17762289879326898],\n",
    "        [0.17895124947325458, 0.2038143268404633, 0.45431038892117714],\n",
    "        [0.44910520386366004, 0.28874952266426823, 0.48880576852948343],\n",
    "        [0.978917156152191, 0.11927306276379035, 0.6831784491543058], \n",
    "        [0.7665547409895508, 0.02661305420346527, 0.662020788170643]\n",
    "    ],\n",
    "    [\n",
    "        [0.9423069699375323, 2.235723993887441],\n",
    "        [1.051430354504024, 2.5441990558270864],\n",
    "        [1.3060781439427196, 2.77617352972661],\n",
    "        [1.1097986223660692, 2.019161891632857],\n",
    "        [0.8312656308401454, 2.1968468090151005],\n",
    "        [1.0883546513743934, 3.182136137325698],\n",
    "        [1.4545203460970286, 3.3294233853738975]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [0.7285150274194675, 0.13990616439149894, 0.08385531710791316],\n",
    "            [0.8119118106104425, 0.19272155988045991, 0.010762309371285528],\n",
    "            [0.5242309485683324, 0.33106798748722055, 0.2219888201243384]\n",
    "        ],\n",
    "        [\n",
    "            [0.31261137319823096, 0.3951341806652614, 0.954412244770657],\n",
    "            [0.5475239344122861, 0.6407966544293683, 0.2840031545245296],\n",
    "            [0.9267337670407934, 0.626334029479077, 0.4315268897320006]\n",
    "        ]\n",
    "    ],\n",
    "    [0.03900532471824536, 0.6619593919342232]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [\n",
    "            [2.4301533243865463, 3.253085788359958, 3.3909318100218258],\n",
    "            [1.8928047647857822, 1.6931753947579833, 1.6786220604803275],\n",
    "            [2.643020708074734, 2.8967149590920043, 3.491658593272137]\n",
    "        ],\n",
    "        [\n",
    "            [2.4301533243865463, 3.253085788359958, 3.3909318100218258],\n",
    "            [1.8928047647857822, 1.6931753947579833, 1.6786220604803275],\n",
    "            [2.643020708074734, 2.8967149590920043, 3.491658593272137]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def calculate_kernel_grad(x, y, kernel, bias):\n",
    "    \"\"\"\n",
    "    x - InLen x InChannels\n",
    "    y - OutLen x OutChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns OutChannels x InChannels x KernelSize\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    kernel = np.asarray(kernel)\n",
    "    bias = np.asarray(bias)\n",
    "    \n",
    "    dy_dkernel = np.zeros(shape=kernel.shape)\n",
    "    \n",
    "    kernel_size = kernel.shape[2]\n",
    "    output_len = y.shape[0]\n",
    "    \n",
    "    for kernel_i, ker in enumerate(kernel):\n",
    "        helper = np.zeros(shape=ker.T.shape)\n",
    "        for i in range(output_len):\n",
    "            helper += x[i:kernel_size+i, :]\n",
    "        dy_dkernel[kernel_i] = helper.T\n",
    "    \n",
    "    return dy_dkernel\n",
    "\n",
    "result = calculate_kernel_grad(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df183319",
   "metadata": {},
   "source": [
    "## 3.8.3\n",
    "\n",
    "–í—ã –ø—Ä–∏–º–µ–Ω—è–µ—Ç–µ —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –∫ –¥–∞–Ω–Ω—ã–º: $y = convolve(x, kernel, bias)$, –≥–¥–µ $x \\in \\mathbb{R}^{InLen \\times InChannels}$ - –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, $kernel \\in \\mathbb{R}^{OutChannels \\times InChannels \\times KernelSize}$ - —è–¥—Ä–æ —Å–≤—ë—Ä—Ç–∫–∏, $bias \\in \\mathbb{R}^{OutChannels}$ - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–¥–≤–∏–≥–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞.\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ –≤—Ö–æ–¥—É: $\\frac{\\partial y} {\\partial x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf9729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.37587508, 1.7854909 ],\n",
       "       [3.07784576, 3.30512337],\n",
       "       [4.02259241, 5.40859579],\n",
       "       [4.02259241, 5.40859579],\n",
       "       [4.02259241, 5.40859579],\n",
       "       [4.02259241, 5.40859579],\n",
       "       [2.64671733, 3.62310489],\n",
       "       [0.94474666, 2.10347242]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.5031766517322117, 0.30744410216949514],\n",
    "        [0.04690208449415345, 0.322727131626243],\n",
    "        [0.1388690574185909, 0.48576543724022325],\n",
    "        [0.5260018011862109, 0.5859221562109312], \n",
    "        [0.9194272143904142, 0.3887293155713266],\n",
    "        [0.26873714217871125, 0.9546207791313607],\n",
    "        [0.8974007607375208, 0.5713329992292489], \n",
    "        [0.378989716528242, 0.49787928388753266]\n",
    "    ],\n",
    "    [\n",
    "        [1.5157583762374225, 0.9460413662192456, 0.9802340338281511],\n",
    "        [1.5728362445918327, 0.996409724139607, 1.2530013664472253],\n",
    "        [1.9068174476481374, 1.430592927945995, 1.6704630594015581],\n",
    "        [2.189768979209843, 2.3149543871163503, 2.1601629609824995],\n",
    "        [2.8353457102707083, 1.7422359297539565, 1.816707087141475],\n",
    "        [2.0532913525958474, 1.9924093441385802, 2.3069493556139014]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [0.8077620147648772, 0.006392942850116379, 0.6080212915877307],\n",
    "            [0.6288229869798402, 0.6410664904844843, 0.75419330562945]\n",
    "        ],\n",
    "        [\n",
    "            [0.5355186530459589, 0.9211024178840701, 0.27725553497982014],\n",
    "            [0.4507098181629161, 0.081570594016668, 0.8234980185346139]\n",
    "        ],\n",
    "        [\n",
    "            [0.0325944131753374, 0.7744753133142763, 0.05946983249285043],\n",
    "            [0.7059580971549311, 0.7969953841197822, 0.5257810951530107]\n",
    "        ]\n",
    "    ],\n",
    "    [0.2579976950685653, 0.029957050945287222, 0.18958928880952108]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [1.3758750809861735, 1.7854909022976875],\n",
    "        [3.0778457550346365, 3.305123370918622],\n",
    "        [4.022592414095037, 5.4085957902356965],\n",
    "        [4.022592414095037, 5.4085957902356965],\n",
    "        [4.022592414095037, 5.4085957902356965],\n",
    "        [4.022592414095037, 5.4085957902356965],\n",
    "        [2.646717333108864, 3.623104887938009],\n",
    "        [0.9447466590604012, 2.1034724193170744]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def calculate_conv_x_grad(x, y, kernel, bias):\n",
    "    \"\"\"\n",
    "    x - InLen x InChannels\n",
    "    y - OutLen x OutChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns InLen x InChannels\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    kernel = np.asarray(kernel)\n",
    "    bias = np.asarray(bias)\n",
    "    \n",
    "    dy_dx = np.zeros(shape=x.shape)\n",
    "    \n",
    "    kernel_size = kernel.shape[2]\n",
    "    output_len = y.shape[0]\n",
    "    \n",
    "    for kernel_i, ker in enumerate(kernel):\n",
    "        for i in range(output_len):\n",
    "            dy_dx[i:kernel_size+i, :] += ker.T\n",
    "    \n",
    "    return dy_dx\n",
    "\n",
    "result = calculate_conv_x_grad(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e36e38",
   "metadata": {},
   "source": [
    "### –ó–∞–º–µ—Ç–∫–∞\n",
    "\n",
    "–í –ø—Ä–æ—à–ª—ã—Ö –¥–≤—É—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –≥–ª–∞–≤–Ω–æ–µ —É—á–µ—Å—Ç—å —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —è–¥—Ä–æ –∏–ª–∏ i,j —ç–ª–µ–º–µ–Ω—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –Ω—É–∂–Ω–æ —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å, –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–ª—É—á–∞–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª—å–∫–æ —Ä–∞–∑, —Å–∫–æ–ª—å–∫–æ –≤ –¥–∞–Ω–Ω–æ–º i,j —ç–ª–µ–º–µ–Ω—Ç–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –¥–æ–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞ —è–¥—Ä–æ –ø—Ä–∏ –ø—Ä—è–º–æ–º –ø—Ä–æ—Ö–æ–¥–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4308287",
   "metadata": {},
   "source": [
    "## 3.8.4\n",
    "\n",
    "–í—ã —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å, —Å–æ—Å—Ç–æ—è—â—É—é –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–≤—ë—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—ë–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:\n",
    "\n",
    " - $kernel >= 1, kernel \\% 2 == 1$ - —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ —Å–≤—ë—Ä—Ç–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–µ—á—ë—Ç–Ω—ã–π)\n",
    " - $dilation >= 1$ - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏—è –∏–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –ø–æ–∑–∏—Ü–∏—è–º–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —É—á–∏—Ç—ã–≤–∞–µ–º—ã—Ö –æ–¥–Ω–æ–π —Å–≤—ë—Ä—Ç–∫–æ–π (–µ—Å–ª–∏ dilation = 1, —Ç–æ —ç—Ç–æ \"–ø–ª–æ—Ç–Ω–∞—è\" —Å–≤—ë—Ä—Ç–∫–∞, –µ—Å–ª–∏ dilation = 2, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –≤—Ç–æ—Ä–æ–π —ç–ª–µ–º–µ–Ω—Ç)\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —à–∏—Ä–∏–Ω—ã —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–ª—è - –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (+1), –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è—é—Ç –Ω–∞ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —ç–ª–µ–º–µ–Ω—Ç –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b0a23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import sys\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "kernels, dilations = [9, 9, 3], [2, 3, 4]\n",
    "sample_output = 49\n",
    "\n",
    "LayerInfo = collections.namedtuple('LayerInfo', ('kernel_size', 'dilation'))\n",
    "\n",
    "\n",
    "def calculate_receptive_field(layers):\n",
    "    \"\"\"\n",
    "    layers - list of LayerInfo\n",
    "\n",
    "    returns int - receptive field size\n",
    "    \"\"\"\n",
    "    r_out = 1 + layers[0].dilation * (layers[0].kernel_size - 1)\n",
    "    for i in range(1, len(layers)):\n",
    "        r_out = r_out + layers[i].dilation * (layers[i].kernel_size - 1)\n",
    "    return r_out\n",
    "\n",
    "\n",
    "layers = [LayerInfo(k, d) for k, d in zip(kernels, dilations)]\n",
    "print(layers[0].dilation)\n",
    "\n",
    "result = calculate_receptive_field(layers)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc0754d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12527.829399838527"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.1 ** 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9dd0a3",
   "metadata": {},
   "source": [
    "## 4.4 –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838cbebc",
   "metadata": {},
   "source": [
    "–í—Å–ø–æ–º–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é —Ñ–æ—Ä–º—É–ª—É –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∑–∞–¥–∞—á–∏ —Å –≥–ª–æ–±–∞–ª—å–Ω—ã–º avg-–ø—É–ª–∏–Ω–≥–æ–º:\n",
    "\n",
    " \n",
    "$avg(Input) = \\frac{1}{k} \\sum_{i=0}^{k-1} Input[i]$\n",
    "\n",
    "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏, –æ—Å–Ω–æ–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è –æ—Ç avg-–ø—É–ª–∏–Ω–≥–∞ - –Ω–∞–ª–∏—á–∏–µ –≤–µ—Å–æ–≤ –ø—Ä–∏ —Å–ª–∞–≥–∞–µ–º—ã—Ö: \n",
    "$Attention[Ch] = \\sum_{i=0}^{InLen-1} AttScores[i] \\cdot Input[i,Ch]$\n",
    "\n",
    "–≥–¥–µ $Input \\in \\mathbb{R} ^ {InLen \\times EmbSize}$ - –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, $Ch$ - –Ω–æ–º–µ—Ä —Å—Ç–æ–ª–±—Ü–∞ (–Ω–æ–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–∞), $AttScores[i]$ - –æ—Ü–µ–Ω–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –¥–ª—è i-–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ($AttScores \\in \\mathbb{R}^{InLen}$, $0 \\le AttScores[i] \\le 1$).\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–∏—Ç–µ –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –∫ –≤—Ö–æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ\n",
    "\n",
    "$Input = \\left( \\begin{matrix} 1 & 0 & 2 \\\\ 0 & 1 & 3 \\\\ 1 & 3 & 0 \\\\ 0 & 0 & 0\\end{matrix} \\right) \\in \\mathbb{R} ^ {InLen \\times EmbSize}$\n",
    "\n",
    "—Å —É—á—ë—Ç–æ–º –æ—Ü–µ–Ω–æ–∫ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ $AttScores = \\left( \\begin{matrix} 0.1 & 0.5 & 0.3 & 0.1 \\end{matrix} \\right)$\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ, —ç–ª–µ–º–µ–Ω—Ç—ã —Ä–∞–∑–¥–µ–ª—è–π—Ç–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c8d72f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 1.4, 1.7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 2],\n",
    "    [0, 1, 3],\n",
    "    [1, 3, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "attention = np.array([[0.1, 0.5, 0.3, 0.1]])\n",
    "\n",
    "np.sum(input_matrix * attention.T, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5970a0",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Å–∫–∞–ª—è—Ä–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º-–∑–∞–ø—Ä–æ—Å–æ–º.\n",
    "\n",
    "–ö–∞–∫ –∏ —Ä–∞–Ω—å—à–µ, $Input \\in \\mathbb{R} ^ {InLen \\times EmbSize}$ - –≤—Ö–æ–¥–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞.\n",
    "\n",
    "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å —Å –ø–æ–º–æ—â—å—é –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è $UnnormScores = Input \\cdot Query$, –≥–¥–µ $Query \\in \\mathbb{R}^{EmbSize}$ - –≤–µ–∫—Ç–æ—Ä-–∑–∞–ø—Ä–æ—Å, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–∏–π –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –¢–æ–≥–¥–∞ $UnnormScores \\in \\mathbb{R}^{InLen}$ - –≤–µ–∫—Ç–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–µ–π —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—á–µ–º –±–æ–ª—å—à–µ $UnnormScores[i]$, —Ç–µ–º –∑–Ω–∞—á–∏–º–µ–µ i-—ã–π —ç–ª–µ–º–µ–Ω—Ç).\n",
    "\n",
    "–ó–∞—Ç–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–æ—Ä–º–∏—Ä—É—é—Ç: $AttScores = Softmax(UnnormScores)$.\n",
    "\n",
    "–ù—É –∏ –Ω–∞–∫–æ–Ω–µ—Ü, —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–Ω–∏–º–∞–Ω–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∑–∞–¥–∞—á–∏ $Attention[Ch] = \\sum_{i=0}^{InLen-1} Input[i,Ch] \\cdot AttScores[i]$\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–∏—Ç–µ –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –∫ –≤—Ö–æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ\n",
    "\n",
    "$Input = \\left( \\begin{matrix} 1 & 0 & 2 \\\\ 0 & 1 & 3 \\\\ 1 & 3 & 0 \\\\ 0 & 0 & 0\\end{matrix} \\right)$\n",
    " \n",
    "—Å —É—á—ë—Ç–æ–º –≤–µ–∫—Ç–æ—Ä–∞-–∑–∞–ø—Ä–æ—Å–∞ $Query = \\left( \\begin{matrix} 0 & 0 & 1 \\end{matrix} \\right)$\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ, —ç–ª–µ–º–µ–Ω—Ç—ã —Ä–∞–∑–¥–µ–ª—è–π—Ç–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É. –ß–∏—Å–ª–∞ –æ–∫—Ä—É–≥–ª–∏—Ç–µ –¥–æ –Ω–µ –º–µ–Ω–µ–µ —á–µ–º –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3215852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28 0.78 2.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 2],\n",
    "    [0, 1, 3],\n",
    "    [1, 3, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "\n",
    "def softmax(z, axis=1):\n",
    "    if axis == 1:\n",
    "        exp_sum = np.sum(np.exp(z), axis=1).reshape(-1, 1)\n",
    "    elif axis == 0:\n",
    "        exp_sum = np.sum(np.exp(z), axis=0)\n",
    "    else:\n",
    "        exp_sum = np.sum(np.exp(z))\n",
    "    return np.exp(z) / exp_sum\n",
    "\n",
    "query = np.array([0, 0, 1])\n",
    "unnorm_scores = input_matrix.dot(query)\n",
    "attention = softmax(unnorm_scores[np.newaxis, :])\n",
    "\n",
    "result = np.sum(input_matrix * attention.T, axis=0)\n",
    "\n",
    "print(f' '.join(map(str, np.round(result, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e28a01",
   "metadata": {},
   "source": [
    "## 4.5 –ú–µ—Ö–∞–Ω–∏–∑–º —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5849f",
   "metadata": {},
   "source": [
    "–ú–µ—Ö–∞–Ω–∏–∑–º self-attention –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É $Input \\in \\mathbb{R} ^ {InLen \\times EmbSize}$, –≥–¥–µ $InLen$ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∞ $EmbSize$ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞.\n",
    "\n",
    "–ù–∞–π–¥–∏—Ç–µ –º–∞—Ç—Ä–∏—Ü—É –ø–æ–ø–∞—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ $Logits=Input \\cdot Input^T$\n",
    "\n",
    "–í—Ö–æ–¥–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –∏–º–µ–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π –≤–∏–¥\n",
    "\n",
    "$Input = \\left( \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\\\ 0 & 0\\end{matrix} \\right)$\n",
    " \n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –º–∞—Ç—Ä–∏—Ü—ã, –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ - —ç–ª–µ–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –º–∞—Ç—Ä–∏—Ü—ã, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏.\n",
    "\n",
    "–ù—É–∂–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤ numpy, –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é dot –∏–ª–∏ matmul, –∞ —Ç–∞–∫–∂–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ —É–º–Ω–æ–∂–µ–Ω–∏—è a @ b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c5ea59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [1, 1, 2, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_matrix = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "logits = input_matrix.dot(input_matrix.T)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac538259",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É—è –º–∞—Ç—Ä–∏—Ü—É $Logits$, –ø–æ–ª—É—á–µ–Ω–Ω—É—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Ä–µ—à–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∑–∞–¥–∞—á–∏, –Ω–∞–π–¥–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É $Result \\in \\mathbb{R}^{InLen \\times EmbSize}$ –¥–ª—è –º–µ—Ö–∞–Ω–∏–∑–º–∞ self-attention.\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ\n",
    "\n",
    " - –º–∞—Ç—Ä–∏—Ü—É $Logits$ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é softmax –ø–æ —Å—Ç—Ä–æ–∫–∞–º $AttScores = softmax(Logits, rows)$, –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ $0 \\leq AttScores[i,j] \\leq 1$ –∏ $\\sum_{j=0}^{InLen-1} AttScores[i, j] = 1$\n",
    " - –Ω–∞–π—Ç–∏ –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —É—á—ë—Ç–æ–º –Ω–∞–π–¥–µ–Ω—ã—Ö –≤–µ—Å–æ–≤: $Result=AttScores \\cdot Input$ (—Å –ø–æ–º–æ—â—å—é –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è)\n",
    " \n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –º–∞—Ç—Ä–∏—Ü—ã, –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ - —ç–ª–µ–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –º–∞—Ç—Ä–∏—Ü—ã, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É. –û—Ç–≤–µ—Ç –æ–∫—Ä—É–≥–ª–∏—Ç–µ –¥–æ –Ω–µ –º–µ–Ω–µ–µ —á–µ–º –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56ed1dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73 0.5 0.5 0.73 0.73 0.73 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "attscore = softmax(logits, axis=1)\n",
    "result = attscore.dot(input_matrix)\n",
    "print(' '.join(map(str, np.round(result.ravel(), 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53347648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73105858, 0.5       ],\n",
       "       [0.5       , 0.73105858],\n",
       "       [0.73105858, 0.73105858],\n",
       "       [0.5       , 0.5       ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e6dbb",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ —Ç–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–æ–ª–µ–µ –æ–±—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç self-attention - –∫–æ–≥–¥–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–ª—é—á–µ–π, –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã.\n",
    "\n",
    "–ù–∞ –≤—Ö–æ–¥ –º—ã –ø–æ–ª—É—á–∞–µ–º –≤—Å—ë —Ç—É –∂–µ –º–∞—Ç—Ä–∏—Ü—É\n",
    "\n",
    "$Input = \\left( \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\\\ 0 & 0\\end{matrix} \\right)$\n",
    "\n",
    "–û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö —à–∞–≥–æ–≤:\n",
    "\n",
    "- –ù–∞–π—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –∫–ª—é—á–µ–π, –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—è –ª–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ \n",
    "\n",
    "$Keys = Input \\cdot Proj_K + Bias_K$\n",
    "\n",
    "$Queries = Input \\cdot Proj_Q + Bias_Q$\n",
    "\n",
    "$Values = Input \\cdot Proj_V + Bias_V$\n",
    "\n",
    "- –ù–∞–π—Ç–∏ –º–∞—Ç—Ä–∏—Ü—É –ø–æ–ø–∞—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞, –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—á–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∫–ª—é—á–µ–π \n",
    "\n",
    "$Logits=Queries \\cdot Keys^T$\n",
    "\n",
    "- –ù–∞–π—Ç–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è, –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–≤ –º–∞—Ç—Ä–∏—Ü—É –ø–æ–ø–∞—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å –ø–æ–º–æ—â—å—é softmax –ø–æ —Å—Ç—Ä–æ–∫–∞–º\n",
    "\n",
    "$AttScores = softmax(Logits, rows)$\n",
    "\n",
    "- –ù–∞–π—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–æ–º–æ—â—å—é –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü –∑–Ω–∞—á–µ–Ω–∏–π –∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ \n",
    "\n",
    "$Result=AttScores \\cdot Values$\n",
    "\n",
    "–í–∞–º —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞–π—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã $Result \\in \\mathbb{R}^{InLen \\times EmbSize}$ —Å —É—á—ë—Ç–æ–º —Å–ª–µ–¥—É—é—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
    "\n",
    "$Proj_K = \\left(\\begin{matrix}1 & 0 \\\\ 0 & 0\\end{matrix} \\right)$\n",
    "\n",
    "$Proj_Q = \\left(\\begin{matrix}0 & 0 \\\\ 1 & 0\\end{matrix} \\right)$\n",
    "\n",
    "$Proj_V = \\left(\\begin{matrix}1 & 0 \\\\ 0 & 1\\end{matrix} \\right)$\n",
    "\n",
    "$Bias_K = Bias_Q = Bias_V = \\left(\\begin{matrix}0 & 0\\end{matrix}\\right)$\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –º–∞—Ç—Ä–∏—Ü—ã, –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ - —ç–ª–µ–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –º–∞—Ç—Ä–∏—Ü—ã, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É. –û—Ç–≤–µ—Ç –æ–∫—Ä—É–≥–ª–∏—Ç–µ –¥–æ –Ω–µ –º–µ–Ω–µ–µ —á–µ–º –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2c77c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.5       ]\n",
      " [0.73105858 0.5       ]\n",
      " [0.73105858 0.5       ]\n",
      " [0.5        0.5       ]]\n",
      "0.5 0.5 0.73 0.5 0.73 0.5 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_matrix = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "proj_k = np.array([\n",
    "    [1, 0],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "proj_q = np.array([\n",
    "    [0, 0],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "proj_v = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "])\n",
    "\n",
    "bias_k = np.array([0, 0])\n",
    "bias_q = np.array([0, 0])\n",
    "bias_v = np.array([0, 0])\n",
    "\n",
    "keys = input_matrix.dot(proj_k) + bias_k\n",
    "queries = input_matrix.dot(proj_q) + bias_q\n",
    "values = input_matrix.dot(proj_v) + bias_v\n",
    "\n",
    "logits = queries.dot(keys.T)\n",
    "attscore = softmax(logits, axis=1)\n",
    "\n",
    "result = attscore.dot(values)\n",
    "print(result)\n",
    "print(' '.join(map(str, np.round(result.ravel(), 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c67b7",
   "metadata": {},
   "source": [
    "–ï—â—ë –æ–¥–∏–Ω —à–∞–≥ - –ø–µ—Ä–µ–π–¥—ë–º –æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ self-attention –∫ multihead self-attention.\n",
    "\n",
    "–û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º - —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ –∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∑–∞–¥–∞—á–µ. –û—Ç–ª–∏—á–∏–µ –≤ —Ç–æ–º, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π $Result^i = SelfAttention(Input, Proj^i_K, Proj^i_Q, Proj^i_V)$, $Result^i \\in \\mathbb{R}^{InLen \\times \\frac{EmbSize} {HeadsN}}$\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç $MHResult \\in \\mathbb{R} ^ {InLen \\times EmbSize}$ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–µ–π $Result^i$ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º: $MHResult = \\left[ Result^1, Result^2, ..., Result^{HeadsN} \\right]$\n",
    "\n",
    "**–í–∞–º —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞–π—Ç–∏ $MHResult$ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**\n",
    "\n",
    "$Input = \\left( \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\\\ 0 & 0\\end{matrix} \\right)$\n",
    " \n",
    "**—Å —É—á—ë—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ \"–≥–æ–ª–æ–≤\" $HeadsN = 2$ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π**\n",
    "\n",
    "$Proj^1_K = \\left(\\begin{matrix}1 & 0 \\\\ 0 & 0\\end{matrix} \\right)$,\n",
    "\n",
    "$Proj^2_K = \\left(\\begin{matrix}0 & 0 \\\\ 1 & 0\\end{matrix} \\right)$,\n",
    "\n",
    "$Proj^1_Q = \\left(\\begin{matrix}0 & 1 \\\\ 1 & 0\\end{matrix} \\right)$,\n",
    "\n",
    "$Proj^2_Q = \\left(\\begin{matrix}1 & 1 \\\\ 1 & 1\\end{matrix} \\right)$,\n",
    "\n",
    "$Proj^1_V = \\left(\\begin{matrix}1 \\\\ 0\\end{matrix} \\right)$,\n",
    "\n",
    "$Proj^2_V = \\left(\\begin{matrix}0 \\\\ 1\\end{matrix} \\right)$\n",
    "\n",
    "$Bias^i_K = Bias^i_Q = \\left(\\begin{matrix}0 & 0\\end{matrix}\\right), \\quad Bias^i_V = 0$\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –º–∞—Ç—Ä–∏—Ü—ã, –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ - —ç–ª–µ–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –º–∞—Ç—Ä–∏—Ü—ã, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–∫—É. –û—Ç–≤–µ—Ç –æ–∫—Ä—É–≥–ª–∏—Ç–µ –¥–æ –Ω–µ –º–µ–Ω–µ–µ —á–µ–º –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1a1fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.73105858]\n",
      " [0.73105858 0.73105858]\n",
      " [0.73105858 0.88079708]\n",
      " [0.5        0.5       ]]\n",
      "0.5 0.73 0.73 0.73 0.73 0.88 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 2\n",
    "\n",
    "input_matrix = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "proj_k = (\n",
    "    np.array([\n",
    "        [1, 0],\n",
    "        [0, 0]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0, 0],\n",
    "        [1, 0]\n",
    "    ])\n",
    ")\n",
    "\n",
    "proj_q = (\n",
    "    np.array([\n",
    "        [0, 1],\n",
    "        [1, 0]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [1, 1],\n",
    "        [1, 1]\n",
    "    ])\n",
    ")\n",
    "\n",
    "proj_v = (\n",
    "    np.array([\n",
    "        [1],\n",
    "        [0]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0],\n",
    "        [1]\n",
    "    ])\n",
    ")\n",
    "\n",
    "bias_k = (\n",
    "    np.array([0, 0]),\n",
    "    np.array([0, 0])\n",
    ")\n",
    "\n",
    "bias_q = (\n",
    "    np.array([0, 0]),\n",
    "    np.array([0, 0])\n",
    ")\n",
    "\n",
    "bias_v = (0, 0)\n",
    "\n",
    "result = []\n",
    "for i in range(N):\n",
    "    keys = input_matrix.dot(proj_k[i]) + bias_k[i]\n",
    "    queries = input_matrix.dot(proj_q[i]) + bias_q[i]\n",
    "    values = input_matrix.dot(proj_v[i]) + bias_v[i]\n",
    "\n",
    "    logits = queries.dot(keys.T)\n",
    "    attscore = softmax(logits, axis=1)\n",
    "    \n",
    "    semiresult = attscore.dot(values)\n",
    "    result.append(semiresult)\n",
    "    \n",
    "result = np.concatenate(result, axis=1)\n",
    "\n",
    "print(result)\n",
    "print(' '.join(map(str, np.round(result.ravel(), 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952ab2a",
   "metadata": {},
   "source": [
    "## 4.7 –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã: –ú–æ–¥–µ–ª—å —è–∑—ã–∫–∞ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dce734",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, —Ä–µ–∞–ª–∏–∑—É—é—â—É—é max-pooling —Å –∑–∞–¥–∞–Ω–Ω–æ–π —à–∏—Ä–∏–Ω–æ–π –æ–∫–Ω–∞. –í –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ—Å–æ–±–∏—è –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [–¥—Ä—É–≥—É—é –∑–∞–¥–∞—á—É](https://stepik.org/lesson/262248/step/2?unit=243131).\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –¥–≤–∞ —Ç–µ–Ω–∑–æ—Ä–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ $OutLen \\times EmbSize$:\n",
    "\n",
    "- –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä - –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è max-–ø—É–ª–∏–Ω–≥–∞ –∫ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞\n",
    "- –≤—Ç–æ—Ä–æ–π —Ç–µ–Ω–∑–æ—Ä - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –Ω—É–∂–Ω–∞—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞, - –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –≤—Ö–æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã $\\left( \\begin{matrix}1 & 0 & 3 \\\\ 0 & 1 & 4\\end{matrix}\\right)$ –∏ —Ä–∞–∑–º–µ—Ä–∞ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ $k=2$ –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–∏–¥ $result = \\left(\\begin{matrix} 1 & 1 & 4 \\end{matrix}\\right)$, –∞ –≤—Ç–æ—Ä–æ–π \n",
    "$indices = \\left( \\begin{matrix} 0 & 1 & 1\\end{matrix} \\right)$. –ò–Ω–¥–µ–∫—Å—ã - –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ–∑–∏—Ü–∏–∏ –æ–∫–Ω–∞ (\n",
    "$0 \\leq indices_i < k$), –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª–∏ –≤–∑—è—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã $result$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da7fed8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.81061878, 0.43955079, 0.82900963, 0.20134328],\n",
       "        [0.93896452, 0.43955079, 0.82900963, 0.07860177],\n",
       "        [0.93896452, 0.64112871, 0.50925343, 0.70944414],\n",
       "        [0.69155288, 0.64112871, 0.50925343, 0.76312625]]),\n",
       " array([[1., 1., 1., 0.],\n",
       "        [1., 0., 0., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [1., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.6046018907385543, 0.0812964077275945, 0.6366439552273822, 0.20134327995534496],\n",
    "        [0.8106187774962709, 0.4395507898340978, 0.8290096270213004, 0.05773841312522798],\n",
    "        [0.938964520620817, 0.3860407857274528, 0.21318174478828456, 0.07860176987690048],\n",
    "        [0.04840110723428537, 0.6411287103553837, 0.509253427569025, 0.7094441369109541],\n",
    "        [0.691552879511939, 0.4979735285634219, 0.07060470682483455, 0.7631262538014161]\n",
    "    ],\n",
    "    2\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [0.8106187774962709, 0.4395507898340978, 0.8290096270213004, 0.20134327995534496],\n",
    "        [0.938964520620817, 0.4395507898340978, 0.8290096270213004, 0.07860176987690048],\n",
    "        [0.938964520620817, 0.6411287103553837, 0.509253427569025, 0.7094441369109541],\n",
    "        [0.691552879511939, 0.6411287103553837, 0.509253427569025, 0.7631262538014161]\n",
    "    ],\n",
    "    [\n",
    "        [1.0, 1.0, 1.0, 0.0],\n",
    "        [1.0, 0.0, 0.0, 1.0],\n",
    "        [0.0, 1.0, 1.0, 1.0],\n",
    "        [1.0, 0.0, 0.0, 1.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def max_pooling(features, kernel_size):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    kernel_size - positive integer - size of sliding window\n",
    "\n",
    "    returns tuple of two matrices of shape OutLen x EmbSize:\n",
    "         - output features (main result)\n",
    "         - relative indices of maximum elements for each position of sliding window\n",
    "    \"\"\"\n",
    "    features = np.asarray(features)\n",
    "    \n",
    "    out_len = features.shape[0] - kernel_size + 1\n",
    "    emb_size = features.shape[1]\n",
    "    \n",
    "    result = np.zeros((out_len, emb_size))\n",
    "    indices = np.zeros((out_len, emb_size))\n",
    "    \n",
    "    for i in range(out_len):\n",
    "        for j in range(emb_size):\n",
    "            result[i, j] = np.max(features[i:i+kernel_size, j])\n",
    "            indices[i, j] = np.argmax(features[i:i+kernel_size, j])\n",
    "    \n",
    "    return result, indices\n",
    "\n",
    "\n",
    "result, indices = max_pooling(*sample_input)\n",
    "\n",
    "result, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa2f0f",
   "metadata": {},
   "source": [
    "–ü—Ä—è–º–æ–º—É –ø—Ä–æ—Ö–æ–¥—É –ø–æ –º–æ–¥—É–ª—é max-–ø—É–ª–∏–Ω–≥–∞ –±—ã–ª–∞ –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –∑–∞–¥–∞—á–∞.\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –∑–∞–π–º—ë–º—Å—è –æ–±—Ä–∞—Ç–Ω—ã–º –ø—Ä–æ—Ö–æ–¥–æ–º: –Ω–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –≤—ã—á–∏—Å–ª—è—é—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–æ –≤—Ö–æ–¥–∞–º –º–æ–¥—É–ª—è max-–ø—É–ª–∏–Ω–≥–∞ $\\frac{\\partial Loss}{\\partial features}$.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã:\n",
    "\n",
    "- $features \\in \\mathbb{R}^{InLen \\times EmbSize}$ - –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥—É–ª—é –ø—Ä–∏ –ø—Ä—è–º–æ–º –ø—Ä–æ—Ö–æ–¥–µ\n",
    "- $2 \\leq kernel\\_size \\leq InLen$ - —Ä–∞–∑–º–µ—Ä —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞\n",
    "- $indices \\in \\mathbb{N}^{OutLen \\times EmbSize}, \\quad 0 \\leq indices < kernel\\_size$ - –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ (—Å–º–µ—â–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫–∏)\n",
    "- $dldout = \\frac{\\partial Loss} {\\partial out} \\in \\mathbb{R}^{OutLen \\times EmbSize}$ - –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–æ –≤—ã—Ö–æ–¥–∞–º —Å–ª–æ—è max-–ø—É–ª–∏–Ω–≥–∞ (—Ç–æ –µ—Å—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ –≤—Ö–æ–¥–∞–º —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—è)\n",
    "\n",
    "–í–∞–º –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π –∫—É—Å–æ—á–Ω–æ-–ª–∏–Ω–µ–π–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ \n",
    "$ReLU(x) = \\begin{cases} 0 & if \\quad x \\leq 0 \\\\ x & otherwise \\end{cases}$; $\\frac{\\partial ReLU(x)} {\\partial x} = \\begin{cases} 0 & if \\quad x \\leq 0 \\\\ 1 & otherwise \\end{cases}$\n",
    "\n",
    "–ê —Ç–∞–∫–∂–µ –ø–æ–º–Ω–∏—Ç–µ –ø—Ä–æ –ø—Ä–∞–≤–∏–ª–æ —Ü–µ–ø–æ—á–∫–∏: \n",
    "$\\frac{\\partial Loss} {\\partial features} = \\frac{\\partial Loss} {\\partial out} \\frac{\\partial out} {\\partial features}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6088d708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.74543372,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , -2.1273406 ,  0.        ,  0.        ],\n",
       "       [-0.0763792 ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -1.00156221, -2.50847038],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.90801897,  0.        ,  0.        ,  2.28032473],\n",
       "       [-0.77715291,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , -2.37105519,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [-1.2420542766989977, -0.045100789663994285, 1.858151857421511, 0.10732741246325356],\n",
    "        [-1.480497780371414, -0.12486054931133332, -0.18422425981847368, -1.4228130362490647],\n",
    "        [-0.8417536968892625, 0.9802583655274091, -0.18413492661665792, -1.5582607186399924],\n",
    "        [1.325799250424393, 0.08149768959330334, -1.454876921308986, 0.1408031456023352],\n",
    "        [0.1637602967235608, -0.21250114632967532, 0.8362859721448469, 0.717774697701287],\n",
    "        [-0.7641399532198978, -2.112568530488304, 0.20121440705964902, 0.015624280892385661],\n",
    "        [1.3862200103422582, 0.6508694196448389, -1.162417318743681, 1.5202488401790915],\n",
    "        [1.3947418297193952, -1.013483406336198, -2.0608332074129545, -1.733019236247151],\n",
    "        [1.0932612618870112, 0.8071262618398916, 0.15924519176972282, -0.6885825807454318]\n",
    "    ],\n",
    "    6,\n",
    "    [\n",
    "        [3.0, 2.0, 0.0, 4.0],\n",
    "        [5.0, 1.0, 3.0, 5.0],\n",
    "        [5.0, 0.0, 2.0, 4.0],\n",
    "        [4.0, 5.0, 1.0, 3.0]\n",
    "    ],\n",
    "    [\n",
    "        [-0.0763791951131031, -0.8729161683329371, 0.7454337173675266, -2.508470377801969],\n",
    "        [-0.9080189656976042, 0.6952579391985969, 0.2829942797947518, 0.35396918585149195],\n",
    "        [0.339009358836277, -1.9496823733556254, -0.11017174942549533, 1.4591363247582954],\n",
    "        [-1.1161622731011638, -2.371055190136431, -1.174384738333498, 0.4672192180206214]\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [0.0, 0.0, 0.7454337173675266, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, -2.1273406024899657, 0.0, 0.0],\n",
    "        [-0.0763791951131031, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, -1.0015622079642417, -2.508470377801969],\n",
    "        [0.0, 0.0, 0.0, 0.0],\n",
    "        [-0.9080189656976042, 0.0, 0.0, 2.2803247286304087],\n",
    "        [-0.7771529142648868, 0.0, 0.0, 0.0],\n",
    "        [0.0, -2.371055190136431, 0.0, 0.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def max_pooling_dldfeatures(features, kernel_size, indices, dldout):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    kernel_size - positive integer - size of sliding window\n",
    "    indices - OutLen x EmbSize - relative indices of maximum elements for each window position\n",
    "    dldout - OutLen x EmbSize - partial derivative of loss function with respect to outputs of max_pooling layer\n",
    "\n",
    "    returns InLen x EmbSize\n",
    "    \"\"\"\n",
    "    features = np.asarray(features)\n",
    "    indices = np.asarray(indices)\n",
    "    dldout = np.asarray(dldout)\n",
    "    \n",
    "    inlen, emb_size = features.shape\n",
    "    out_len = features.shape[0] - kernel_size + 1\n",
    "    \n",
    "    dldfeatures = np.zeros((inlen, emb_size))\n",
    "    \n",
    "    for i in range(out_len):\n",
    "        for j in range(emb_size):\n",
    "            index = int(indices[i, j])\n",
    "            dldfeatures[i:i+kernel_size, j][index] += dldout[i, j]\n",
    "    \n",
    "    return dldfeatures\n",
    "\n",
    "\n",
    "dldfeatures = max_pooling_dldfeatures(*sample_input)\n",
    "\n",
    "dldfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527ab2a",
   "metadata": {},
   "source": [
    "–í–µ–∫—Ç–æ—Ä-—Ñ—É–Ω–∫—Ü–∏—è \n",
    "$softmax(x) = \\left( \\begin{matrix} \\frac{e^{x_1}}{\\sum_j e^{x_j}} & ... & \\frac{e^{x_n}}{\\sum_j e^{x_j}} \\end{matrix} \\right)$ - –ø–æ–ø—É–ª—è—Ä–Ω—ã–π —Å–ø–æ—Å–æ–± –Ω–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª \n",
    "$x \\in \\mathbb{R}^n$ —Ç–∞–∫, —á—Ç–æ–±—ã $0 \\leq softmax_i(x) \\leq 1$ –∏ $\\sum_i softmax_i(x) = 1$\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –≤—ã—á–∏—Å–ª—è—é—â—É—é softmax –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞.\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç—É –∏–∑ numpy: np.exp(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "714b3194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06860598, 0.03703718, 0.06169052, 0.00699966, 0.02530594,\n",
       "       0.02723806, 0.04080633, 0.01926289, 0.18134764, 0.01644131,\n",
       "       0.00710907, 0.03555705, 0.03393158, 0.02671735, 0.03221016,\n",
       "       0.25362224, 0.02825008, 0.09786696])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        0.7903253367110061,\n",
    "        0.1738679257213426,\n",
    "        0.6840758121402977, \n",
    "        -1.4921922753864911,\n",
    "        -0.20701526564877176,\n",
    "        -0.13343908330179777,\n",
    "        0.27078275189785883, \n",
    "        -0.47987385916752834,\n",
    "        1.762361457920409,\n",
    "        -0.6382574781276095,\n",
    "        -1.476682298043406,\n",
    "        0.13308403857533435,\n",
    "        0.08629164346752129, \n",
    "        -0.15274120983311792,\n",
    "        0.03422761142701722,\n",
    "        2.0977915122558075, \n",
    "        -0.09695813983037735,\n",
    "        1.145554587286743\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        0.06860598204389033,\n",
    "        0.03703718180652343,\n",
    "        0.06169051603553571,\n",
    "        0.006999663809155501,\n",
    "        0.02530593948353462, \n",
    "        0.02723806143745914,\n",
    "        0.040806327204274295,\n",
    "        0.019262891730251305,\n",
    "        0.18134764032840614, \n",
    "        0.01644130749673833,\n",
    "        0.007109074723334883,\n",
    "        0.03555704949423753, \n",
    "        0.033931576448048006,\n",
    "        0.0267173505099923,\n",
    "        0.032210162471156406,\n",
    "        0.25362223807297396, \n",
    "        0.028250079060620836,\n",
    "        0.09786695784386741\n",
    "    ]\n",
    ")\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    x - vector of n elements - input\n",
    "\n",
    "    returns vector of n elements - softmax output\n",
    "    \"\"\"\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp, axis=0)\n",
    "\n",
    "result = softmax(sample_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba016c9",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, —Ä–µ–∞–ª–∏–∑—É—é—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é –≤—ã—Ö–æ–¥–∞ softmax –ø–æ –≤—Ö–æ–¥–∞–º $\\frac{\\partial softmax(x)} {\\partial x}$.\n",
    "\n",
    "–ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –∏ $softmax$ –∏ $x$ - –≤–µ–∫—Ç–æ—Ä–∞ –∏–∑ $n$ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è - —ç—Ç–æ –º–∞—Ç—Ä–∏—Ü–∞, –≤ ij-—è—á–µ–π–∫–µ –∫–æ—Ç–æ—Ä–æ–π —Å—Ç–æ–∏—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è i-–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ \n",
    "$softmax_i(x)$ –ø–æ j-–º—É –≤—Ö–æ–¥—É $x_j$ (i —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–æ–∫–∏, j - –Ω–æ–º–µ—Ä —Å—Ç–æ–ª–±—Ü–∞). –¢–∞–∫–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –µ—â—ë –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –º–∞—Ç—Ä–∏—Ü–µ–π –Ø–∫–æ–±–∏.\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤–æ–∑–º–æ–∂–Ω–æ, –±—É–¥–µ—Ç –ø—Ä–æ—â–µ —Ä–µ—à–∞—Ç—å —ç—Ç—É –∑–∞–¥–∞—á—É, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—è –¥–≤–∞ —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ $i=j$ –∏ –∫–æ–≥–¥–∞ $i \\neq j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cde8461c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_input = [\n",
    "    -0.36170314084137395,\n",
    "    1.531638983431016,\n",
    "    -1.7131284538840788,\n",
    "    -0.9027503682845508,\n",
    "    -0.8591376176087115,\n",
    "    0.16481576122888014,\n",
    "    0.2286590883015934,\n",
    "    0.4686776665093307,\n",
    "    -0.4880318948728026,\n",
    "    0.13865483857501165,\n",
    "    -1.0740873577508447,\n",
    "    -1.1693607815929845,\n",
    "    0.6388250392697977\n",
    "]\n",
    "\n",
    "sample_output = [\n",
    "    [\n",
    "        0.04520990642005896,\n",
    "        -0.01496136384662353,\n",
    "        -0.0005831584750616379,\n",
    "        -0.0013113823146393676, \n",
    "        -0.001369840806658998, \n",
    "        -0.0038138833133273915, \n",
    "        -0.004065315035397694,\n",
    "        -0.005168124298133092, \n",
    "        -0.0019853599968400696,\n",
    "        -0.0037154023993240717,\n",
    "        -0.0011048889071803723, \n",
    "        -0.0010044813810742047, \n",
    "        -0.006126705645798535\n",
    "    ],\n",
    "    [\n",
    "        -0.01496136384662353,\n",
    "        0.2158579197223101, \n",
    "        -0.0038730635991859903,\n",
    "        -0.008709582942971316, \n",
    "        -0.00909783668048341,\n",
    "        -0.02533001450562798, \n",
    "        -0.026999905439354373, \n",
    "        -0.03432424452555928,\n",
    "        -0.013185824889586901,\n",
    "        -0.024675950714133716,\n",
    "        -0.007338151103938566, \n",
    "        -0.006671291663363668, \n",
    "        -0.04069068981148138\n",
    "    ],\n",
    "    [\n",
    "        -0.0005831584750616379,\n",
    "        -0.0038730635991859903,\n",
    "        0.012135730472354804,\n",
    "        -0.0003394788843793973, \n",
    "        -0.0003546120941472776, \n",
    "        -0.000987303883778268,\n",
    "        -0.0010523922714690001,\n",
    "        -0.0013378776360475466,\n",
    "        -0.0005139521780146152, \n",
    "        -0.0009618100285956132, \n",
    "        -0.0002860237242683219, \n",
    "        -0.00026003112503520596,\n",
    "        -0.0015860265723719278\n",
    "    ],\n",
    "    [\n",
    "        -0.0013113823146393676,\n",
    "        -0.008709582942971316,\n",
    "        -0.0003394788843793973,\n",
    "        0.026866394590907443, \n",
    "        -0.0007974368009876185,\n",
    "        -0.0022202075554586314, \n",
    "        -0.0023665755911748154, \n",
    "        -0.003008563102643473, \n",
    "        -0.0011557540971131601,\n",
    "        -0.0021628780434165113, \n",
    "        -0.0006431981521542989,\n",
    "        -0.0005847470854143117,\n",
    "        -0.003566590020554541\n",
    "    ],\n",
    "    [\n",
    "        -0.001369840806658998, \n",
    "        -0.00909783668048341, \n",
    "        -0.0003546120941472776,\n",
    "        -0.0007974368009876185, \n",
    "        0.02802849045258695, \n",
    "        -0.0023191794450546825,\n",
    "        -0.002472072240600495, \n",
    "        -0.003142678120181134, \n",
    "        -0.0012072750310990093,\n",
    "        -0.0022592943115246175,\n",
    "        -0.0006718704879216859, \n",
    "        -0.000610813803292534,\n",
    "        -0.0037255806306354905\n",
    "    ],\n",
    "    [\n",
    "        -0.0038138833133273915,\n",
    "        -0.02533001450562798,\n",
    "        -0.000987303883778268,\n",
    "        -0.0022202075554586314,\n",
    "        -0.0023191794450546825,\n",
    "        0.07389852776941823, \n",
    "        -0.006882693975777504,\n",
    "        -0.008749781422376342,\n",
    "        -0.0033612709398950754,\n",
    "        -0.006290281931106346,\n",
    "        -0.0018706083437909523,\n",
    "        -0.0017006155464219198,\n",
    "        -0.010372686906803137\n",
    "    ],\n",
    "    [\n",
    "        -0.004065315035397694,\n",
    "        -0.026999905439354373,\n",
    "        -0.0010523922714690001,\n",
    "        -0.0023665755911748154,\n",
    "        -0.002472072240600495,\n",
    "        -0.006882693975777504,\n",
    "        0.07831657234824194, \n",
    "        -0.009326614122810346,\n",
    "        -0.0035828640174308843,\n",
    "        -0.006704971183060923, \n",
    "        -0.0019939289172219475, \n",
    "        -0.0018127292794043132,\n",
    "        -0.011056510274539641\n",
    "    ],\n",
    "    [\n",
    "        -0.005168124298133092, \n",
    "        -0.03432424452555928,\n",
    "        -0.0013378776360475466,\n",
    "        -0.003008563102643473,\n",
    "        -0.003142678120181134, \n",
    "        -0.008749781422376342, \n",
    "        -0.009326614122810346, \n",
    "        0.09703166928519828, \n",
    "        -0.004554797457063466,\n",
    "        -0.008523847275730119,\n",
    "        -0.002534827533934738,\n",
    "        -0.002304473368792744,\n",
    "        -0.014055840421926011\n",
    "    ],\n",
    "    [\n",
    "        -0.0019853599968400696, \n",
    "        -0.013185824889586901,\n",
    "        -0.0005139521780146152,\n",
    "        -0.0011557540971131601,\n",
    "        -0.0012072750310990093, \n",
    "        -0.0033612709398950754, \n",
    "        -0.0035828640174308843,\n",
    "        -0.004554797457063466, \n",
    "        0.040080235966119454, \n",
    "        -0.0032744772424536947,\n",
    "        -0.0009737662823977987,\n",
    "        -0.0008852746134293082,\n",
    "        -0.005399619220795473\n",
    "    ],\n",
    "    [\n",
    "        -0.0037154023993240717,\n",
    "        -0.024675950714133716,\n",
    "        -0.0009618100285956132,\n",
    "        -0.0021628780434165113,\n",
    "        -0.0022592943115246175, \n",
    "        -0.006290281931106346,\n",
    "        -0.006704971183060923,\n",
    "        -0.008523847275730119,\n",
    "        -0.0032744772424536947,\n",
    "        0.07215276857928996, \n",
    "        -0.001822306074344211,\n",
    "        -0.001656702778353048,\n",
    "        -0.010104846597247093\n",
    "    ],\n",
    "    [\n",
    "        -0.0011048889071803723, \n",
    "        -0.007338151103938566,\n",
    "        -0.0002860237242683219,\n",
    "        -0.0006431981521542989,\n",
    "        -0.0006718704879216859, \n",
    "        -0.0018706083437909523, \n",
    "        -0.0019939289172219475, \n",
    "        -0.002534827533934738, \n",
    "        -0.0009737662823977987,\n",
    "        -0.001822306074344211, \n",
    "        0.02273722712642639,\n",
    "        -0.0004926714055603228,\n",
    "        -0.003004986193713176\n",
    "    ],\n",
    "    [\n",
    "        -0.0010044813810742047,\n",
    "        -0.006671291663363668, \n",
    "        -0.00026003112503520596,\n",
    "        -0.0005847470854143117,\n",
    "        -0.000610813803292534, \n",
    "        -0.0017006155464219198, \n",
    "        -0.0018127292794043132, \n",
    "        -0.002304473368792744, \n",
    "        -0.0008852746134293082,\n",
    "        -0.001656702778353048,\n",
    "        -0.0004926714055603228, \n",
    "        0.020715738092779736,\n",
    "        -0.0027319060426381574\n",
    "    ],\n",
    "    [\n",
    "        -0.006126705645798535,\n",
    "        -0.04069068981148138, \n",
    "        -0.0015860265723719278,\n",
    "        -0.003566590020554541,\n",
    "        -0.0037255806306354905,\n",
    "        -0.010372686906803137, \n",
    "        -0.011056510274539641, \n",
    "        -0.014055840421926011,\n",
    "        -0.005399619220795473,\n",
    "        -0.010104846597247093,\n",
    "        -0.003004986193713176,\n",
    "        -0.0027319060426381574,\n",
    "        0.11242198833850454\n",
    "    ]\n",
    "]\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    x - vector of n elements - input\n",
    "\n",
    "    returns vector of n elements - softmax output\n",
    "    \"\"\"\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp, axis=0)\n",
    "\n",
    "def dsoftmax_dx(x):\n",
    "    \"\"\"\n",
    "    x - vector of n elements - input\n",
    "\n",
    "    returns matrix n x n\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    x_softmax = softmax(x)\n",
    "    grad = np.zeros(shape=(n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                grad[i, j] = x_softmax[j] * (1 - x_softmax[j])\n",
    "            else:\n",
    "                grad[i, j] = -x_softmax[i] * x_softmax[j]\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "result = dsoftmax_dx(sample_input)\n",
    "\n",
    "np.allclose(result, np.asarray(sample_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ccd77f",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, —Ä–µ–∞–ª–∏–∑—É—é—â—É—é –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è, –∫–∞–∫ –≤ [—ç—Ç–æ–π –∑–∞–¥–∞—á–µ](https://stepik.org/lesson/262248/step/10?unit=243131)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fda3685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47405818, 0.34432835, 0.46651675, 0.6711508 , 0.30149326,\n",
       "       0.52160135, 0.57392068, 0.50116642, 0.66594268, 0.58704035,\n",
       "       0.48456045, 0.55190928, 0.6631513 , 0.62031582, 0.67996142])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [\n",
    "            0.3504305689198156,\n",
    "            0.871844425624726,\n",
    "            0.29345316540775357,\n",
    "            0.49159320438393916,\n",
    "            0.16391992930609034, \n",
    "            0.24589641847050037,\n",
    "            0.34921020303336925,\n",
    "            0.09968814035867879,\n",
    "            0.8652385667745919,\n",
    "            0.00906484385602968,\n",
    "            0.6134586521086117,\n",
    "            0.08104312584086149,\n",
    "            0.643129733435556, \n",
    "            0.6610968673257929,\n",
    "            0.6825169003800382\n",
    "        ],\n",
    "        [\n",
    "            0.005641686042561211,\n",
    "            0.3397733866278605,\n",
    "            0.4408793722092307,\n",
    "            0.6618752692611525,\n",
    "            0.4192615374283991,\n",
    "            0.6718589897811911, \n",
    "            0.23503584107912667,\n",
    "            0.9972834040264165,\n",
    "            0.6907780153811639,\n",
    "            0.5160598448726361,\n",
    "            0.4200243418824855,\n",
    "            0.7745997472321381, \n",
    "            0.9124177261957108,\n",
    "            0.627661131744206,\n",
    "            0.7792319239076758\n",
    "        ],\n",
    "        [\n",
    "            0.44947044223343224,\n",
    "            0.39851993627332394,\n",
    "            0.27645205987950927,\n",
    "            0.3360502940952873, \n",
    "            0.20207394761469466,\n",
    "            0.27730469648938627,\n",
    "            0.9647449489128369,\n",
    "            0.38480306917172535,\n",
    "            0.7014748335636187, \n",
    "            0.5616919724157547,\n",
    "            0.3082991954077743,\n",
    "            0.43320540280287834,\n",
    "            0.7682716834674514, \n",
    "            0.04669826413239708,\n",
    "            0.7975639937877288\n",
    "        ],\n",
    "        [\n",
    "            0.3529089999231677,\n",
    "            0.5085801437940869,\n",
    "            0.6686697864089949,\n",
    "            0.9579051761714787,\n",
    "            0.14893344048972235,\n",
    "            0.6504801381978066,\n",
    "            0.6554087909852483,\n",
    "            0.2182290972559655,\n",
    "            0.8874805349214916,\n",
    "            0.8549111586624765,\n",
    "            0.2256959432511686,\n",
    "            0.7090739886051667, \n",
    "            0.9215898392742404,\n",
    "            0.8361038069049278, \n",
    "            0.9807575571901945\n",
    "        ],\n",
    "        [\n",
    "            0.93096165894251,\n",
    "            0.21204415175966806,\n",
    "            0.005393301311816812,\n",
    "            0.6868163541395496, \n",
    "            0.17651743121260177,\n",
    "            0.4276211882347165,\n",
    "            0.7172630747046246, \n",
    "            0.6222321154458413,\n",
    "            0.782866044726867,\n",
    "            0.9401403417712956,\n",
    "            0.6009251310321828,\n",
    "            0.7689712777389628,\n",
    "            0.011137370287858661,\n",
    "            0.6750220130270511,\n",
    "            0.3656918897133191\n",
    "        ],\n",
    "        [\n",
    "            0.344423832576648,\n",
    "            0.5200078573131781, \n",
    "            0.08090528060543856,\n",
    "            0.6187002344784092,\n",
    "            0.24428489996011238,\n",
    "            0.18400539459399,\n",
    "            0.40308101020726217,\n",
    "            0.19255989698913867, \n",
    "            0.8010944590934469,\n",
    "            0.20324438899818598, \n",
    "            0.4927144298170735, \n",
    "            0.03783988662477278,\n",
    "            0.7705093963091103, \n",
    "            0.2520865403496373,\n",
    "            0.40266725180440743\n",
    "        ],\n",
    "        [\n",
    "            0.6681310493060861,\n",
    "            0.2801674372250399, \n",
    "            0.6224648405839522,\n",
    "            0.6287746784150413,\n",
    "            0.864080498689899, \n",
    "            0.23833127705610258,\n",
    "            0.20311743810136906,\n",
    "            0.6646132937899738,\n",
    "            0.23575457417289924,\n",
    "            0.1869625695994146,\n",
    "            0.7712148738157554, \n",
    "            0.15237041670323637,\n",
    "            0.2763150373902683, \n",
    "            0.46500408886101585, \n",
    "            0.991468614310106\n",
    "        ],\n",
    "        [\n",
    "            0.47955269815875845,\n",
    "            0.18371674117676162,\n",
    "            0.4749895427072034, \n",
    "            0.5127159626377625,\n",
    "            0.14327300286458633,\n",
    "            0.5921086963579639,\n",
    "            0.21467664382766927,\n",
    "            0.08984875049424312,\n",
    "            0.5619088573772313, \n",
    "            0.6324525220346037, \n",
    "            0.65145500723789,\n",
    "            0.5118736033583858,\n",
    "            0.3791794826772541,\n",
    "            0.7062193547285907,\n",
    "            0.12888775429739185\n",
    "        ],\n",
    "        [\n",
    "            0.8936198110390413,\n",
    "            0.1499351596848777,\n",
    "            0.23230300209801535,\n",
    "            0.6275970485906217, \n",
    "            0.14179412142521963,\n",
    "            0.44590423506527455,\n",
    "            0.6398118989481705,\n",
    "            0.44025473834142315,\n",
    "            0.9690917160909921, \n",
    "            0.7329911430579539, \n",
    "            0.4723409208689966,\n",
    "            0.30051845327308735,\n",
    "            0.6517065287372249,\n",
    "            0.11682964074366375,\n",
    "            0.3356912564688531\n",
    "        ],\n",
    "        [\n",
    "            0.5819483213886298,\n",
    "            0.12715730125007862,\n",
    "            0.6624081011547434,\n",
    "            0.27210122174739293,\n",
    "            0.3321414469174103,\n",
    "            0.6738692045564213,\n",
    "            0.49979407643990537,\n",
    "            0.923095453187033, \n",
    "            0.8688108133354637,\n",
    "            0.29672803800781,\n",
    "            0.8422355709858387,\n",
    "            0.22967466587429908,\n",
    "            0.48606633908371566, \n",
    "            0.3302629931498261,\n",
    "            0.9271715208940098\n",
    "        ],\n",
    "        [\n",
    "            0.814229644181095,\n",
    "            0.6269508015754929, \n",
    "            0.19067116118180638,\n",
    "            0.6597416333912787,\n",
    "            0.3042396495694798,\n",
    "            0.5349586078017191,\n",
    "            0.9889297007928726,\n",
    "            0.5059647631701082,\n",
    "            0.6586214714303461, \n",
    "            0.19972197385065704,\n",
    "            0.730120041302739,\n",
    "            0.9254129585548022,\n",
    "            0.7774768791337286,\n",
    "            0.5880525770183761, \n",
    "            0.4404909426586451\n",
    "        ],\n",
    "        [\n",
    "            0.8393608070151912,\n",
    "            0.551470751477307,\n",
    "            0.3776646281929925,\n",
    "            0.7403545806778788,\n",
    "            0.01464073752506101,\n",
    "            0.49682079457661743,\n",
    "            0.12829037985166736,\n",
    "            0.8323709714882789,\n",
    "            0.4861583628986299, \n",
    "            0.10966510942571872,\n",
    "            0.36384711262095637,\n",
    "            0.008343156485128067,\n",
    "            0.05481969871494197,\n",
    "            0.11036480291979456,\n",
    "            0.3495717657917\n",
    "        ],\n",
    "        [\n",
    "            0.575668909069271,\n",
    "            0.1948209406820347,\n",
    "            0.5066632418120769,\n",
    "            0.5610866065811511,\n",
    "            0.7503051258152065,\n",
    "            0.20250301475454058,\n",
    "            0.9387177222181186,\n",
    "            0.4214964558859865, \n",
    "            0.2441688535705906, \n",
    "            0.2852282954051667,\n",
    "            0.7185375048873539,\n",
    "            0.09961745251862686,\n",
    "            0.507873295740294,\n",
    "            0.9713796833363287,\n",
    "            0.8218946227484244\n",
    "        ],\n",
    "        [\n",
    "            0.14519733396011691,\n",
    "            0.07264015089790021,\n",
    "            0.7254237309701331,\n",
    "            0.7437297525624584,\n",
    "            0.3465971472185204,\n",
    "            0.6489212261982703,\n",
    "            0.2152569561085349,\n",
    "            0.6476151760429897,\n",
    "            0.2045187871395916,\n",
    "            0.9599712380254137,\n",
    "            0.28554199184758966,\n",
    "            0.7701922251424572,\n",
    "            0.7095119328780166, \n",
    "            0.7579558453415812,\n",
    "            0.4251898428876446\n",
    "        ]\n",
    "    ],\n",
    "    [\n",
    "        0.30760147020407946, \n",
    "        0.1528992448227442,\n",
    "        0.9387231083505163,\n",
    "        0.12201982125460176,\n",
    "        0.3159744925438269,\n",
    "        0.555332538642272,\n",
    "        0.8654043562058316,\n",
    "        0.5523485724329922,\n",
    "        0.6405492495162189,\n",
    "        0.8421217300945876, \n",
    "        0.03415012932624606,\n",
    "        0.0914780538557024,\n",
    "        0.745151636966557,\n",
    "        0.9885343010237021,\n",
    "        0.02289480154711454\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        0.4740581778159267, 0.34432834551260527, 0.4665167530554428, 0.6711507992179184, 0.30149325789082704,\n",
    "        0.5216013512810533, 0.5739206841874827, 0.5011664230502018, 0.6659426824711602, 0.5870403517141657,\n",
    "        0.48456045445664925, 0.5519092842133653, 0.6631513043916594, 0.6203158151313124, 0.6799614219857062\n",
    "    ]\n",
    ")\n",
    "\n",
    "def softmax(z, axis=1):\n",
    "    if axis == 1:\n",
    "        exp_sum = np.sum(np.exp(z), axis=1).reshape(-1, 1)\n",
    "    elif axis == 0:\n",
    "        exp_sum = np.sum(np.exp(z), axis=0)\n",
    "    else:\n",
    "        exp_sum = np.sum(np.exp(z))\n",
    "    return np.exp(z) / exp_sum\n",
    "\n",
    "def attention(features, query):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    query - EmbSize - features of query object\n",
    "\n",
    "    returns vector of size EmbSize - features, aggregated according to the query\n",
    "    \"\"\"\n",
    "    features = np.asarray(features)\n",
    "    query = np.asarray(query)\n",
    "    \n",
    "    unnorm_scores = features.dot(query)\n",
    "    attention = softmax(unnorm_scores[np.newaxis, :])\n",
    "\n",
    "    result = np.sum(features * attention.T, axis=0)\n",
    "    return result\n",
    "\n",
    "result = attention(*sample_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e9064",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, —Ä–µ–∞–ª–∏–∑—É—é—â—É—é –º–µ—Ö–∞–Ω–∏–∑–º self-attention –≤–Ω–∏–º–∞–Ω–∏—è —Å –ª–∏–Ω–µ–π–Ω—ã–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏, –∫–∞–∫ –≤ [—ç—Ç–æ–π –∑–∞–¥–∞—á–µ](https://stepik.org/lesson/262249/step/7?unit=243132)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c833fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.38285163, -0.70524914],\n",
       "       [ 1.29902313,  0.07313413],\n",
       "       [ 1.7291639 ,  0.05709756],\n",
       "       [ 4.99774937,  0.96111943],\n",
       "       [ 4.92077627,  0.94173054],\n",
       "       [ 5.02724023,  0.96754176],\n",
       "       [ 5.00840585,  0.96471468],\n",
       "       [ 4.61770667,  0.89159573],\n",
       "       [ 5.01858654,  0.96604169],\n",
       "       [ 1.41217099, -1.00828542],\n",
       "       [ 0.80820852, -0.02863474],\n",
       "       [ 4.26163007,  0.78786003],\n",
       "       [ 1.14883058, -1.18828026],\n",
       "       [ 1.19290807, -1.22014831],\n",
       "       [ 3.90683039,  0.77443985]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_input = (\n",
    "    [\n",
    "        [0.5175129778200084, 0.13021330700949507],\n",
    "        [-0.3578609445921744, -0.07768163060380659],\n",
    "        [-0.046577477754636734, -0.12288550821838619],\n",
    "        [0.4424092505449793, -1.431399548551344],\n",
    "        [0.753992222548331, -1.1210257338970167],\n",
    "        [1.6736061037504428, -1.9789731491226337],\n",
    "        [-1.4985152255486565, -1.6614802556117283],\n",
    "        [-0.610065708073959, -0.8475335063027695],\n",
    "        [-0.1657640783522184, -1.7079776825852762],\n",
    "        [0.7857341373616981, 0.2956255012408635],\n",
    "        [-0.49243028413686984, 0.01065675311085114],\n",
    "        [0.20598401523943788, -0.6339670563637549],\n",
    "        [-0.15698934123474126, 0.9516567843056503], \n",
    "        [-0.08965595798444444, 0.9923765422389716],\n",
    "        [-0.9649404480809814, -0.6203623955866846]\n",
    "    ],\n",
    "    [\n",
    "        [-0.4777373377067222, 1.384780896738418],\n",
    "        [1.5537173245233542, -1.6151073640132454]\n",
    "    ],\n",
    "    [0.34068677065672126, -1.7225350645946451],\n",
    "    [\n",
    "        [1.667192089239799, 0.9072106203091014],\n",
    "        [1.0017863742909645, -0.8578876449703756]\n",
    "    ],\n",
    "    [-0.3811843050970959, -0.15922065479353645],\n",
    "    [\n",
    "        [2.396375885002737, 0.23995979796695774],\n",
    "        [0.21631803999882093, -0.6475173781192963]\n",
    "    ],\n",
    "    [1.448781271879823, -0.7144164516316529]\n",
    ")\n",
    "\n",
    "sample_output = (\n",
    "    [\n",
    "        [1.3828516277455327, -0.7052491362196253],\n",
    "        [1.2990231347325174, 0.07313412990950195],\n",
    "        [1.7291639000678214, 0.057097555962845575],\n",
    "        [4.9977493686508465, 0.9611194260544597],\n",
    "        [4.92077627317798, 0.9417305419570732],\n",
    "        [5.027240226701748, 0.9675417617162317],\n",
    "        [5.008405848246054, 0.9647146788718596],\n",
    "        [4.617706670795201, 0.8915957294670733],\n",
    "        [5.018586540911721, 0.966041694502124],\n",
    "        [1.4121709865145842, -1.0082854213057408],\n",
    "        [0.8082085153678329, -0.02863474439053916], \n",
    "        [4.261630070405553, 0.7878600291134995], \n",
    "        [1.1488305812076605, -1.1882802581002707], \n",
    "        [1.1929080669359462, -1.220148314614849],\n",
    "        [3.9068303877684656, 0.7744398548226676]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def softmax(z, axis=1):\n",
    "    if axis == 1:\n",
    "        exp_sum = np.sum(np.exp(z), axis=1).reshape(-1, 1)\n",
    "    elif axis == 0:\n",
    "        exp_sum = np.sum(np.exp(z), axis=0)\n",
    "    else:\n",
    "        exp_sum = np.sum(np.exp(z))\n",
    "    return np.exp(z) / exp_sum\n",
    "\n",
    "def self_attention(features, proj_k, bias_k, proj_q, bias_q, proj_v, bias_v):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    proj_k - EmbSize x EmbSize - projection matrix to make keys from features\n",
    "    bias_k - EmbSize - bias vector to make keys from features\n",
    "    proj_q - EmbSize x EmbSize - projection matrix to make queries from features\n",
    "    bias_q - EmbSize - bias vector to make queries from features\n",
    "    proj_v - EmbSize x EmbSize - projection matrix to make values from features\n",
    "    bias_v - EmbSize - bias vector to make values from features\n",
    "\n",
    "    returns InLen x EmbSize\n",
    "    \"\"\"\n",
    "    features = np.asarray(features)\n",
    "    proj_k = np.asarray(proj_k)\n",
    "    bias_k = np.asarray(bias_k)\n",
    "    proj_q = np.asarray(proj_q)\n",
    "    bias_q = np.asarray(bias_q)\n",
    "    proj_v = np.asarray(proj_v)\n",
    "    bias_v = np.asarray(bias_v)\n",
    "    \n",
    "    keys = features.dot(proj_k) + bias_k\n",
    "    querries = features.dot(proj_q) + bias_q\n",
    "    values = features.dot(proj_v) + bias_v\n",
    "    \n",
    "    logits = querries.dot(keys.T)\n",
    "    attscores = softmax(logits, axis=1)\n",
    "\n",
    "    result = attscores.dot(values)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "result = self_attention(*sample_input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d539971",
   "metadata": {},
   "source": [
    "## 5.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654201c0",
   "metadata": {},
   "source": [
    "–ê–ª–≥–æ—Ä–∏—Ç–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π. –†–∞–∑–º–µ—Ä –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Ä–∞–≤–µ–Ω 5000 —Ç–æ–∫–µ–Ω–æ–≤, —Ä—É—Å—Å–∫–æ–≥–æ - 8000. –û—Ü–µ–Ω–∏—Ç–µ, —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç –¥–µ–∫–æ–¥–µ—Ä –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∏–±–æ–ª—å—à–µ–π –¥–ª–∏–Ω—ã 5 –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏, —á—Ç–æ –ø—Ä–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–±–æ—Ä–∞?\n",
    "\n",
    "–í –æ—Ç–≤–µ—Ç –∑–∞–ø–∏—à–∏—Ç–µ –æ–¥–Ω–æ —á–∏—Å–ª–æ.\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–ª—É—á–∏—Ç—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350f0ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768000000000000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8000**5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e046003",
   "metadata": {},
   "source": [
    "–ê–ª–≥–æ—Ä–∏—Ç–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º —Ç–µ–∫—Å—Ç–∞ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π. –†–∞–∑–º–µ—Ä –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Ä–∞–≤–µ–Ω 5000 —Ç–æ–∫–µ–Ω–æ–≤, —Ä—É—Å—Å–∫–æ–≥–æ - 8000. –û—Ü–µ–Ω–∏—Ç–µ, —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ–∫–æ–¥–µ—Ä –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª–∏–Ω—ã 5 –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª—É—á–µ–≤–æ–π –ø–æ–∏—Å–∫ (beam search) –ø—Ä–∏ b=3 (b - —à–∏—Ä–∏–Ω–∞ –ª—É—á–∞)? \n",
    "\n",
    "–í –æ—Ç–≤–µ—Ç –∑–∞–ø–∏—à–∏—Ç–µ –æ–¥–Ω–æ —á–∏—Å–ª–æ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23027904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 ** 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c3b02",
   "metadata": {},
   "source": [
    "–ü—É—Å—Ç—å —É –Ω–∞—Å –µ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, —Å–æ—Å—Ç–æ—è—â–µ–µ –∏–∑ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö —Ü–∏—Ñ—Ä. –ù–∞–ø—Ä–∏–º–µ—Ä, '1576429830'.\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞–π—Ç–µ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç–∞–µ—Ç, —á—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –∫–∞–∂–¥—É—é —Ü–∏—Ñ—Ä—É —Ä–∞–≤–Ω–∞ 0.1.\n",
    "\n",
    " \n",
    "\n",
    "*–ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ: \n",
    "$PP(W) = P(w_1w_2..w_N)^{-1/N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f154576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1**10)**(-1/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09041846",
   "metadata": {},
   "source": [
    "BLEU (bilingual evaluation understudy) - –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º, –∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ (ground truth). –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–¥—Å—á–µ—Ç–∞ n-–≥—Ä–∞–º–º (n –º–µ–Ω—è–µ—Ç—Å—è –æ—Ç 1 –¥–æ –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä–æ–≥–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, 4), –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ, –∏ –≤ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–º (ground truth). –ü–æ—Å–ª–µ –ø–æ–¥—Å—á–µ—Ç–∞ —Å–æ–≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ n-–≥—Ä–∞–º–º –ø–æ–ª—É—á–µ–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–π brevity penalty - —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–µ—Ä–µ–≤–æ–¥–∞. Brevity penalty —Å—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–∫ <–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º> / <–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ>.\n",
    "\n",
    "–§–æ—Ä–º—É–ª–∞:\n",
    "$BLEU = \\text{brevity penalty} \\cdot \\left (\\prod_{i=1}^n \\text{precision}_i \\right)^{1/n} \\cdot 100\\%$\n",
    ", –≥–¥–µ $\\text{brevity penalty} = min \\left(1, \\dfrac{\\text{output length}}{\\text{reference length}} \\right)$\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä:\n",
    "![](https://ucarecdn.com/c3c754b4-29b3-4fec-ba6b-6e031b30de94/)\n",
    "\n",
    "\n",
    "–ó–∞–¥–∞—á–∞\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞–π—Ç–µ BLEU-score –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ —É—á–∏—Ç—ã–≤–∞–π—Ç–µ n-–≥—Ä–∞–º–º—ã —Å $n \\in [1,2,3]$\n",
    "\n",
    "–ü–µ—Ä–µ–≤–æ–¥, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º: \"–ö–æ—à–∫–∞ –≤—ã—à–ª–∞ –∏–∑ –¥–æ–º–∞ –∏ —Å–µ–ª–∞ –Ω–∞ –∫—Ä—ã–ª—å—Ü–æ\"\n",
    "\n",
    "–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ (ground truth): \"–ö–æ—à–∫–∞ –≤—ã—à–ª–∞ –∏–∑ –∫–æ–º–Ω–∞—Ç—ã –∏ —Å–µ–ª–∞ –Ω–∞ —Å—Ç—É–ø–µ–Ω—å–∫–∏\"\n",
    "\n",
    " \n",
    "\n",
    "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: –æ—Ç–≤–µ—Ç –∑–∞–ø–∏—à–∏—Ç–µ –≤ –≤–∏–¥–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤, –æ–∫—Ä—É–≥–ª–∏–≤ –¥–æ —Ü–µ–ª—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e2c8b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.27579585747102"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "translation = \"–ö–æ—à–∫–∞ –≤—ã—à–ª–∞ –∏–∑ –¥–æ–º–∞ –∏ —Å–µ–ª–∞ –Ω–∞ –∫—Ä—ã–ª—å—Ü–æ\"\n",
    "ground_truth = \"–ö–æ—à–∫–∞ –≤—ã—à–ª–∞ –∏–∑ –∫–æ–º–Ω–∞—Ç—ã –∏ —Å–µ–ª–∞ –Ω–∞ —Å—Ç—É–ø–µ–Ω—å–∫–∏\"\n",
    "\n",
    "\n",
    "def get_n_grams(sentence, n):\n",
    "    sentence_splitted = re.findall(r'[\\w]+', sentence)\n",
    "    n_grams = []\n",
    "    out_len = len(sentence_splitted) - n + 1\n",
    "    for i in range(out_len):\n",
    "        n_grams.append(sentence_splitted[i:i+n])\n",
    "    return n_grams \n",
    "\n",
    "def precision(translation, ground_truth, n):\n",
    "    n_grams_translation = get_n_grams(translation, n)\n",
    "    n_grams_ground_truth = get_n_grams(ground_truth, n)\n",
    "\n",
    "    intercetion = [value for value in n_grams_translation if value in n_grams_ground_truth]\n",
    "    precision = len(intercetion) / len(n_grams_ground_truth)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def bleu_score(translation, ground_truth, n_list):\n",
    "    brevity_penalty = len(re.findall(r'[\\w]+', translation)) / len(re.findall(r'[\\w]+', ground_truth))\n",
    "    \n",
    "    precision_prod = 1\n",
    "    for n in n_list:\n",
    "        precision_prod *= precision(translation, ground_truth, n)\n",
    "        \n",
    "    return brevity_penalty * (precision_prod) ** (1/max(n_list)) * 100\n",
    "\n",
    "bleu_score(translation, ground_truth, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2299f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung_nlp",
   "language": "python",
   "name": "samsung_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
