{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10497,
     "status": "ok",
     "timestamp": 1737644434493,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "eOEz6R1WfGfW",
    "outputId": "a428c442-8378-4d48-ca38-b1f4708cc661"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 18260,
     "status": "ok",
     "timestamp": 1737644452751,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "UlfR6Pqz8hc-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy import stats as sts\n",
    "\n",
    "from utils import ndcg, num_swapped_pairs, compute_ideal_dcg\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxolFVjlcF5J"
   },
   "source": [
    "# LambdaRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg1d6tQwz96E"
   },
   "source": [
    "Обучается ставить score выше для того, кто должен быть выше в списке. Для обучение нужно брать пары {i, j}, где i документ стоит выше, чем j. Для обучения нужно выбрать документ i и взять все пары, где он встречается, будь то {i, j} (где он выше) или {k, i} (где ниже)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1iHEmAcU8P"
   },
   "source": [
    "$$C_{ij}=C(s_{i}-s_{j})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})=\\frac{1}{2}(1-S_{ij})\\sigma(s_{i}-s_{j})+log(1+e^{-\\sigma(s_{i}-s_{j})})$$\n",
    "\n",
    "$$\\bar{P_{ij}}=\\frac{1}{2}(1+S_{ij})$$\n",
    "\n",
    "$$S_{ij}\\in\\{0;\\pm1\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737644452752,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "FDpKIfHdcF5M"
   },
   "outputs": [],
   "source": [
    "class LambdaRank(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=16):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        logits = self.model(inp)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambdas(y_true, y_pred, gain_scheme='exp2'):\n",
    "    # рассчитаем нормировку, IdealDCG\n",
    "    ideal_dcg = compute_ideal_dcg(y_true, gain_scheme=gain_scheme)\n",
    "    try:\n",
    "        N = 1 / ideal_dcg\n",
    "    except ZeroDivisionError:\n",
    "        N = 0\n",
    "    \n",
    "    # рассчитаем порядок документов согласно оценкам релевантности\n",
    "    _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "    rank_order += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # получаем все попарные разницы скоров в батче\n",
    "        pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "        \n",
    "        # поставим разметку для пар, 1 если первый документ релевантнее\n",
    "        # -1 если второй документ релевантнее\n",
    "        Sij = compute_labels_in_batch(y_true)\n",
    "        # посчитаем изменение gain из-за перестановок\n",
    "        gain_diff = compute_gain_diff(y_true, gain_scheme)\n",
    "        \n",
    "        # посчитаем изменение знаменателей-дискаунтеров\n",
    "        decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "        # посчитаем непосредственное изменение nDCG\n",
    "        delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "        # посчитаем лямбды\n",
    "        lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "        lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "        \n",
    "        return lambda_update\n",
    "    \n",
    "    \n",
    "def compute_labels_in_batch(y_true):\n",
    "    \n",
    "    # разница релевантностей каждого с каждым объектом\n",
    "    rel_diff = y_true - y_true.t()\n",
    "    \n",
    "    # 1 в этой матрице - объект более релевантен\n",
    "    pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "    \n",
    "    # 1 тут - объект менее релевантен\n",
    "    neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "    Sij = pos_pairs - neg_pairs\n",
    "    return Sij\n",
    "\n",
    "def compute_gain_diff(y_true, gain_scheme):\n",
    "    if gain_scheme == \"exp2\":\n",
    "        gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "    elif gain_scheme == \"const\":\n",
    "        gain_diff = y_true - y_true.t()\n",
    "    else:\n",
    "        raise ValueError(f\"{gain_scheme} method not supported\")\n",
    "    return gain_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737644452752,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "-XbuRb1BcF5N"
   },
   "outputs": [],
   "source": [
    "lambda_model = LambdaRank(num_input_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "96EqGFJgcF5N",
    "outputId": "798c43af-e64e-4a59-cf66-aa5a8cf46a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3256, 0.1433, 0.6899, 0.0219, 0.1388, 0.9045, 0.3842, 0.9491, 0.6014,\n",
       "         0.8825],\n",
       "        [0.3464, 0.6013, 0.6932, 0.0778, 0.1991, 0.2231, 0.4087, 0.5377, 0.0096,\n",
       "         0.9442],\n",
       "        [0.5481, 0.0355, 0.2304, 0.8616, 0.3843, 0.7930, 0.0048, 0.5900, 0.0301,\n",
       "         0.1524],\n",
       "        [0.3828, 0.5160, 0.0010, 0.0387, 0.6079, 0.3299, 0.2769, 0.8888, 0.2703,\n",
       "         0.8580]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand(4, 10)\n",
    "y_true = torch.Tensor([[1], [3], [2], [0]])\n",
    "# batch_size x input_dim\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "XeaC6qoLcF5N",
    "outputId": "b9b620f8-87be-4538-9c36-5928a69fc59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913328532777214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0494],\n",
       "        [-0.1123],\n",
       "        [-0.0916],\n",
       "        [-0.0911]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lambda_model(inp)\n",
    "print(ndcg(y_true, preds))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = compute_lambdas(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lambda_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0494],\n",
      "        [-0.1123],\n",
      "        [-0.0916],\n",
      "        [-0.0911]], grad_fn=<AddmmBackward0>)\n",
      "0.6913328532777214\n",
      "tensor([[-0.1465],\n",
      "        [-0.1094],\n",
      "        [-0.1025],\n",
      "        [-0.1756]], grad_fn=<AddmmBackward0>)\n",
      "0.9224945508080385\n",
      "tensor([[-0.2130],\n",
      "        [-0.0955],\n",
      "        [-0.1035],\n",
      "        [-0.2364]], grad_fn=<AddmmBackward0>)\n",
      "1.0\n",
      "tensor([[-0.2632],\n",
      "        [-0.0565],\n",
      "        [-0.1029],\n",
      "        [-0.2844]], grad_fn=<AddmmBackward0>)\n",
      "1.0\n",
      "tensor([[-0.3216],\n",
      "        [-0.0064],\n",
      "        [-0.1022],\n",
      "        [-0.3392]], grad_fn=<AddmmBackward0>)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    preds = lambda_model(inp)\n",
    "    if i % 20 == 0:\n",
    "        print(preds)\n",
    "        print(ndcg(y_true, preds))\n",
    "    lambdas = compute_lambdas(y_true, preds)\n",
    "\n",
    "    preds.backward(lambdas/preds.shape[0])\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737644452993,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "TlphjZlBcF5O"
   },
   "source": [
    "## Попробуем обучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 9838,
     "status": "ok",
     "timestamp": 1737644462827,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "67DXlMFWcF5O",
    "outputId": "327ae952-1f65-42d4-d98b-abfea46b7d90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>query</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>feature_130</th>\n",
       "      <th>feature_131</th>\n",
       "      <th>feature_132</th>\n",
       "      <th>feature_133</th>\n",
       "      <th>feature_134</th>\n",
       "      <th>feature_135</th>\n",
       "      <th>feature_136</th>\n",
       "      <th>feature_137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11089534.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>64034.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11089534.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>64034.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11089534.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>63933.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  query  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     2.0    1.0        3.0        3.0        0.0        0.0        3.0   \n",
       "1     2.0    1.0        3.0        0.0        3.0        0.0        3.0   \n",
       "2     0.0    1.0        3.0        0.0        2.0        0.0        3.0   \n",
       "3     2.0    1.0        3.0        0.0        3.0        0.0        3.0   \n",
       "4     1.0    1.0        3.0        0.0        3.0        0.0        3.0   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_128  feature_129  \\\n",
       "0        1.0        1.0   0.000000  ...         62.0   11089534.0   \n",
       "1        1.0        0.0   1.000000  ...         54.0   11089534.0   \n",
       "2        1.0        0.0   0.666667  ...         45.0          3.0   \n",
       "3        1.0        0.0   1.000000  ...         56.0   11089534.0   \n",
       "4        1.0        0.0   1.000000  ...         64.0          5.0   \n",
       "\n",
       "   feature_130  feature_131  feature_132  feature_133  feature_134  \\\n",
       "0          2.0        116.0      64034.0         13.0          3.0   \n",
       "1          2.0        124.0      64034.0          1.0          2.0   \n",
       "2          1.0        124.0       3344.0         14.0         67.0   \n",
       "3         13.0        123.0      63933.0          1.0          3.0   \n",
       "4          7.0        256.0      49697.0          1.0         13.0   \n",
       "\n",
       "   feature_135  feature_136  feature_137  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost.datasets import msrank_10k\n",
    "\n",
    "msrank_10k_train, msrank_10k_test = msrank_10k()\n",
    "msrank_10k_train = msrank_10k_train.rename(columns={0: 'target', 1: 'query'}).rename(columns={i: f'feature_{i}' for i in range(2, 138)})\n",
    "msrank_10k_test = msrank_10k_test.rename(columns={0: 'target', 1: 'query'}).rename(columns={i: f'feature_{i}' for i in range(2, 138)})\n",
    "\n",
    "for feature in msrank_10k_train.columns:\n",
    "    msrank_10k_train[feature] = msrank_10k_train[feature].astype(float)\n",
    "\n",
    "for feature in msrank_10k_test.columns:\n",
    "    msrank_10k_test[feature] = msrank_10k_test[feature].astype(float)\n",
    "\n",
    "msrank_10k_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Надо отнормировать признаки перед подачей в нейросеть, нормировать надо по группам, так как разные признаки соответствуют разным запросам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for query in msrank_10k_train['query'].unique():\n",
    "    scaler = StandardScaler()\n",
    "    msrank_10k_train.loc[msrank_10k_train['query'] == query, 'feature_2':] = scaler\\\n",
    "    .fit_transform(msrank_10k_train.loc[msrank_10k_train['query'] == query, 'feature_2':])\n",
    "\n",
    "for query in msrank_10k_test['query'].unique():\n",
    "    scaler = StandardScaler()\n",
    "    msrank_10k_test.loc[msrank_10k_test['query'] == query, 'feature_2':] = scaler\\\n",
    "    .fit_transform(msrank_10k_test.loc[msrank_10k_test['query'] == query, 'feature_2':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_check = torch.as_tensor(msrank_10k_train.loc[msrank_10k_train['query'] == 1, 'feature_2':].values, dtype=torch.float32)\n",
    "y_check = torch.as_tensor(msrank_10k_train.loc[msrank_10k_train['query'] == 1, 'target'].values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737644480537,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "_oLFLIEX4j54"
   },
   "outputs": [],
   "source": [
    "# test the model works\n",
    "\n",
    "model = LambdaRank(num_input_features=136)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5891392105347059\n",
      "0.8938722611119746\n",
      "0.9149902933369998\n",
      "0.9232238948801027\n",
      "0.9267892939268222\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(x_check)\n",
    "    if i % 20 == 0:\n",
    "        print(ndcg(y_check, preds))\n",
    "    lambdas = compute_lambdas(y_check, preds)\n",
    "\n",
    "    preds.backward(lambdas/preds.shape[0])\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSRankDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return torch.as_tensor(x, dtype=torch.float32), torch.as_tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = msrank_10k_train.loc[msrank_10k_train['query'] == 1, 'feature_2':].values\n",
    "y = msrank_10k_train.loc[msrank_10k_train['query'] == 1, 'target'].values.reshape(-1, 1)\n",
    "\n",
    "dataset = MSRankDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model works\n",
    "\n",
    "model = LambdaRank(num_input_features=136)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720676636856725\n",
      "0.8651334896561893\n",
      "0.8954911591404534\n",
      "0.9077700753816907\n",
      "0.9133565127549089\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        preds = model(batch_x)\n",
    "        lambdas = compute_lambdas(batch_y, preds)\n",
    "        preds.backward(lambdas/batch_x.shape[0])\n",
    "        \n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            whole_preds = model(x_check)\n",
    "            print(ndcg(y_check, whole_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_datasets = {}\n",
    "train_dataloaders = {}\n",
    "\n",
    "for query in msrank_10k_train['query'].unique():\n",
    "    subset = msrank_10k_train.loc[msrank_10k_train['query'] == query]\n",
    "    subset_x = subset.loc[:, 'feature_2':].values\n",
    "    subset_y = subset.loc[:, 'target'].values.reshape(-1, 1)\n",
    "    \n",
    "    dataset = MSRankDataset(subset_x, subset_y)\n",
    "    train_datasets[query] = dataset\n",
    "    train_dataloaders[query] = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# test\n",
    "test_datasets = {}\n",
    "test_dataloaders = {}\n",
    "\n",
    "for query in msrank_10k_test['query'].unique():\n",
    "    subset = msrank_10k_test.loc[msrank_10k_test['query'] == query]\n",
    "    subset_x = subset.loc[:, 'feature_2':].values\n",
    "    subset_y = subset.loc[:, 'target'].values.reshape(-1, 1)\n",
    "    \n",
    "    dataset = MSRankDataset(subset_x, subset_y)\n",
    "    test_datasets[query] = dataset\n",
    "    test_dataloaders[query] = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for it, (batch_x, batch_y) in enumerate(dataloader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            preds.append(model(batch_x))\n",
    "            y_true.append(batch_y)\n",
    "    preds = torch.concatenate(preds, dim=0)\n",
    "    y_true = torch.concatenate(y_true, dim=0)\n",
    "\n",
    "    try:\n",
    "        result = ndcg(y_true, preds, gain_scheme='exp2', k=10)\n",
    "    except ZeroDivisionError:\n",
    "        result = 0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LambdaRank(num_input_features=136, hidden_dim=32)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.10866858044176127\n",
      "MEAN TEST=0.11949016964402541\n"
     ]
    }
   ],
   "source": [
    "# score untrained\n",
    "\n",
    "train_ndcgs = []\n",
    "test_ndcgs = []\n",
    "\n",
    "print('########### TRAIN')\n",
    "for query, msrank_dataloader in train_dataloaders.items():\n",
    "    ndcg_query = score_model(model, msrank_dataloader)\n",
    "    # print(f'#### QUERY={query}, NDCG={ndcg_query}')\n",
    "    train_ndcgs.append(ndcg_query)\n",
    "\n",
    "print('########### TEST')\n",
    "for query, msrank_dataloader in test_dataloaders.items():\n",
    "    ndcg_query = score_model(model, msrank_dataloader)\n",
    "    # print(f'#### QUERY={query}, NDCG={ndcg_query}')\n",
    "    test_ndcgs.append(ndcg_query)\n",
    "\n",
    "print(f'MEAN TRAIN={np.mean(train_ndcgs)}')\n",
    "print(f'MEAN TEST={np.mean(test_ndcgs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.40812127526588526\n",
      "MEAN TEST=0.3452550271309377\n",
      "Epoch: 1\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.4561624446357904\n",
      "MEAN TEST=0.361557087164106\n",
      "Epoch: 2\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.48806239120891987\n",
      "MEAN TEST=0.3981795669297291\n",
      "Epoch: 3\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.48414182749977436\n",
      "MEAN TEST=0.39828112286589423\n",
      "Epoch: 4\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.4731208490013138\n",
      "MEAN TEST=0.39805250629393013\n",
      "Epoch: 5\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.4803048019623369\n",
      "MEAN TEST=0.41241678944021737\n",
      "Epoch: 6\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.47805806366205916\n",
      "MEAN TEST=0.41638812427488275\n",
      "Epoch: 7\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5018134056763615\n",
      "MEAN TEST=0.4246640499767288\n",
      "Epoch: 8\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5117037513826276\n",
      "MEAN TEST=0.4346634366644597\n",
      "Epoch: 9\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5174016501899608\n",
      "MEAN TEST=0.4290405419573324\n",
      "Epoch: 10\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.48713983461720656\n",
      "MEAN TEST=0.424130814602841\n",
      "Epoch: 11\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5178480326476638\n",
      "MEAN TEST=0.42933312135818286\n",
      "Epoch: 12\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5149852830114799\n",
      "MEAN TEST=0.43207551508294645\n",
      "Epoch: 13\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.4990322209047468\n",
      "MEAN TEST=0.4160806418123288\n",
      "Epoch: 14\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5169841542874567\n",
      "MEAN TEST=0.4250030805065102\n",
      "Epoch: 15\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5220343568642763\n",
      "MEAN TEST=0.42507307603309313\n",
      "Epoch: 16\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5226516833097279\n",
      "MEAN TEST=0.4357416187750237\n",
      "Epoch: 17\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5263637353735954\n",
      "MEAN TEST=0.4353903297220237\n",
      "Epoch: 18\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5283540601660042\n",
      "MEAN TEST=0.4247116808624208\n",
      "Epoch: 19\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5256357052895619\n",
      "MEAN TEST=0.4137409968628672\n",
      "Epoch: 20\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5210036995232946\n",
      "MEAN TEST=0.4106246891865836\n",
      "Epoch: 21\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5344874386594585\n",
      "MEAN TEST=0.4363448534019504\n",
      "Epoch: 22\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.53766837996067\n",
      "MEAN TEST=0.42056085024700157\n",
      "Epoch: 23\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5136791907542353\n",
      "MEAN TEST=0.4136911338355502\n",
      "Epoch: 24\n",
      "########### TRAIN\n",
      "########### TEST\n",
      "MEAN TRAIN=0.5107361351795747\n",
      "MEAN TEST=0.4174116966062901\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "len_dataset = len(msrank_10k_train)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_losses = []\n",
    "    for query, msrank_dataloader in train_dataloaders.items():\n",
    "        for it, (batch_x, batch_y) in enumerate(msrank_dataloader):\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "    \n",
    "            batch_pred = model(batch_x)\n",
    "            lambdas = compute_lambdas(batch_y, batch_pred)\n",
    "            batch_pred.backward(lambdas/batch_x.shape[0])\n",
    "    \n",
    "        optimizer.step()\n",
    "\n",
    "    # check scores\n",
    "    train_ndcgs = []\n",
    "    test_ndcgs = []\n",
    "    \n",
    "    print('########### TRAIN')\n",
    "    for query, msrank_dataloader in train_dataloaders.items():\n",
    "        ndcg_query = score_model(model, msrank_dataloader)\n",
    "        # print(f'#### QUERY={query}, NDCG={ndcg_query}')\n",
    "        train_ndcgs.append(ndcg_query)\n",
    "    \n",
    "    print('########### TEST')\n",
    "    for query, msrank_dataloader in test_dataloaders.items():\n",
    "        ndcg_query = score_model(model, msrank_dataloader)\n",
    "        # print(f'#### QUERY={query}, NDCG={ndcg_query}')\n",
    "        test_ndcgs.append(ndcg_query)\n",
    "    \n",
    "    print(f'MEAN TRAIN={np.mean(train_ndcgs)}')\n",
    "    print(f'MEAN TEST={np.mean(test_ndcgs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "uplift",
   "language": "python",
   "name": "uplift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
