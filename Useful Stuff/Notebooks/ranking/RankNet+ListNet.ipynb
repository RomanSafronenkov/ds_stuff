{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10497,
     "status": "ok",
     "timestamp": 1737644434493,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "eOEz6R1WfGfW",
    "outputId": "a428c442-8378-4d48-ca38-b1f4708cc661"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 18260,
     "status": "ok",
     "timestamp": 1737644452751,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "UlfR6Pqz8hc-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "from scipy import stats as sts\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737644452752,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "5tS4VXSFPC_E"
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "from torch import Tensor, sort\n",
    "\n",
    "def num_swapped_pairs(ys_true: Tensor, ys_pred: Tensor) -> int:\n",
    "    _, sorted_ys_true_idx = sort(ys_true, descending=True)\n",
    "\n",
    "    sorted_preds_by_true = ys_pred[sort(ys_true, descending=True)[1]]\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(sorted_preds_by_true)):\n",
    "        for j in range(i+1, len(sorted_preds_by_true)):\n",
    "            if sorted_preds_by_true[i] < sorted_preds_by_true[j]:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def compute_gain(y_value: float, gain_scheme: str) -> float:\n",
    "  assert gain_scheme in ['const', 'exp2']\n",
    "  if gain_scheme == 'const':\n",
    "      return y_value\n",
    "  elif gain_scheme == 'exp2':\n",
    "      return 2 ** y_value - 1\n",
    "\n",
    "\n",
    "def dcg(ys_true: Tensor, ys_pred: Tensor, gain_scheme: str) -> float:\n",
    "    dcg_value = 0\n",
    "    _, sorted_ys_pred_idx = sort(ys_pred, descending=True)\n",
    "    for i, rel in enumerate(ys_true[sorted_ys_pred_idx]):\n",
    "        dcg_value += compute_gain(rel, gain_scheme=gain_scheme) / log2(i+2)\n",
    "    return dcg_value\n",
    "\n",
    "\n",
    "def ndcg(ys_true: Tensor, ys_pred: Tensor, gain_scheme: str = 'const') -> float:\n",
    "    \"\"\"\n",
    "    https://en.wikipedia.org/wiki/Discounted_cumulative_gain#cite_note-4\n",
    "    \"\"\"\n",
    "    dcg_value = dcg(ys_true, ys_pred, gain_scheme=gain_scheme)\n",
    "    perfect_dcg = dcg(ys_true, ys_true, gain_scheme=gain_scheme)\n",
    "\n",
    "    return dcg_value / perfect_dcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxolFVjlcF5J"
   },
   "source": [
    "# RankNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg1d6tQwz96E"
   },
   "source": [
    "Обучается ставить score выше для того, кто должен быть выше в списке. В итоге модель выдает величину, которую можно сравнить и выводить топ, может обучаться на данных одного ранга, тогда таргет = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1iHEmAcU8P"
   },
   "source": [
    "$$C_{ij}=C(o_{ij})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})$$\n",
    "\n",
    "$$o_{ij}=f(x_i)-f(x_j)$$\n",
    "\n",
    "$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$\n",
    "\n",
    "$$\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737644452752,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "FDpKIfHdcF5M"
   },
   "outputs": [],
   "source": [
    "class RankNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=16):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.out_activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        logits_1 = self.predict(input_1)\n",
    "        logits_2 = self.predict(input_2)\n",
    "\n",
    "        logits_diff = logits_1 - logits_2\n",
    "        out = self.out_activation(logits_diff)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict(self, inp):\n",
    "        logits = self.model(inp)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737644452752,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "-XbuRb1BcF5N"
   },
   "outputs": [],
   "source": [
    "ranknet_model = RankNet(num_input_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "96EqGFJgcF5N",
    "outputId": "798c43af-e64e-4a59-cf66-aa5a8cf46a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0919, 0.9394, 0.2377, 0.3483, 0.1489, 0.9118, 0.6660, 0.8441, 0.2611,\n",
       "         0.8819],\n",
       "        [0.3265, 0.1266, 0.9855, 0.1064, 0.8750, 0.5784, 0.8128, 0.1228, 0.6015,\n",
       "         0.2889],\n",
       "        [0.8808, 0.6673, 0.2847, 0.2359, 0.8470, 0.1170, 0.3532, 0.5040, 0.0520,\n",
       "         0.8451],\n",
       "        [0.8741, 0.9857, 0.7272, 0.5581, 0.8266, 0.0216, 0.7462, 0.9887, 0.5326,\n",
       "         0.1212]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1, inp_2 = torch.rand(4, 10), torch.rand(4, 10)\n",
    "# batch_size x input_dim\n",
    "inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "XeaC6qoLcF5N",
    "outputId": "b9b620f8-87be-4538-9c36-5928a69fc59f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4863],\n",
       "        [0.4918],\n",
       "        [0.4986],\n",
       "        [0.4696]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ranknet_model(inp_1, inp_2)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "sI79hKZ9cF5O"
   },
   "outputs": [],
   "source": [
    "first_linear_layer = ranknet_model.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "L8OX6Qk1cF5O"
   },
   "outputs": [],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "r1U5iEX9cF5O"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "loss = criterion(preds, torch.ones_like(preds))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "MjWsaXRCcF5O",
    "outputId": "3b133ccc-06f4-48de-de1d-c90f80bd17f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7947e-04,  5.5189e-03, -8.6106e-04, -6.7795e-03,  5.1461e-03,\n",
       "         -1.9429e-03,  1.1229e-03,  3.2511e-03, -5.4011e-03, -4.3615e-03],\n",
       "        [-1.5919e-02,  1.4320e-02,  6.2754e-03,  1.4060e-03,  1.9067e-03,\n",
       "          2.2156e-02,  5.2619e-03,  6.3696e-03, -1.3810e-02, -2.4862e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-5.0858e-03, -4.3651e-03, -5.7997e-03, -9.0197e-03, -2.9486e-03,\n",
       "         -5.2925e-03, -4.3932e-03, -4.4423e-03, -4.8907e-03, -7.0829e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.5874e-03,  1.7782e-03,  1.3847e-02,  1.4946e-03,  1.2294e-02,\n",
       "          8.1261e-03,  1.1420e-02,  1.7257e-03,  8.4518e-03,  4.0598e-03],\n",
       "        [-3.6782e-04,  1.1311e-02, -1.7647e-03, -1.3894e-02,  1.0547e-02,\n",
       "         -3.9818e-03,  2.3013e-03,  6.6631e-03, -1.1069e-02, -8.9387e-03],\n",
       "        [ 6.0304e-02,  4.8142e-02,  4.5882e-02,  7.9952e-02,  2.5647e-02,\n",
       "          4.5798e-02,  4.9694e-02,  5.4530e-02,  6.1837e-02,  8.6180e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.6100e-04, -4.9510e-03,  7.7245e-04,  6.0818e-03, -4.6165e-03,\n",
       "          1.7429e-03, -1.0073e-03, -2.9166e-03,  4.8453e-03,  3.9126e-03],\n",
       "        [ 5.9399e-03,  1.8713e-02,  1.2385e-02,  4.1492e-02, -1.0790e-02,\n",
       "          3.2796e-02,  2.6428e-02,  1.9004e-02,  5.2808e-02,  4.1065e-02],\n",
       "        [ 7.3661e-04,  1.4876e-03,  1.1991e-03,  2.3363e-03,  6.9780e-04,\n",
       "          1.8971e-03,  1.3191e-03,  8.9264e-04,  1.8897e-03,  2.1772e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0707e-04, -1.8969e-04, -9.4804e-05, -3.5919e-04, -6.5979e-05,\n",
       "         -7.4205e-05, -8.4615e-05, -1.6276e-04, -5.4461e-05, -1.9792e-04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737644452992,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "bbsXyNWpcF5O"
   },
   "outputs": [],
   "source": [
    "ranknet_model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737644452993,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "TlphjZlBcF5O"
   },
   "source": [
    "## Попробуем обучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 9838,
     "status": "ok",
     "timestamp": 1737644462827,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "67DXlMFWcF5O",
    "outputId": "327ae952-1f65-42d4-d98b-abfea46b7d90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>query</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>feature_130</th>\n",
       "      <th>feature_131</th>\n",
       "      <th>feature_132</th>\n",
       "      <th>feature_133</th>\n",
       "      <th>feature_134</th>\n",
       "      <th>feature_135</th>\n",
       "      <th>feature_136</th>\n",
       "      <th>feature_137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11089534.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>64034.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11089534.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>64034.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11089534.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>63933.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  query  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     2.0    1.0        3.0        3.0        0.0        0.0        3.0   \n",
       "1     2.0    1.0        3.0        0.0        3.0        0.0        3.0   \n",
       "2     0.0    1.0        3.0        0.0        2.0        0.0        3.0   \n",
       "3     2.0    1.0        3.0        0.0        3.0        0.0        3.0   \n",
       "4     1.0    1.0        3.0        0.0        3.0        0.0        3.0   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_128  feature_129  \\\n",
       "0        1.0        1.0   0.000000  ...         62.0   11089534.0   \n",
       "1        1.0        0.0   1.000000  ...         54.0   11089534.0   \n",
       "2        1.0        0.0   0.666667  ...         45.0          3.0   \n",
       "3        1.0        0.0   1.000000  ...         56.0   11089534.0   \n",
       "4        1.0        0.0   1.000000  ...         64.0          5.0   \n",
       "\n",
       "   feature_130  feature_131  feature_132  feature_133  feature_134  \\\n",
       "0          2.0        116.0      64034.0         13.0          3.0   \n",
       "1          2.0        124.0      64034.0          1.0          2.0   \n",
       "2          1.0        124.0       3344.0         14.0         67.0   \n",
       "3         13.0        123.0      63933.0          1.0          3.0   \n",
       "4          7.0        256.0      49697.0          1.0         13.0   \n",
       "\n",
       "   feature_135  feature_136  feature_137  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost.datasets import msrank_10k\n",
    "\n",
    "msrank_10k_train, msrank_10k_test = msrank_10k()\n",
    "msrank_10k_train = msrank_10k_train.rename(columns={0: 'target', 1: 'query'}).rename(columns={i: f'feature_{i}' for i in range(2, 138)})\n",
    "msrank_10k_test = msrank_10k_test.rename(columns={0: 'target', 1: 'query'}).rename(columns={i: f'feature_{i}' for i in range(2, 138)})\n",
    "\n",
    "for feature in msrank_10k_train.columns:\n",
    "    msrank_10k_train[feature] = msrank_10k_train[feature].astype(float)\n",
    "\n",
    "for feature in msrank_10k_test.columns:\n",
    "    msrank_10k_test[feature] = msrank_10k_test[feature].astype(float)\n",
    "\n",
    "msrank_10k_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Надо отнормировать признаки перед подачей в нейросеть, нормировать надо по группам, так как разные признаки соответствуют разным запросам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+00, 1.600e+01, 3.100e+01, 4.600e+01, 6.100e+01, 7.600e+01,\n",
       "       9.100e+01, 1.060e+02, 1.210e+02, 1.360e+02, 1.510e+02, 1.660e+02,\n",
       "       1.810e+02, 1.960e+02, 2.110e+02, 2.260e+02, 2.410e+02, 2.560e+02,\n",
       "       2.710e+02, 2.860e+02, 3.010e+02, 3.160e+02, 3.310e+02, 3.460e+02,\n",
       "       3.610e+02, 3.760e+02, 3.910e+02, 4.060e+02, 4.210e+02, 4.360e+02,\n",
       "       4.510e+02, 4.660e+02, 4.810e+02, 4.960e+02, 5.110e+02, 5.260e+02,\n",
       "       5.410e+02, 5.560e+02, 5.710e+02, 5.860e+02, 6.010e+02, 6.160e+02,\n",
       "       6.310e+02, 6.460e+02, 6.610e+02, 6.760e+02, 6.910e+02, 7.060e+02,\n",
       "       7.210e+02, 7.360e+02, 7.510e+02, 7.660e+02, 7.810e+02, 7.960e+02,\n",
       "       8.110e+02, 8.260e+02, 8.410e+02, 8.560e+02, 8.710e+02, 8.860e+02,\n",
       "       9.010e+02, 9.160e+02, 9.310e+02, 9.460e+02, 9.610e+02, 9.760e+02,\n",
       "       9.910e+02, 1.006e+03, 1.021e+03, 1.036e+03, 1.051e+03, 1.066e+03,\n",
       "       1.081e+03, 1.096e+03, 1.111e+03, 1.126e+03, 1.141e+03, 1.156e+03,\n",
       "       1.171e+03, 1.186e+03, 1.201e+03, 1.216e+03, 1.231e+03, 1.246e+03,\n",
       "       1.261e+03, 1.276e+03, 1.291e+03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msrank_10k_train['query'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for query in msrank_10k_train['query'].unique():\n",
    "    scaler = StandardScaler()\n",
    "    msrank_10k_train.loc[msrank_10k_train['query'] == query, 'feature_2':] = scaler\\\n",
    "    .fit_transform(msrank_10k_train.loc[msrank_10k_train['query'] == query, 'feature_2':])\n",
    "\n",
    "for query in msrank_10k_test['query'].unique():\n",
    "    scaler = StandardScaler()\n",
    "    msrank_10k_test.loc[msrank_10k_test['query'] == query, 'feature_2':] = scaler\\\n",
    "    .fit_transform(msrank_10k_test.loc[msrank_10k_test['query'] == query, 'feature_2':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737644462827,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "qCJrMWdKcF5O"
   },
   "outputs": [],
   "source": [
    "x_train = msrank_10k_train.drop(['target', 'query'], axis=1).values\n",
    "y_train = msrank_10k_train['target'].values\n",
    "query_train = msrank_10k_train['query'].values.astype(int)\n",
    "\n",
    "x_test = msrank_10k_test.drop(['target', 'query'], axis=1).values\n",
    "y_test = msrank_10k_test['target'].values\n",
    "query_test = msrank_10k_test['query'].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBNKZIf55U9t"
   },
   "source": [
    "У нас есть датасет, в котором представлены запросы в 1 колонке, релевантности в 0 колонке, остальные колонки - это признаки. Необходимо для RankNet сделать такой датасет, что в рамках одного запроса мы будем видеть пары, если первый более релевантен, значит таргет 1, иначе 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737644462827,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "_Z94GctE7Yok",
    "outputId": "989f8002-b3b0-4615-b78c-22517990d4f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   16,   31,   46,   61,   76,   91,  106,  121,  136,  151,\n",
       "        166,  181,  196,  211,  226,  241,  256,  271,  286,  301,  316,\n",
       "        331,  346,  361,  376,  391,  406,  421,  436,  451,  466,  481,\n",
       "        496,  511,  526,  541,  556,  571,  586,  601,  616,  631,  646,\n",
       "        661,  676,  691,  706,  721,  736,  751,  766,  781,  796,  811,\n",
       "        826,  841,  856,  871,  886,  901,  916,  931,  946,  961,  976,\n",
       "        991, 1006, 1021, 1036, 1051, 1066, 1081, 1096, 1111, 1126, 1141,\n",
       "       1156, 1171, 1186, 1201, 1216, 1231, 1246, 1261, 1276, 1291])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(query_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17422,
     "status": "ok",
     "timestamp": 1737644480242,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "xXEhaUR56kXe",
    "outputId": "9956f60f-b881-4d0e-fa2a-b482dd1300e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [00:06<00:00, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of comparison: 750487\n",
      "Classes balance:\n",
      "0.5    333916\n",
      "1.0    209955\n",
      "0.0    206616\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0, 0.5),\n",
       " (1, 0, 1, 0.5),\n",
       " (1, 0, 2, 1),\n",
       " (1, 0, 3, 0.5),\n",
       " (1, 0, 4, 1),\n",
       " (1, 0, 5, 1),\n",
       " (1, 0, 6, 1),\n",
       " (1, 0, 7, 0.5),\n",
       " (1, 0, 8, 1),\n",
       " (1, 0, 9, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 if i-th score larger than j-th\n",
    "\n",
    "comparison = []\n",
    "\n",
    "for query in tqdm(np.unique(query_train)):\n",
    "    subset = msrank_10k_train[msrank_10k_train['query'] == query]\n",
    "    indexes = subset.index\n",
    "\n",
    "    for i, idx1 in enumerate(indexes):\n",
    "        for idx2 in indexes[i:]:\n",
    "            val1 = subset.loc[idx1, 'target']\n",
    "            val2 = subset.loc[idx2, 'target']\n",
    "            if val1 > val2:\n",
    "                comparison.append((query, idx1, idx2, 1))  # i должен быть отранжирован выше j\n",
    "            elif val1 < val2:\n",
    "                comparison.append((query, idx1, idx2, 0))  # j должен быть отранжирован выше i\n",
    "            else:\n",
    "                comparison.append((query, idx1, idx2, 0.5))  # одинаковый ранг\n",
    "\n",
    "print(f'Length of comparison: {len(comparison)}')\n",
    "print(f'Classes balance:\\n{pd.Series(np.array([x[3] for x in comparison])).value_counts()}')\n",
    "\n",
    "comparison[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1 if i-th score larger than j-th\n",
    "# # отдельно для каждого запроса\n",
    "\n",
    "# comparisons = {}\n",
    "\n",
    "# for query in tqdm(np.unique(query_train), position=0, leave=None):\n",
    "#     subset = msrank_10k_train[msrank_10k_train['query'] == query]\n",
    "#     indexes = subset.index\n",
    "#     comparisons[query] = []\n",
    "\n",
    "#     for i, idx1 in enumerate(indexes):\n",
    "#         # for idx2 in indexes[i+1:]:\n",
    "#         for idx2 in indexes:\n",
    "#             val1 = subset.loc[idx1, 'target']\n",
    "#             val2 = subset.loc[idx2, 'target']\n",
    "#             if val1 > val2:\n",
    "#                 comparisons[query].append((query, idx1, idx2, 1))  # i должен быть отранжирован выше j\n",
    "#             elif val1 < val2:\n",
    "#                 comparisons[query].append((query, idx1, idx2, 0))  # j должен быть отранжирован выше i\n",
    "#             else:\n",
    "#                 comparisons[query].append((query, idx1, idx2, 0.5))  # одинаковый ранг\n",
    "\n",
    "#     # print(f'Length of comparison {query}: {len(comparisons[query])}')\n",
    "#     # print(f'Classes balance:\\n{pd.Series(np.array([x[3] for x in comparisons[query]])).value_counts()}')\n",
    "\n",
    "# comparisons[query][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>query</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>feature_130</th>\n",
       "      <th>feature_131</th>\n",
       "      <th>feature_132</th>\n",
       "      <th>feature_133</th>\n",
       "      <th>feature_134</th>\n",
       "      <th>feature_135</th>\n",
       "      <th>feature_136</th>\n",
       "      <th>feature_137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>4.817052</td>\n",
       "      <td>-2.175931</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>4.817052</td>\n",
       "      <td>-2.175932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890364</td>\n",
       "      <td>3.122498</td>\n",
       "      <td>-0.862910</td>\n",
       "      <td>-0.862552</td>\n",
       "      <td>0.770712</td>\n",
       "      <td>0.281923</td>\n",
       "      <td>-0.469119</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391122</td>\n",
       "      <td>3.122498</td>\n",
       "      <td>-0.862910</td>\n",
       "      <td>-0.862023</td>\n",
       "      <td>0.770712</td>\n",
       "      <td>-0.434689</td>\n",
       "      <td>-0.507108</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>-0.313940</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>-0.313940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170526</td>\n",
       "      <td>-0.320409</td>\n",
       "      <td>-0.938022</td>\n",
       "      <td>-0.862023</td>\n",
       "      <td>-2.197231</td>\n",
       "      <td>0.341641</td>\n",
       "      <td>1.962172</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515932</td>\n",
       "      <td>3.122498</td>\n",
       "      <td>-0.036682</td>\n",
       "      <td>-0.862089</td>\n",
       "      <td>0.765773</td>\n",
       "      <td>-0.434689</td>\n",
       "      <td>-0.469119</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015175</td>\n",
       "      <td>-0.320408</td>\n",
       "      <td>-0.487352</td>\n",
       "      <td>-0.853286</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>-0.434689</td>\n",
       "      <td>-0.089230</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890364</td>\n",
       "      <td>-0.320408</td>\n",
       "      <td>-0.487352</td>\n",
       "      <td>-0.856330</td>\n",
       "      <td>0.080637</td>\n",
       "      <td>-0.195818</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890364</td>\n",
       "      <td>-0.320408</td>\n",
       "      <td>-0.487352</td>\n",
       "      <td>-0.853286</td>\n",
       "      <td>0.085527</td>\n",
       "      <td>-0.315254</td>\n",
       "      <td>-0.051241</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>1.576823</td>\n",
       "      <td>-0.320410</td>\n",
       "      <td>0.263764</td>\n",
       "      <td>-0.862618</td>\n",
       "      <td>0.735697</td>\n",
       "      <td>-0.434689</td>\n",
       "      <td>-0.469119</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203906</td>\n",
       "      <td>3.122498</td>\n",
       "      <td>0.113541</td>\n",
       "      <td>-0.862023</td>\n",
       "      <td>0.737898</td>\n",
       "      <td>-0.434689</td>\n",
       "      <td>-0.469119</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>-0.300235</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.234978</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>-0.320409</td>\n",
       "      <td>-0.938022</td>\n",
       "      <td>-0.834421</td>\n",
       "      <td>0.737898</td>\n",
       "      <td>-0.434689</td>\n",
       "      <td>-0.393141</td>\n",
       "      <td>-0.111758</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.266225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  query  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     2.0    1.0   0.316064   4.817052  -2.175931  -0.300235   0.316064   \n",
       "1     2.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "2     0.0    1.0   0.316064  -0.234978  -0.313940  -0.300235   0.316064   \n",
       "3     2.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "4     1.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "5     1.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "6     1.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "7     2.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "8     1.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "9     0.0    1.0   0.316064  -0.234978   0.617055  -0.300235   0.316064   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_128  feature_129  \\\n",
       "0   0.316064   4.817052  -2.175932  ...     0.890364     3.122498   \n",
       "1   0.316064  -0.234978   0.617055  ...     0.391122     3.122498   \n",
       "2   0.316064  -0.234978  -0.313940  ...    -0.170526    -0.320409   \n",
       "3   0.316064  -0.234978   0.617055  ...     0.515932     3.122498   \n",
       "4   0.316064  -0.234978   0.617055  ...     1.015175    -0.320408   \n",
       "5   0.316064  -0.234978   0.617055  ...     0.890364    -0.320408   \n",
       "6   0.316064  -0.234978   0.617055  ...     0.890364    -0.320408   \n",
       "7   0.316064  -0.234978   0.617055  ...     1.576823    -0.320410   \n",
       "8   0.316064  -0.234978   0.617055  ...     0.203906     3.122498   \n",
       "9   0.316064  -0.234978   0.617055  ...     0.016690    -0.320409   \n",
       "\n",
       "   feature_130  feature_131  feature_132  feature_133  feature_134  \\\n",
       "0    -0.862910    -0.862552     0.770712     0.281923    -0.469119   \n",
       "1    -0.862910    -0.862023     0.770712    -0.434689    -0.507108   \n",
       "2    -0.938022    -0.862023    -2.197231     0.341641     1.962172   \n",
       "3    -0.036682    -0.862089     0.765773    -0.434689    -0.469119   \n",
       "4    -0.487352    -0.853286     0.069585    -0.434689    -0.089230   \n",
       "5    -0.487352    -0.856330     0.080637    -0.195818    -0.013252   \n",
       "6    -0.487352    -0.853286     0.085527    -0.315254    -0.051241   \n",
       "7     0.263764    -0.862618     0.735697    -0.434689    -0.469119   \n",
       "8     0.113541    -0.862023     0.737898    -0.434689    -0.469119   \n",
       "9    -0.938022    -0.834421     0.737898    -0.434689    -0.393141   \n",
       "\n",
       "   feature_135  feature_136  feature_137  \n",
       "0    -0.111758    -0.195935    -0.266225  \n",
       "1    -0.111758    -0.195935    -0.266225  \n",
       "2    -0.111758    -0.195935    -0.266225  \n",
       "3    -0.111758    -0.195935    -0.266225  \n",
       "4    -0.111758    -0.195935    -0.266225  \n",
       "5    -0.111758    -0.195935    -0.266225  \n",
       "6    -0.111758    -0.195935    -0.266225  \n",
       "7    -0.111758    -0.195935    -0.266225  \n",
       "8    -0.111758    -0.195935    -0.266225  \n",
       "9    -0.111758    -0.195935    -0.266225  \n",
       "\n",
       "[10 rows x 138 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msrank_10k_train.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1737644480537,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "YDOVxkbh-fHk"
   },
   "outputs": [],
   "source": [
    "class MSRankPairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, comparison):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.comparison = comparison\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comparison)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        query, i, j, target = self.comparison[index]\n",
    "        x_i, x_j = self.data.loc[i, 'feature_2':], self.data.loc[j, 'feature_2':]\n",
    "\n",
    "        return torch.as_tensor(query, dtype=torch.float32),\\\n",
    "        torch.as_tensor(x_i.values, dtype=torch.float32),\\\n",
    "        torch.as_tensor(x_j.values, dtype=torch.float32),\\\n",
    "        torch.as_tensor(target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737644480537,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "cc0uSEEv1Gfr"
   },
   "outputs": [],
   "source": [
    "# msrank_dataset = MSRankPairDataset(msrank_10k_train, comparisons[query])\n",
    "msrank_dataset = MSRankPairDataset(msrank_10k_train, comparison)\n",
    "msrank_dataloader = torch.utils.data.DataLoader(msrank_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737644480537,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "BFxl_Shj4kPQ",
    "outputId": "05ed69a2-aa2c-40d8-b2a0-13836c93eaef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3600e+02, 6.1600e+02, 6.7600e+02, 6.9100e+02, 4.5100e+02, 7.6600e+02,\n",
      "        2.5600e+02, 5.7100e+02, 1.9600e+02, 1.0810e+03, 2.5600e+02, 5.4100e+02,\n",
      "        4.2100e+02, 1.0210e+03, 5.5600e+02, 6.1600e+02, 1.2310e+03, 1.9600e+02,\n",
      "        4.6000e+01, 4.2100e+02, 7.2100e+02, 8.8600e+02, 1.1560e+03, 4.0600e+02,\n",
      "        1.9600e+02, 1.1260e+03, 2.5600e+02, 8.5600e+02, 2.7100e+02, 4.2100e+02,\n",
      "        1.0360e+03, 1.0510e+03, 5.7100e+02, 4.0600e+02, 4.9600e+02, 1.3600e+02,\n",
      "        5.5600e+02, 1.0210e+03, 1.9600e+02, 4.8100e+02, 5.2600e+02, 6.4600e+02,\n",
      "        9.9100e+02, 5.4100e+02, 5.7100e+02, 1.0810e+03, 6.3100e+02, 9.0100e+02,\n",
      "        6.9100e+02, 4.2100e+02, 6.4600e+02, 5.8600e+02, 6.1600e+02, 5.4100e+02,\n",
      "        5.2600e+02, 6.1600e+02, 9.0100e+02, 1.1260e+03, 5.7100e+02, 6.0100e+02,\n",
      "        5.7100e+02, 5.5600e+02, 1.9600e+02, 5.7100e+02, 9.0100e+02, 6.1600e+02,\n",
      "        2.1100e+02, 9.7600e+02, 7.0600e+02, 3.7600e+02, 1.2460e+03, 1.9600e+02,\n",
      "        6.7600e+02, 1.9600e+02, 3.1000e+01, 5.7100e+02, 1.9600e+02, 7.6600e+02,\n",
      "        1.1110e+03, 4.8100e+02, 1.1710e+03, 9.0100e+02, 1.2310e+03, 4.0600e+02,\n",
      "        4.3600e+02, 8.4100e+02, 6.9100e+02, 2.5600e+02, 7.6600e+02, 7.0600e+02,\n",
      "        9.9100e+02, 1.0060e+03, 1.9600e+02, 9.6100e+02, 3.6100e+02, 8.8600e+02,\n",
      "        5.2600e+02, 6.9100e+02, 5.5600e+02, 1.9600e+02, 3.1600e+02, 6.4600e+02,\n",
      "        9.4600e+02, 4.3600e+02, 1.0060e+03, 1.1860e+03, 1.1560e+03, 1.3600e+02,\n",
      "        6.9100e+02, 7.6600e+02, 5.4100e+02, 4.6000e+01, 1.2460e+03, 1.0060e+03,\n",
      "        5.2600e+02, 1.2610e+03, 6.9100e+02, 1.9600e+02, 1.0000e+00, 9.0100e+02,\n",
      "        5.2600e+02, 1.3600e+02, 1.0210e+03, 4.6000e+01, 9.0100e+02, 6.1600e+02,\n",
      "        6.9100e+02, 7.3600e+02])\n",
      "tensor([[ 0.3524, -0.4220,  0.4964,  ..., -0.1267, -0.0789, -0.4441],\n",
      "        [ 0.3241, -0.5990,  0.5448,  ..., -0.1343, -0.1128, -0.2731],\n",
      "        [ 0.3950, -0.5038,  0.5419,  ..., -0.1956, -0.1101, -0.2787],\n",
      "        ...,\n",
      "        [ 0.3241,  1.6693,  0.5448,  ..., -0.1343, -0.1128, -0.2731],\n",
      "        [ 0.4168, -0.4330,  0.5925,  ..., -0.1127,  0.5958, -0.0852],\n",
      "        [ 0.4035, -0.3354,  1.7307,  ..., -0.2463, -0.1698, -0.2660]])\n",
      "tensor([[ 0.3524, -0.4220,  0.4964,  ..., -0.1267, -0.0789, -0.4441],\n",
      "        [ 0.3241, -0.5990,  0.5448,  ..., -0.1343, -0.0992,  0.2412],\n",
      "        [ 0.3950, -0.5038,  0.5419,  ..., -0.1956, -0.2348, -0.2787],\n",
      "        ...,\n",
      "        [ 0.3241, -0.5990,  0.5448,  ..., -0.1343, -0.1128, -0.2731],\n",
      "        [ 0.4168, -0.4330,  0.5925,  ...,  4.6110, -0.1520, -0.0508],\n",
      "        [ 0.4035, -0.3354,  1.7307,  ..., -0.2463, -0.1698, -0.2660]])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.0000, 0.5000, 1.0000, 0.5000,\n",
      "        0.5000, 0.0000, 1.0000, 0.0000, 0.5000, 1.0000, 0.5000, 1.0000, 1.0000,\n",
      "        1.0000, 0.5000, 0.0000, 0.0000, 1.0000, 0.0000, 0.5000, 0.0000, 1.0000,\n",
      "        0.5000, 1.0000, 0.5000, 0.5000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.5000, 1.0000, 1.0000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 0.0000, 1.0000,\n",
      "        0.5000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.5000, 1.0000, 1.0000,\n",
      "        0.5000, 0.5000, 1.0000, 1.0000, 0.5000, 0.0000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 1.0000, 0.5000, 0.5000, 1.0000,\n",
      "        0.5000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.0000, 0.0000,\n",
      "        0.5000, 0.5000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.5000,\n",
      "        0.0000, 0.5000, 1.0000, 1.0000, 1.0000, 0.5000, 1.0000, 0.5000, 0.5000,\n",
      "        1.0000, 1.0000, 0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 0.0000, 1.0000,\n",
      "        1.0000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "for query, first, second, tgt in msrank_dataloader:\n",
    "    print(query)\n",
    "    print(first)\n",
    "    print(second)\n",
    "    print(tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737644480537,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "_oLFLIEX4j54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model works\n",
    "\n",
    "ranknet_model = RankNet(num_input_features=136)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "preds = ranknet_model(first, second)\n",
    "criterion(preds, tgt.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нужно пройтись по каждому запросу в обучении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = {}\n",
    "# dataloaders = {}\n",
    "\n",
    "# for query in np.unique(query_train):\n",
    "#     subset = msrank_10k_train.loc[msrank_10k_train['query'] == query]\n",
    "#     dataset = MSRankPairDataset(data=subset, comparison=comparisons[query])\n",
    "#     datasets[query] = dataset\n",
    "#     dataloaders[query] = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1737644480537,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "RanRTdNKOk_W"
   },
   "outputs": [],
   "source": [
    "# случайная подвыборка тестового датасета\n",
    "\n",
    "# idx = np.random.choice(msrank_10k_test.shape[0], 1000)\n",
    "# test_x = torch.as_tensor(msrank_10k_test.loc[idx, 'feature_2':].values, dtype=torch.float32).to(device)\n",
    "# test_y = torch.as_tensor(msrank_10k_test.loc[idx, 'target'].values, dtype=torch.float32).to(device)\n",
    "# test_query = msrank_10k_test.loc[idx, 'query'].values\n",
    "\n",
    "# N_valid = test_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gain(y_value: float, gain_scheme: str) -> float:\n",
    "  assert gain_scheme in ['const', 'exp2']\n",
    "  if gain_scheme == 'const':\n",
    "      return y_value\n",
    "  elif gain_scheme == 'exp2':\n",
    "      return 2 ** y_value - 1\n",
    "\n",
    "\n",
    "def dcg_k(ys_true: Tensor, ys_pred: Tensor, gain_scheme: str, k: int) -> float:\n",
    "    dcg_value = 0\n",
    "    _, sorted_ys_pred_idx = sort(ys_pred, descending=True)\n",
    "    for i, rel in enumerate(ys_true[sorted_ys_pred_idx][:k]):\n",
    "        dcg_value += compute_gain(rel, gain_scheme=gain_scheme) / log2(i+2)\n",
    "    return dcg_value\n",
    "\n",
    "\n",
    "def ndcg_k(ys_true: Tensor, ys_pred: Tensor, gain_scheme: str = 'const', k=5) -> float:\n",
    "    dcg_value = dcg_k(ys_true, ys_pred, gain_scheme=gain_scheme, k=k)\n",
    "    perfect_dcg = dcg_k(ys_true, ys_true, gain_scheme=gain_scheme, k=k)\n",
    "\n",
    "    return dcg_value / perfect_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model = RankNet(num_input_features=136, hidden_dim=32)\n",
    "ranknet_model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(ranknet_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss: 0.6381915278817132\n",
      "epoch: 1.\tNumber of swapped pairs: 4406.0/9453\tnDCG_at_10: 0.3652\n",
      "epoch: 1.\tNumber of swapped pairs: 1731.0/4371\tnDCG_at_10: 0.4355\n",
      "epoch: 1.\tNumber of swapped pairs: 1382.0/3655\tnDCG_at_10: 0.5105\n",
      "epoch: 1.\tNumber of swapped pairs: 5048.0/10878\tnDCG_at_10: 0.2458\n",
      "epoch: 1.\tNumber of swapped pairs: 3300.0/7503\tnDCG_at_10: 0.5711\n",
      "epoch: 1.\tNumber of swapped pairs: 5591.0/14028\tnDCG_at_10: 0.5415\n",
      "epoch: 1.\tNumber of swapped pairs: 3541.0/7260\tnDCG_at_10: 0.3957\n",
      "epoch: 1.\tNumber of swapped pairs: 3225.0/9316\tnDCG_at_10: 0.5379\n",
      "epoch: 1.\tNumber of swapped pairs: 705.0/1711\tnDCG_at_10: 0.2631\n",
      "epoch: 1.\tNumber of swapped pairs: 2700.0/6555\tnDCG_at_10: 0.0886\n",
      "epoch: 1.\tNumber of swapped pairs: 3483.0/8646\tnDCG_at_10: 0.2317\n",
      "epoch: 1.\tNumber of swapped pairs: 1892.0/3570\tnDCG_at_10: 0.1662\n",
      "epoch: 1.\tNumber of swapped pairs: 8656.0/19503\tnDCG_at_10: 0.1516\n",
      "epoch: 1.\tNumber of swapped pairs: 3410.0/7875\tnDCG_at_10: 0.1640\n",
      "epoch: 1.\tNumber of swapped pairs: 3876.0/7875\tnDCG_at_10: 0.2863\n",
      "epoch: 1.\tNumber of swapped pairs: 3910.0/9591\tnDCG_at_10: 0.5212\n",
      "epoch: 1.\tNumber of swapped pairs: 1867.0/4005\tnDCG_at_10: 0.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 3228.0/7503\tnDCG_at_10: 0.4631\n",
      "epoch: 1.\tNumber of swapped pairs: 7333.0/17205\tnDCG_at_10: 0.5207\n",
      "epoch: 1.\tNumber of swapped pairs: 2575.0/6903\tnDCG_at_10: 0.6235\n",
      "epoch: 1.\tNumber of swapped pairs: 210.0/435\tnDCG_at_10: 0.4485\n",
      "epoch: 1.\tNumber of swapped pairs: 3000.0/7875\tnDCG_at_10: 0.5080\n",
      "epoch: 1.\tNumber of swapped pairs: 422.0/861\tnDCG_at_10: 0.2014\n",
      "epoch: 1.\tNumber of swapped pairs: 6595.0/13695\tnDCG_at_10: 0.3786\n",
      "epoch: 1.\tNumber of swapped pairs: 1253.0/3003\tnDCG_at_10: 0.3465\n",
      "epoch: 1.\tNumber of swapped pairs: 1237.0/2926\tnDCG_at_10: 0.3297\n",
      "epoch: 1.\tNumber of swapped pairs: 4577.0/11628\tnDCG_at_10: 0.5223\n",
      "epoch: 1.\tNumber of swapped pairs: 1225.0/3321\tnDCG_at_10: 0.6054\n",
      "epoch: 1.\tNumber of swapped pairs: 2724.0/7021\tnDCG_at_10: 0.6891\n",
      "epoch: 1.\tNumber of swapped pairs: 1808.0/4371\tnDCG_at_10: 0.5879\n",
      "epoch: 1.\tNumber of swapped pairs: 279.0/903\tnDCG_at_10: 0.6173\n",
      "epoch: 1.\tNumber of swapped pairs: 2397.0/6903\tnDCG_at_10: 0.8362\n",
      "epoch: 1.\tNumber of swapped pairs: 2729.0/6786\tnDCG_at_10: 0.5816\n",
      "epoch: 1.\tNumber of swapped pairs: 12218.0/26106\tnDCG_at_10: 0.2089\n",
      "epoch: 1.\tNumber of swapped pairs: 7771.0/16836\tnDCG_at_10: 0.3895\n",
      "epoch: 1.\tNumber of swapped pairs: 1665.0/4465\tnDCG_at_10: 0.5275\n",
      "epoch: 1.\tNumber of swapped pairs: 1574.0/4095\tnDCG_at_10: 0.6015\n",
      "epoch: 1.\tNumber of swapped pairs: 2271.0/5995\tnDCG_at_10: 0.1593\n",
      "epoch: 1.\tNumber of swapped pairs: 4345.0/11781\tnDCG_at_10: 0.8049\n",
      "epoch: 1.\tNumber of swapped pairs: 6066.0/13041\tnDCG_at_10: 0.3802\n",
      "epoch: 1.\tNumber of swapped pairs: 3718.0/9045\tnDCG_at_10: 0.4726\n",
      "epoch: 1.\tNumber of swapped pairs: 411.0/1596\tnDCG_at_10: 0.7355\n",
      "epoch: 1.\tNumber of swapped pairs: 892.0/2211\tnDCG_at_10: 0.5247\n",
      "epoch: 1.\tNumber of swapped pairs: 29941.0/68265\tnDCG_at_10: 0.5524\n",
      "epoch: 1.\tNumber of swapped pairs: 1796.0/5151\tnDCG_at_10: 0.2263\n",
      "epoch: 1.\tNumber of swapped pairs: 1928.0/4950\tnDCG_at_10: 0.3415\n",
      "epoch: 1.\tNumber of swapped pairs: 932.0/2556\tnDCG_at_10: 0.6281\n",
      "epoch: 1.\tNumber of swapped pairs: 6836.0/16471\tnDCG_at_10: 0.5874\n",
      "epoch: 1.\tNumber of swapped pairs: 1203.0/3570\tnDCG_at_10: 0.8639\n",
      "epoch: 1.\tNumber of swapped pairs: 12011.0/25425\tnDCG_at_10: 0.1814\n",
      "epoch: 1.\tNumber of swapped pairs: 12203.0/26565\tnDCG_at_10: 0.1304\n",
      "epoch: 1.\tNumber of swapped pairs: 874.0/1596\tnDCG_at_10: 0.3287\n",
      "epoch: 1.\tNumber of swapped pairs: 3018.0/8256\tnDCG_at_10: 0.4820\n",
      "epoch: 1.\tNumber of swapped pairs: 764.0/2850\tnDCG_at_10: 0.5190\n",
      "epoch: 1.\tNumber of swapped pairs: 1683.0/3240\tnDCG_at_10: 0.0601\n",
      "epoch: 1.\tNumber of swapped pairs: 573.0/1540\tnDCG_at_10: 0.3207\n",
      "epoch: 1.\tNumber of swapped pairs: 1056.0/2145\tnDCG_at_10: 0.4212\n",
      "epoch: 1.\tNumber of swapped pairs: 3454.0/7503\tnDCG_at_10: 0.2589\n",
      "epoch: 1.\tNumber of swapped pairs: 3288.0/7626\tnDCG_at_10: 0.6051\n",
      "epoch: 1.\tNumber of swapped pairs: 2439.0/6555\tnDCG_at_10: 0.4775\n",
      "epoch: 1.\tNumber of swapped pairs: 7177.0/15576\tnDCG_at_10: 0.5253\n",
      "epoch: 1.\tNumber of swapped pairs: 1537.0/4005\tnDCG_at_10: 0.5560\n",
      "epoch: 1.\tNumber of swapped pairs: 2256.0/4656\tnDCG_at_10: 0.1120\n",
      "epoch: 1.\tNumber of swapped pairs: 607.0/1326\tnDCG_at_10: 0.2658\n",
      "epoch: 1.\tNumber of swapped pairs: 1508.0/4560\tnDCG_at_10: 0.7949\n",
      "epoch: 1.\tNumber of swapped pairs: 2185.0/5356\tnDCG_at_10: 0.7414\n",
      "epoch: 1.\tNumber of swapped pairs: 4849.0/10011\tnDCG_at_10: 0.1909\n",
      "epoch: 1.\tNumber of swapped pairs: 1293.0/3741\tnDCG_at_10: 0.6675\n",
      "epoch: 1.\tNumber of swapped pairs: 2324.0/5050\tnDCG_at_10: 0.5365\n",
      "epoch: 1.\tNumber of swapped pairs: 1536.0/3916\tnDCG_at_10: 0.6838\n",
      "epoch: 1.\tNumber of swapped pairs: 1043.0/2628\tnDCG_at_10: 0.2830\n",
      "epoch: 1.\tNumber of swapped pairs: 6074.0/14028\tnDCG_at_10: 0.5143\n",
      "epoch: 1.\tNumber of swapped pairs: 355.0/903\tnDCG_at_10: 0.5382\n",
      "epoch: 1.\tNumber of swapped pairs: 3671.0/8911\tnDCG_at_10: 0.0856\n",
      "epoch: 1.\tNumber of swapped pairs: 590.0/1275\tnDCG_at_10: 0.0980\n",
      "epoch: 1.\tNumber of swapped pairs: 972.0/2211\tnDCG_at_10: 0.5903\n",
      "epoch: 1.\tNumber of swapped pairs: 309.0/820\tnDCG_at_10: 0.3224\n",
      "epoch: 1.\tNumber of swapped pairs: 2317.0/6786\tnDCG_at_10: 0.7862\n",
      "epoch: 1.\tNumber of swapped pairs: 1120.0/3240\tnDCG_at_10: 0.7336\n",
      "epoch: 1.\tNumber of swapped pairs: 1243.0/3160\tnDCG_at_10: 0.5993\n",
      "epoch: 1.\tNumber of swapped pairs: 2037.0/4560\tnDCG_at_10: 0.0897\n",
      "epoch: 1.\tNumber of swapped pairs: 5663.0/13203\tnDCG_at_10: 0.3103\n",
      "epoch: 1.\tNumber of swapped pairs: 1616.0/4186\tnDCG_at_10: 0.4483\n",
      "epoch: 1.\tNumber of swapped pairs: 5775.0/13695\tnDCG_at_10: 0.6869\n",
      "epoch: 1.\tNumber of swapped pairs: 233.0/861\tnDCG_at_10: 0.6890\n",
      "epoch: 1.\tNumber of swapped pairs: 4320.0/12090\tnDCG_at_10: 0.5425\n",
      "epoch: 1.\tNumber of swapped pairs: 5683.0/12246\tnDCG_at_10: 0.4321\n",
      "epoch: 1.\tNumber of swapped pairs: nan/1\tnDCG_at_10: 1.0000\n",
      "Mean NDCG: 0.447141170501709\n",
      "Epoch: 1\n",
      "Train loss: 0.613798686242899\n",
      "epoch: 2.\tNumber of swapped pairs: 4571.0/9453\tnDCG_at_10: 0.3211\n",
      "epoch: 2.\tNumber of swapped pairs: 1741.0/4371\tnDCG_at_10: 0.4978\n",
      "epoch: 2.\tNumber of swapped pairs: 1384.0/3655\tnDCG_at_10: 0.3727\n",
      "epoch: 2.\tNumber of swapped pairs: 5485.0/10878\tnDCG_at_10: 0.2074\n",
      "epoch: 2.\tNumber of swapped pairs: 3429.0/7503\tnDCG_at_10: 0.4819\n",
      "epoch: 2.\tNumber of swapped pairs: 5560.0/14028\tnDCG_at_10: 0.5633\n",
      "epoch: 2.\tNumber of swapped pairs: 3468.0/7260\tnDCG_at_10: 0.2646\n",
      "epoch: 2.\tNumber of swapped pairs: 3345.0/9316\tnDCG_at_10: 0.4298\n",
      "epoch: 2.\tNumber of swapped pairs: 760.0/1711\tnDCG_at_10: 0.1503\n",
      "epoch: 2.\tNumber of swapped pairs: 2660.0/6555\tnDCG_at_10: 0.1772\n",
      "epoch: 2.\tNumber of swapped pairs: 3369.0/8646\tnDCG_at_10: 0.3854\n",
      "epoch: 2.\tNumber of swapped pairs: 2043.0/3570\tnDCG_at_10: 0.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 9034.0/19503\tnDCG_at_10: 0.1458\n",
      "epoch: 2.\tNumber of swapped pairs: 3304.0/7875\tnDCG_at_10: 0.1651\n",
      "epoch: 2.\tNumber of swapped pairs: 3620.0/7875\tnDCG_at_10: 0.2051\n",
      "epoch: 2.\tNumber of swapped pairs: 3847.0/9591\tnDCG_at_10: 0.5205\n",
      "epoch: 2.\tNumber of swapped pairs: 1930.0/4005\tnDCG_at_10: 0.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 3251.0/7503\tnDCG_at_10: 0.3248\n",
      "epoch: 2.\tNumber of swapped pairs: 7469.0/17205\tnDCG_at_10: 0.5215\n",
      "epoch: 2.\tNumber of swapped pairs: 2660.0/6903\tnDCG_at_10: 0.4703\n",
      "epoch: 2.\tNumber of swapped pairs: 220.0/435\tnDCG_at_10: 0.4090\n",
      "epoch: 2.\tNumber of swapped pairs: 3398.0/7875\tnDCG_at_10: 0.3941\n",
      "epoch: 2.\tNumber of swapped pairs: 446.0/861\tnDCG_at_10: 0.1151\n",
      "epoch: 2.\tNumber of swapped pairs: 6443.0/13695\tnDCG_at_10: 0.4539\n",
      "epoch: 2.\tNumber of swapped pairs: 1310.0/3003\tnDCG_at_10: 0.2279\n",
      "epoch: 2.\tNumber of swapped pairs: 1305.0/2926\tnDCG_at_10: 0.2205\n",
      "epoch: 2.\tNumber of swapped pairs: 4429.0/11628\tnDCG_at_10: 0.5232\n",
      "epoch: 2.\tNumber of swapped pairs: 1253.0/3321\tnDCG_at_10: 0.7049\n",
      "epoch: 2.\tNumber of swapped pairs: 2740.0/7021\tnDCG_at_10: 0.6373\n",
      "epoch: 2.\tNumber of swapped pairs: 1806.0/4371\tnDCG_at_10: 0.5483\n",
      "epoch: 2.\tNumber of swapped pairs: 316.0/903\tnDCG_at_10: 0.4825\n",
      "epoch: 2.\tNumber of swapped pairs: 2437.0/6903\tnDCG_at_10: 0.7765\n",
      "epoch: 2.\tNumber of swapped pairs: 2802.0/6786\tnDCG_at_10: 0.4935\n",
      "epoch: 2.\tNumber of swapped pairs: 11956.0/26106\tnDCG_at_10: 0.1344\n",
      "epoch: 2.\tNumber of swapped pairs: 7674.0/16836\tnDCG_at_10: 0.3500\n",
      "epoch: 2.\tNumber of swapped pairs: 1619.0/4465\tnDCG_at_10: 0.5473\n",
      "epoch: 2.\tNumber of swapped pairs: 1660.0/4095\tnDCG_at_10: 0.5316\n",
      "epoch: 2.\tNumber of swapped pairs: 2445.0/5995\tnDCG_at_10: 0.1755\n",
      "epoch: 2.\tNumber of swapped pairs: 4329.0/11781\tnDCG_at_10: 0.7386\n",
      "epoch: 2.\tNumber of swapped pairs: 6527.0/13041\tnDCG_at_10: 0.3469\n",
      "epoch: 2.\tNumber of swapped pairs: 3807.0/9045\tnDCG_at_10: 0.3879\n",
      "epoch: 2.\tNumber of swapped pairs: 398.0/1596\tnDCG_at_10: 0.8313\n",
      "epoch: 2.\tNumber of swapped pairs: 904.0/2211\tnDCG_at_10: 0.5224\n",
      "epoch: 2.\tNumber of swapped pairs: 30430.0/68265\tnDCG_at_10: 0.3279\n",
      "epoch: 2.\tNumber of swapped pairs: 2013.0/5151\tnDCG_at_10: 0.2656\n",
      "epoch: 2.\tNumber of swapped pairs: 2009.0/4950\tnDCG_at_10: 0.4832\n",
      "epoch: 2.\tNumber of swapped pairs: 896.0/2556\tnDCG_at_10: 0.6293\n",
      "epoch: 2.\tNumber of swapped pairs: 6690.0/16471\tnDCG_at_10: 0.6498\n",
      "epoch: 2.\tNumber of swapped pairs: 1291.0/3570\tnDCG_at_10: 0.7812\n",
      "epoch: 2.\tNumber of swapped pairs: 12762.0/25425\tnDCG_at_10: 0.0948\n",
      "epoch: 2.\tNumber of swapped pairs: 12498.0/26565\tnDCG_at_10: 0.0991\n",
      "epoch: 2.\tNumber of swapped pairs: 840.0/1596\tnDCG_at_10: 0.1272\n",
      "epoch: 2.\tNumber of swapped pairs: 3117.0/8256\tnDCG_at_10: 0.4565\n",
      "epoch: 2.\tNumber of swapped pairs: 659.0/2850\tnDCG_at_10: 0.6639\n",
      "epoch: 2.\tNumber of swapped pairs: 1540.0/3240\tnDCG_at_10: 0.2446\n",
      "epoch: 2.\tNumber of swapped pairs: 508.0/1540\tnDCG_at_10: 0.3576\n",
      "epoch: 2.\tNumber of swapped pairs: 989.0/2145\tnDCG_at_10: 0.3230\n",
      "epoch: 2.\tNumber of swapped pairs: 3563.0/7503\tnDCG_at_10: 0.1064\n",
      "epoch: 2.\tNumber of swapped pairs: 3288.0/7626\tnDCG_at_10: 0.6520\n",
      "epoch: 2.\tNumber of swapped pairs: 2682.0/6555\tnDCG_at_10: 0.5376\n",
      "epoch: 2.\tNumber of swapped pairs: 7228.0/15576\tnDCG_at_10: 0.3697\n",
      "epoch: 2.\tNumber of swapped pairs: 1576.0/4005\tnDCG_at_10: 0.5365\n",
      "epoch: 2.\tNumber of swapped pairs: 2288.0/4656\tnDCG_at_10: 0.1491\n",
      "epoch: 2.\tNumber of swapped pairs: 613.0/1326\tnDCG_at_10: 0.2658\n",
      "epoch: 2.\tNumber of swapped pairs: 1718.0/4560\tnDCG_at_10: 0.6923\n",
      "epoch: 2.\tNumber of swapped pairs: 2227.0/5356\tnDCG_at_10: 0.5688\n",
      "epoch: 2.\tNumber of swapped pairs: 4937.0/10011\tnDCG_at_10: 0.1391\n",
      "epoch: 2.\tNumber of swapped pairs: 1289.0/3741\tnDCG_at_10: 0.6335\n",
      "epoch: 2.\tNumber of swapped pairs: 2492.0/5050\tnDCG_at_10: 0.6557\n",
      "epoch: 2.\tNumber of swapped pairs: 1668.0/3916\tnDCG_at_10: 0.6972\n",
      "epoch: 2.\tNumber of swapped pairs: 1121.0/2628\tnDCG_at_10: 0.2419\n",
      "epoch: 2.\tNumber of swapped pairs: 6304.0/14028\tnDCG_at_10: 0.4194\n",
      "epoch: 2.\tNumber of swapped pairs: 353.0/903\tnDCG_at_10: 0.6591\n",
      "epoch: 2.\tNumber of swapped pairs: 3683.0/8911\tnDCG_at_10: 0.0973\n",
      "epoch: 2.\tNumber of swapped pairs: 635.0/1275\tnDCG_at_10: 0.0902\n",
      "epoch: 2.\tNumber of swapped pairs: 989.0/2211\tnDCG_at_10: 0.7055\n",
      "epoch: 2.\tNumber of swapped pairs: 304.0/820\tnDCG_at_10: 0.2882\n",
      "epoch: 2.\tNumber of swapped pairs: 2503.0/6786\tnDCG_at_10: 0.8199\n",
      "epoch: 2.\tNumber of swapped pairs: 954.0/3240\tnDCG_at_10: 0.6117\n",
      "epoch: 2.\tNumber of swapped pairs: 1222.0/3160\tnDCG_at_10: 0.5533\n",
      "epoch: 2.\tNumber of swapped pairs: 2041.0/4560\tnDCG_at_10: 0.1242\n",
      "epoch: 2.\tNumber of swapped pairs: 5688.0/13203\tnDCG_at_10: 0.3694\n",
      "epoch: 2.\tNumber of swapped pairs: 1737.0/4186\tnDCG_at_10: 0.3249\n",
      "epoch: 2.\tNumber of swapped pairs: 5605.0/13695\tnDCG_at_10: 0.7450\n",
      "epoch: 2.\tNumber of swapped pairs: 287.0/861\tnDCG_at_10: 0.9159\n",
      "epoch: 2.\tNumber of swapped pairs: 4164.0/12090\tnDCG_at_10: 0.6328\n",
      "epoch: 2.\tNumber of swapped pairs: 5472.0/12246\tnDCG_at_10: 0.3700\n",
      "epoch: 2.\tNumber of swapped pairs: nan/1\tnDCG_at_10: 1.0000\n",
      "Mean NDCG: 0.42310380935668945\n",
      "Epoch: 2\n",
      "Train loss: 0.6036616836141333\n",
      "epoch: 3.\tNumber of swapped pairs: 4485.0/9453\tnDCG_at_10: 0.3214\n",
      "epoch: 3.\tNumber of swapped pairs: 1813.0/4371\tnDCG_at_10: 0.4507\n",
      "epoch: 3.\tNumber of swapped pairs: 1424.0/3655\tnDCG_at_10: 0.3750\n",
      "epoch: 3.\tNumber of swapped pairs: 5664.0/10878\tnDCG_at_10: 0.1746\n",
      "epoch: 3.\tNumber of swapped pairs: 3358.0/7503\tnDCG_at_10: 0.4855\n",
      "epoch: 3.\tNumber of swapped pairs: 5650.0/14028\tnDCG_at_10: 0.5610\n",
      "epoch: 3.\tNumber of swapped pairs: 3369.0/7260\tnDCG_at_10: 0.3370\n",
      "epoch: 3.\tNumber of swapped pairs: 3431.0/9316\tnDCG_at_10: 0.3931\n",
      "epoch: 3.\tNumber of swapped pairs: 746.0/1711\tnDCG_at_10: 0.1600\n",
      "epoch: 3.\tNumber of swapped pairs: 2669.0/6555\tnDCG_at_10: 0.1894\n",
      "epoch: 3.\tNumber of swapped pairs: 3342.0/8646\tnDCG_at_10: 0.3121\n",
      "epoch: 3.\tNumber of swapped pairs: 2048.0/3570\tnDCG_at_10: 0.0000\n",
      "epoch: 3.\tNumber of swapped pairs: 8907.0/19503\tnDCG_at_10: 0.1813\n",
      "epoch: 3.\tNumber of swapped pairs: 3251.0/7875\tnDCG_at_10: 0.2638\n",
      "epoch: 3.\tNumber of swapped pairs: 3532.0/7875\tnDCG_at_10: 0.0784\n",
      "epoch: 3.\tNumber of swapped pairs: 3920.0/9591\tnDCG_at_10: 0.4755\n",
      "epoch: 3.\tNumber of swapped pairs: 1902.0/4005\tnDCG_at_10: 0.0000\n",
      "epoch: 3.\tNumber of swapped pairs: 3236.0/7503\tnDCG_at_10: 0.3162\n",
      "epoch: 3.\tNumber of swapped pairs: 7694.0/17205\tnDCG_at_10: 0.4933\n",
      "epoch: 3.\tNumber of swapped pairs: 2691.0/6903\tnDCG_at_10: 0.5265\n",
      "epoch: 3.\tNumber of swapped pairs: 247.0/435\tnDCG_at_10: 0.3089\n",
      "epoch: 3.\tNumber of swapped pairs: 3248.0/7875\tnDCG_at_10: 0.4015\n",
      "epoch: 3.\tNumber of swapped pairs: 414.0/861\tnDCG_at_10: 0.1151\n",
      "epoch: 3.\tNumber of swapped pairs: 6520.0/13695\tnDCG_at_10: 0.4192\n",
      "epoch: 3.\tNumber of swapped pairs: 1419.0/3003\tnDCG_at_10: 0.2619\n",
      "epoch: 3.\tNumber of swapped pairs: 1330.0/2926\tnDCG_at_10: 0.4195\n",
      "epoch: 3.\tNumber of swapped pairs: 4330.0/11628\tnDCG_at_10: 0.5413\n",
      "epoch: 3.\tNumber of swapped pairs: 1206.0/3321\tnDCG_at_10: 0.7039\n",
      "epoch: 3.\tNumber of swapped pairs: 2767.0/7021\tnDCG_at_10: 0.5118\n",
      "epoch: 3.\tNumber of swapped pairs: 1921.0/4371\tnDCG_at_10: 0.3827\n",
      "epoch: 3.\tNumber of swapped pairs: 330.0/903\tnDCG_at_10: 0.5877\n",
      "epoch: 3.\tNumber of swapped pairs: 2304.0/6903\tnDCG_at_10: 0.8122\n",
      "epoch: 3.\tNumber of swapped pairs: 2856.0/6786\tnDCG_at_10: 0.5796\n",
      "epoch: 3.\tNumber of swapped pairs: 12063.0/26106\tnDCG_at_10: 0.1344\n",
      "epoch: 3.\tNumber of swapped pairs: 7843.0/16836\tnDCG_at_10: 0.4107\n",
      "epoch: 3.\tNumber of swapped pairs: 1829.0/4465\tnDCG_at_10: 0.4311\n",
      "epoch: 3.\tNumber of swapped pairs: 1629.0/4095\tnDCG_at_10: 0.5377\n",
      "epoch: 3.\tNumber of swapped pairs: 2474.0/5995\tnDCG_at_10: 0.2558\n",
      "epoch: 3.\tNumber of swapped pairs: 4534.0/11781\tnDCG_at_10: 0.7829\n",
      "epoch: 3.\tNumber of swapped pairs: 6406.0/13041\tnDCG_at_10: 0.3449\n",
      "epoch: 3.\tNumber of swapped pairs: 3928.0/9045\tnDCG_at_10: 0.3860\n",
      "epoch: 3.\tNumber of swapped pairs: 412.0/1596\tnDCG_at_10: 0.8381\n",
      "epoch: 3.\tNumber of swapped pairs: 915.0/2211\tnDCG_at_10: 0.5919\n",
      "epoch: 3.\tNumber of swapped pairs: 30074.0/68265\tnDCG_at_10: 0.5146\n",
      "epoch: 3.\tNumber of swapped pairs: 2079.0/5151\tnDCG_at_10: 0.1361\n",
      "epoch: 3.\tNumber of swapped pairs: 2160.0/4950\tnDCG_at_10: 0.4127\n",
      "epoch: 3.\tNumber of swapped pairs: 883.0/2556\tnDCG_at_10: 0.5664\n",
      "epoch: 3.\tNumber of swapped pairs: 6785.0/16471\tnDCG_at_10: 0.6563\n",
      "epoch: 3.\tNumber of swapped pairs: 1385.0/3570\tnDCG_at_10: 0.7812\n",
      "epoch: 3.\tNumber of swapped pairs: 13161.0/25425\tnDCG_at_10: 0.1266\n",
      "epoch: 3.\tNumber of swapped pairs: 12483.0/26565\tnDCG_at_10: 0.1322\n",
      "epoch: 3.\tNumber of swapped pairs: 876.0/1596\tnDCG_at_10: 0.1096\n",
      "epoch: 3.\tNumber of swapped pairs: 3220.0/8256\tnDCG_at_10: 0.4525\n",
      "epoch: 3.\tNumber of swapped pairs: 677.0/2850\tnDCG_at_10: 0.6599\n",
      "epoch: 3.\tNumber of swapped pairs: 1562.0/3240\tnDCG_at_10: 0.0601\n",
      "epoch: 3.\tNumber of swapped pairs: 535.0/1540\tnDCG_at_10: 0.5309\n",
      "epoch: 3.\tNumber of swapped pairs: 1018.0/2145\tnDCG_at_10: 0.3960\n",
      "epoch: 3.\tNumber of swapped pairs: 3471.0/7503\tnDCG_at_10: 0.1653\n",
      "epoch: 3.\tNumber of swapped pairs: 3216.0/7626\tnDCG_at_10: 0.5502\n",
      "epoch: 3.\tNumber of swapped pairs: 2633.0/6555\tnDCG_at_10: 0.5465\n",
      "epoch: 3.\tNumber of swapped pairs: 7101.0/15576\tnDCG_at_10: 0.3170\n",
      "epoch: 3.\tNumber of swapped pairs: 1627.0/4005\tnDCG_at_10: 0.3962\n",
      "epoch: 3.\tNumber of swapped pairs: 2293.0/4656\tnDCG_at_10: 0.2161\n",
      "epoch: 3.\tNumber of swapped pairs: 607.0/1326\tnDCG_at_10: 0.3354\n",
      "epoch: 3.\tNumber of swapped pairs: 1654.0/4560\tnDCG_at_10: 0.7758\n",
      "epoch: 3.\tNumber of swapped pairs: 2260.0/5356\tnDCG_at_10: 0.6954\n",
      "epoch: 3.\tNumber of swapped pairs: 4953.0/10011\tnDCG_at_10: 0.2081\n",
      "epoch: 3.\tNumber of swapped pairs: 1278.0/3741\tnDCG_at_10: 0.6482\n",
      "epoch: 3.\tNumber of swapped pairs: 2572.0/5050\tnDCG_at_10: 0.5019\n",
      "epoch: 3.\tNumber of swapped pairs: 1681.0/3916\tnDCG_at_10: 0.6518\n",
      "epoch: 3.\tNumber of swapped pairs: 1023.0/2628\tnDCG_at_10: 0.2224\n",
      "epoch: 3.\tNumber of swapped pairs: 6483.0/14028\tnDCG_at_10: 0.4396\n",
      "epoch: 3.\tNumber of swapped pairs: 348.0/903\tnDCG_at_10: 0.6574\n",
      "epoch: 3.\tNumber of swapped pairs: 3624.0/8911\tnDCG_at_10: 0.1814\n",
      "epoch: 3.\tNumber of swapped pairs: 604.0/1275\tnDCG_at_10: 0.1091\n",
      "epoch: 3.\tNumber of swapped pairs: 1063.0/2211\tnDCG_at_10: 0.6043\n",
      "epoch: 3.\tNumber of swapped pairs: 383.0/820\tnDCG_at_10: 0.2786\n",
      "epoch: 3.\tNumber of swapped pairs: 2642.0/6786\tnDCG_at_10: 0.7829\n",
      "epoch: 3.\tNumber of swapped pairs: 990.0/3240\tnDCG_at_10: 0.5858\n",
      "epoch: 3.\tNumber of swapped pairs: 1280.0/3160\tnDCG_at_10: 0.4875\n",
      "epoch: 3.\tNumber of swapped pairs: 2161.0/4560\tnDCG_at_10: 0.1242\n",
      "epoch: 3.\tNumber of swapped pairs: 5640.0/13203\tnDCG_at_10: 0.4288\n",
      "epoch: 3.\tNumber of swapped pairs: 1758.0/4186\tnDCG_at_10: 0.3724\n",
      "epoch: 3.\tNumber of swapped pairs: 5616.0/13695\tnDCG_at_10: 0.7146\n",
      "epoch: 3.\tNumber of swapped pairs: 315.0/861\tnDCG_at_10: 0.8776\n",
      "epoch: 3.\tNumber of swapped pairs: 4219.0/12090\tnDCG_at_10: 0.5468\n",
      "epoch: 3.\tNumber of swapped pairs: 5635.0/12246\tnDCG_at_10: 0.3380\n",
      "epoch: 3.\tNumber of swapped pairs: nan/1\tnDCG_at_10: 1.0000\n",
      "Mean NDCG: 0.4221348464488983\n",
      "Epoch: 3\n",
      "Train loss: 0.5971859742215648\n",
      "epoch: 4.\tNumber of swapped pairs: 4598.0/9453\tnDCG_at_10: 0.3549\n",
      "epoch: 4.\tNumber of swapped pairs: 1988.0/4371\tnDCG_at_10: 0.4542\n",
      "epoch: 4.\tNumber of swapped pairs: 1318.0/3655\tnDCG_at_10: 0.3682\n",
      "epoch: 4.\tNumber of swapped pairs: 5612.0/10878\tnDCG_at_10: 0.1771\n",
      "epoch: 4.\tNumber of swapped pairs: 3254.0/7503\tnDCG_at_10: 0.4030\n",
      "epoch: 4.\tNumber of swapped pairs: 6201.0/14028\tnDCG_at_10: 0.5609\n",
      "epoch: 4.\tNumber of swapped pairs: 3157.0/7260\tnDCG_at_10: 0.4233\n",
      "epoch: 4.\tNumber of swapped pairs: 3523.0/9316\tnDCG_at_10: 0.3723\n",
      "epoch: 4.\tNumber of swapped pairs: 798.0/1711\tnDCG_at_10: 0.1679\n",
      "epoch: 4.\tNumber of swapped pairs: 2652.0/6555\tnDCG_at_10: 0.2662\n",
      "epoch: 4.\tNumber of swapped pairs: 3258.0/8646\tnDCG_at_10: 0.4010\n",
      "epoch: 4.\tNumber of swapped pairs: 2111.0/3570\tnDCG_at_10: 0.0000\n",
      "epoch: 4.\tNumber of swapped pairs: 9257.0/19503\tnDCG_at_10: 0.1639\n",
      "epoch: 4.\tNumber of swapped pairs: 3201.0/7875\tnDCG_at_10: 0.4056\n",
      "epoch: 4.\tNumber of swapped pairs: 4018.0/7875\tnDCG_at_10: 0.1584\n",
      "epoch: 4.\tNumber of swapped pairs: 4012.0/9591\tnDCG_at_10: 0.4864\n",
      "epoch: 4.\tNumber of swapped pairs: 1980.0/4005\tnDCG_at_10: 0.0000\n",
      "epoch: 4.\tNumber of swapped pairs: 3388.0/7503\tnDCG_at_10: 0.4188\n",
      "epoch: 4.\tNumber of swapped pairs: 7998.0/17205\tnDCG_at_10: 0.4234\n",
      "epoch: 4.\tNumber of swapped pairs: 2658.0/6903\tnDCG_at_10: 0.5622\n",
      "epoch: 4.\tNumber of swapped pairs: 252.0/435\tnDCG_at_10: 0.2815\n",
      "epoch: 4.\tNumber of swapped pairs: 3022.0/7875\tnDCG_at_10: 0.5006\n",
      "epoch: 4.\tNumber of swapped pairs: 455.0/861\tnDCG_at_10: 0.1352\n",
      "epoch: 4.\tNumber of swapped pairs: 6700.0/13695\tnDCG_at_10: 0.3807\n",
      "epoch: 4.\tNumber of swapped pairs: 1419.0/3003\tnDCG_at_10: 0.2674\n",
      "epoch: 4.\tNumber of swapped pairs: 1305.0/2926\tnDCG_at_10: 0.5325\n",
      "epoch: 4.\tNumber of swapped pairs: 4494.0/11628\tnDCG_at_10: 0.5949\n",
      "epoch: 4.\tNumber of swapped pairs: 1168.0/3321\tnDCG_at_10: 0.6779\n",
      "epoch: 4.\tNumber of swapped pairs: 3072.0/7021\tnDCG_at_10: 0.5338\n",
      "epoch: 4.\tNumber of swapped pairs: 1739.0/4371\tnDCG_at_10: 0.3476\n",
      "epoch: 4.\tNumber of swapped pairs: 360.0/903\tnDCG_at_10: 0.5811\n",
      "epoch: 4.\tNumber of swapped pairs: 2520.0/6903\tnDCG_at_10: 0.7790\n",
      "epoch: 4.\tNumber of swapped pairs: 2748.0/6786\tnDCG_at_10: 0.6263\n",
      "epoch: 4.\tNumber of swapped pairs: 12125.0/26106\tnDCG_at_10: 0.1344\n",
      "epoch: 4.\tNumber of swapped pairs: 7681.0/16836\tnDCG_at_10: 0.4009\n",
      "epoch: 4.\tNumber of swapped pairs: 1807.0/4465\tnDCG_at_10: 0.4300\n",
      "epoch: 4.\tNumber of swapped pairs: 1539.0/4095\tnDCG_at_10: 0.5215\n",
      "epoch: 4.\tNumber of swapped pairs: 2308.0/5995\tnDCG_at_10: 0.3671\n",
      "epoch: 4.\tNumber of swapped pairs: 4505.0/11781\tnDCG_at_10: 0.7775\n",
      "epoch: 4.\tNumber of swapped pairs: 6411.0/13041\tnDCG_at_10: 0.3372\n",
      "epoch: 4.\tNumber of swapped pairs: 3869.0/9045\tnDCG_at_10: 0.4644\n",
      "epoch: 4.\tNumber of swapped pairs: 536.0/1596\tnDCG_at_10: 0.8001\n",
      "epoch: 4.\tNumber of swapped pairs: 969.0/2211\tnDCG_at_10: 0.6070\n",
      "epoch: 4.\tNumber of swapped pairs: 29819.0/68265\tnDCG_at_10: 0.5308\n",
      "epoch: 4.\tNumber of swapped pairs: 2032.0/5151\tnDCG_at_10: 0.2992\n",
      "epoch: 4.\tNumber of swapped pairs: 2279.0/4950\tnDCG_at_10: 0.3929\n",
      "epoch: 4.\tNumber of swapped pairs: 971.0/2556\tnDCG_at_10: 0.4765\n",
      "epoch: 4.\tNumber of swapped pairs: 6891.0/16471\tnDCG_at_10: 0.5946\n",
      "epoch: 4.\tNumber of swapped pairs: 1506.0/3570\tnDCG_at_10: 0.6423\n",
      "epoch: 4.\tNumber of swapped pairs: 13553.0/25425\tnDCG_at_10: 0.1736\n",
      "epoch: 4.\tNumber of swapped pairs: 12755.0/26565\tnDCG_at_10: 0.0923\n",
      "epoch: 4.\tNumber of swapped pairs: 880.0/1596\tnDCG_at_10: 0.0950\n",
      "epoch: 4.\tNumber of swapped pairs: 3563.0/8256\tnDCG_at_10: 0.3784\n",
      "epoch: 4.\tNumber of swapped pairs: 722.0/2850\tnDCG_at_10: 0.6639\n",
      "epoch: 4.\tNumber of swapped pairs: 1564.0/3240\tnDCG_at_10: 0.0601\n",
      "epoch: 4.\tNumber of swapped pairs: 581.0/1540\tnDCG_at_10: 0.4470\n",
      "epoch: 4.\tNumber of swapped pairs: 1106.0/2145\tnDCG_at_10: 0.4044\n",
      "epoch: 4.\tNumber of swapped pairs: 3485.0/7503\tnDCG_at_10: 0.1513\n",
      "epoch: 4.\tNumber of swapped pairs: 3344.0/7626\tnDCG_at_10: 0.5456\n",
      "epoch: 4.\tNumber of swapped pairs: 2775.0/6555\tnDCG_at_10: 0.3998\n",
      "epoch: 4.\tNumber of swapped pairs: 7478.0/15576\tnDCG_at_10: 0.3235\n",
      "epoch: 4.\tNumber of swapped pairs: 1725.0/4005\tnDCG_at_10: 0.4066\n",
      "epoch: 4.\tNumber of swapped pairs: 2402.0/4656\tnDCG_at_10: 0.2600\n",
      "epoch: 4.\tNumber of swapped pairs: 610.0/1326\tnDCG_at_10: 0.4955\n",
      "epoch: 4.\tNumber of swapped pairs: 1814.0/4560\tnDCG_at_10: 0.7248\n",
      "epoch: 4.\tNumber of swapped pairs: 2389.0/5356\tnDCG_at_10: 0.4939\n",
      "epoch: 4.\tNumber of swapped pairs: 5029.0/10011\tnDCG_at_10: 0.1467\n",
      "epoch: 4.\tNumber of swapped pairs: 1322.0/3741\tnDCG_at_10: 0.6328\n",
      "epoch: 4.\tNumber of swapped pairs: 2604.0/5050\tnDCG_at_10: 0.6567\n",
      "epoch: 4.\tNumber of swapped pairs: 1789.0/3916\tnDCG_at_10: 0.6250\n",
      "epoch: 4.\tNumber of swapped pairs: 1024.0/2628\tnDCG_at_10: 0.2980\n",
      "epoch: 4.\tNumber of swapped pairs: 6749.0/14028\tnDCG_at_10: 0.4863\n",
      "epoch: 4.\tNumber of swapped pairs: 359.0/903\tnDCG_at_10: 0.6441\n",
      "epoch: 4.\tNumber of swapped pairs: 3746.0/8911\tnDCG_at_10: 0.1532\n",
      "epoch: 4.\tNumber of swapped pairs: 555.0/1275\tnDCG_at_10: 0.2330\n",
      "epoch: 4.\tNumber of swapped pairs: 1080.0/2211\tnDCG_at_10: 0.5431\n",
      "epoch: 4.\tNumber of swapped pairs: 388.0/820\tnDCG_at_10: 0.3354\n",
      "epoch: 4.\tNumber of swapped pairs: 2541.0/6786\tnDCG_at_10: 0.7389\n",
      "epoch: 4.\tNumber of swapped pairs: 1239.0/3240\tnDCG_at_10: 0.5577\n",
      "epoch: 4.\tNumber of swapped pairs: 1384.0/3160\tnDCG_at_10: 0.4785\n",
      "epoch: 4.\tNumber of swapped pairs: 2429.0/4560\tnDCG_at_10: 0.0667\n",
      "epoch: 4.\tNumber of swapped pairs: 6032.0/13203\tnDCG_at_10: 0.3565\n",
      "epoch: 4.\tNumber of swapped pairs: 1896.0/4186\tnDCG_at_10: 0.3350\n",
      "epoch: 4.\tNumber of swapped pairs: 5687.0/13695\tnDCG_at_10: 0.7731\n",
      "epoch: 4.\tNumber of swapped pairs: 353.0/861\tnDCG_at_10: 0.8269\n",
      "epoch: 4.\tNumber of swapped pairs: 4336.0/12090\tnDCG_at_10: 0.4767\n",
      "epoch: 4.\tNumber of swapped pairs: 5739.0/12246\tnDCG_at_10: 0.3300\n",
      "epoch: 4.\tNumber of swapped pairs: nan/1\tnDCG_at_10: 1.0000\n",
      "Mean NDCG: 0.424917608499527\n",
      "Epoch: 4\n",
      "Train loss: 0.5919793625961408\n",
      "epoch: 5.\tNumber of swapped pairs: 4581.0/9453\tnDCG_at_10: 0.3998\n",
      "epoch: 5.\tNumber of swapped pairs: 1928.0/4371\tnDCG_at_10: 0.4825\n",
      "epoch: 5.\tNumber of swapped pairs: 1273.0/3655\tnDCG_at_10: 0.3562\n",
      "epoch: 5.\tNumber of swapped pairs: 5920.0/10878\tnDCG_at_10: 0.2025\n",
      "epoch: 5.\tNumber of swapped pairs: 3405.0/7503\tnDCG_at_10: 0.4183\n",
      "epoch: 5.\tNumber of swapped pairs: 6796.0/14028\tnDCG_at_10: 0.3871\n",
      "epoch: 5.\tNumber of swapped pairs: 3112.0/7260\tnDCG_at_10: 0.4653\n",
      "epoch: 5.\tNumber of swapped pairs: 3758.0/9316\tnDCG_at_10: 0.3245\n",
      "epoch: 5.\tNumber of swapped pairs: 707.0/1711\tnDCG_at_10: 0.3703\n",
      "epoch: 5.\tNumber of swapped pairs: 2669.0/6555\tnDCG_at_10: 0.1894\n",
      "epoch: 5.\tNumber of swapped pairs: 3387.0/8646\tnDCG_at_10: 0.3169\n",
      "epoch: 5.\tNumber of swapped pairs: 2111.0/3570\tnDCG_at_10: 0.0000\n",
      "epoch: 5.\tNumber of swapped pairs: 9245.0/19503\tnDCG_at_10: 0.2560\n",
      "epoch: 5.\tNumber of swapped pairs: 3348.0/7875\tnDCG_at_10: 0.3336\n",
      "epoch: 5.\tNumber of swapped pairs: 3610.0/7875\tnDCG_at_10: 0.1420\n",
      "epoch: 5.\tNumber of swapped pairs: 4009.0/9591\tnDCG_at_10: 0.3535\n",
      "epoch: 5.\tNumber of swapped pairs: 2059.0/4005\tnDCG_at_10: 0.0000\n",
      "epoch: 5.\tNumber of swapped pairs: 3481.0/7503\tnDCG_at_10: 0.2627\n",
      "epoch: 5.\tNumber of swapped pairs: 8115.0/17205\tnDCG_at_10: 0.5409\n",
      "epoch: 5.\tNumber of swapped pairs: 2726.0/6903\tnDCG_at_10: 0.6047\n",
      "epoch: 5.\tNumber of swapped pairs: 242.0/435\tnDCG_at_10: 0.2424\n",
      "epoch: 5.\tNumber of swapped pairs: 3203.0/7875\tnDCG_at_10: 0.4392\n",
      "epoch: 5.\tNumber of swapped pairs: 463.0/861\tnDCG_at_10: 0.1283\n",
      "epoch: 5.\tNumber of swapped pairs: 6552.0/13695\tnDCG_at_10: 0.3253\n",
      "epoch: 5.\tNumber of swapped pairs: 1378.0/3003\tnDCG_at_10: 0.2634\n",
      "epoch: 5.\tNumber of swapped pairs: 1288.0/2926\tnDCG_at_10: 0.5722\n",
      "epoch: 5.\tNumber of swapped pairs: 4415.0/11628\tnDCG_at_10: 0.4803\n",
      "epoch: 5.\tNumber of swapped pairs: 1193.0/3321\tnDCG_at_10: 0.6779\n",
      "epoch: 5.\tNumber of swapped pairs: 2895.0/7021\tnDCG_at_10: 0.4021\n",
      "epoch: 5.\tNumber of swapped pairs: 1808.0/4371\tnDCG_at_10: 0.2801\n",
      "epoch: 5.\tNumber of swapped pairs: 346.0/903\tnDCG_at_10: 0.6058\n",
      "epoch: 5.\tNumber of swapped pairs: 2781.0/6903\tnDCG_at_10: 0.7568\n",
      "epoch: 5.\tNumber of swapped pairs: 2799.0/6786\tnDCG_at_10: 0.5266\n",
      "epoch: 5.\tNumber of swapped pairs: 12156.0/26106\tnDCG_at_10: 0.1631\n",
      "epoch: 5.\tNumber of swapped pairs: 7622.0/16836\tnDCG_at_10: 0.3369\n",
      "epoch: 5.\tNumber of swapped pairs: 1849.0/4465\tnDCG_at_10: 0.4336\n",
      "epoch: 5.\tNumber of swapped pairs: 1775.0/4095\tnDCG_at_10: 0.2842\n",
      "epoch: 5.\tNumber of swapped pairs: 2301.0/5995\tnDCG_at_10: 0.2701\n",
      "epoch: 5.\tNumber of swapped pairs: 4285.0/11781\tnDCG_at_10: 0.8204\n",
      "epoch: 5.\tNumber of swapped pairs: 6740.0/13041\tnDCG_at_10: 0.3631\n",
      "epoch: 5.\tNumber of swapped pairs: 4195.0/9045\tnDCG_at_10: 0.4293\n",
      "epoch: 5.\tNumber of swapped pairs: 478.0/1596\tnDCG_at_10: 0.7968\n",
      "epoch: 5.\tNumber of swapped pairs: 906.0/2211\tnDCG_at_10: 0.5936\n",
      "epoch: 5.\tNumber of swapped pairs: 30228.0/68265\tnDCG_at_10: 0.4544\n",
      "epoch: 5.\tNumber of swapped pairs: 2231.0/5151\tnDCG_at_10: 0.1054\n",
      "epoch: 5.\tNumber of swapped pairs: 2225.0/4950\tnDCG_at_10: 0.4392\n",
      "epoch: 5.\tNumber of swapped pairs: 1019.0/2556\tnDCG_at_10: 0.4493\n",
      "epoch: 5.\tNumber of swapped pairs: 6964.0/16471\tnDCG_at_10: 0.5096\n",
      "epoch: 5.\tNumber of swapped pairs: 1457.0/3570\tnDCG_at_10: 0.7219\n",
      "epoch: 5.\tNumber of swapped pairs: 13629.0/25425\tnDCG_at_10: 0.0000\n",
      "epoch: 5.\tNumber of swapped pairs: 12382.0/26565\tnDCG_at_10: 0.1052\n",
      "epoch: 5.\tNumber of swapped pairs: 848.0/1596\tnDCG_at_10: 0.1772\n",
      "epoch: 5.\tNumber of swapped pairs: 3419.0/8256\tnDCG_at_10: 0.4366\n",
      "epoch: 5.\tNumber of swapped pairs: 707.0/2850\tnDCG_at_10: 0.5997\n",
      "epoch: 5.\tNumber of swapped pairs: 1709.0/3240\tnDCG_at_10: 0.1299\n",
      "epoch: 5.\tNumber of swapped pairs: 579.0/1540\tnDCG_at_10: 0.6583\n",
      "epoch: 5.\tNumber of swapped pairs: 1178.0/2145\tnDCG_at_10: 0.3185\n",
      "epoch: 5.\tNumber of swapped pairs: 3819.0/7503\tnDCG_at_10: 0.1429\n",
      "epoch: 5.\tNumber of swapped pairs: 3525.0/7626\tnDCG_at_10: 0.6526\n",
      "epoch: 5.\tNumber of swapped pairs: 2783.0/6555\tnDCG_at_10: 0.2189\n",
      "epoch: 5.\tNumber of swapped pairs: 7444.0/15576\tnDCG_at_10: 0.3800\n",
      "epoch: 5.\tNumber of swapped pairs: 1822.0/4005\tnDCG_at_10: 0.3471\n",
      "epoch: 5.\tNumber of swapped pairs: 2487.0/4656\tnDCG_at_10: 0.2480\n",
      "epoch: 5.\tNumber of swapped pairs: 604.0/1326\tnDCG_at_10: 0.3354\n",
      "epoch: 5.\tNumber of swapped pairs: 1665.0/4560\tnDCG_at_10: 0.6738\n",
      "epoch: 5.\tNumber of swapped pairs: 2439.0/5356\tnDCG_at_10: 0.5052\n",
      "epoch: 5.\tNumber of swapped pairs: 5074.0/10011\tnDCG_at_10: 0.1535\n",
      "epoch: 5.\tNumber of swapped pairs: 1305.0/3741\tnDCG_at_10: 0.5787\n",
      "epoch: 5.\tNumber of swapped pairs: 2658.0/5050\tnDCG_at_10: 0.5755\n",
      "epoch: 5.\tNumber of swapped pairs: 1841.0/3916\tnDCG_at_10: 0.5028\n",
      "epoch: 5.\tNumber of swapped pairs: 1034.0/2628\tnDCG_at_10: 0.3463\n",
      "epoch: 5.\tNumber of swapped pairs: 6699.0/14028\tnDCG_at_10: 0.4378\n",
      "epoch: 5.\tNumber of swapped pairs: 347.0/903\tnDCG_at_10: 0.6292\n",
      "epoch: 5.\tNumber of swapped pairs: 3893.0/8911\tnDCG_at_10: 0.1206\n",
      "epoch: 5.\tNumber of swapped pairs: 630.0/1275\tnDCG_at_10: 0.1091\n",
      "epoch: 5.\tNumber of swapped pairs: 1108.0/2211\tnDCG_at_10: 0.4393\n",
      "epoch: 5.\tNumber of swapped pairs: 359.0/820\tnDCG_at_10: 0.3237\n",
      "epoch: 5.\tNumber of swapped pairs: 2726.0/6786\tnDCG_at_10: 0.5525\n",
      "epoch: 5.\tNumber of swapped pairs: 1150.0/3240\tnDCG_at_10: 0.4978\n",
      "epoch: 5.\tNumber of swapped pairs: 1375.0/3160\tnDCG_at_10: 0.4720\n",
      "epoch: 5.\tNumber of swapped pairs: 2334.0/4560\tnDCG_at_10: 0.1069\n",
      "epoch: 5.\tNumber of swapped pairs: 6030.0/13203\tnDCG_at_10: 0.3292\n",
      "epoch: 5.\tNumber of swapped pairs: 1839.0/4186\tnDCG_at_10: 0.3885\n",
      "epoch: 5.\tNumber of swapped pairs: 5559.0/13695\tnDCG_at_10: 0.8059\n",
      "epoch: 5.\tNumber of swapped pairs: 395.0/861\tnDCG_at_10: 0.7791\n",
      "epoch: 5.\tNumber of swapped pairs: 4527.0/12090\tnDCG_at_10: 0.4187\n",
      "epoch: 5.\tNumber of swapped pairs: 5729.0/12246\tnDCG_at_10: 0.3826\n",
      "epoch: 5.\tNumber of swapped pairs: nan/1\tnDCG_at_10: 1.0000\n",
      "Mean NDCG: 0.39950448274612427\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "len_dataset = len(msrank_dataset)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_losses = []\n",
    "    # for query, msrank_dataloader in dataloaders.items():\n",
    "    for it, (_, batch_x1, batch_x2, tgt) in enumerate(msrank_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_x1 = batch_x1.to(device)\n",
    "        batch_x2 = batch_x2.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        batch_pred = ranknet_model(batch_x1, batch_x2)\n",
    "        batch_loss = criterion(batch_pred, tgt.view(-1, 1))\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(batch_loss.item() * len(batch_x1))\n",
    "\n",
    "            \n",
    "    print(f'Train loss: {np.sum(train_losses) / len_dataset}')\n",
    "    \n",
    "    ndcg_scores = []\n",
    "    with torch.no_grad():\n",
    "        for query_test in msrank_10k_test['query'].unique():\n",
    "            test_x = torch.as_tensor(msrank_10k_test.loc[msrank_10k_test['query']==query_test, 'feature_2':].values, dtype=torch.float32).to(device)\n",
    "            test_y = torch.as_tensor(msrank_10k_test.loc[msrank_10k_test['query']==query_test, 'target'].values, dtype=torch.float32).to(device)\n",
    "\n",
    "            total_pairs = len(test_x) * (len(test_x) - 1) // 2\n",
    "            \n",
    "            valid_pred = ranknet_model.predict(test_x).cpu().flatten()\n",
    "            \n",
    "            valid_swapped_pairs = -(sts.kendalltau(test_y.cpu().numpy(), valid_pred.numpy()).statistic * total_pairs - total_pairs) // 2\n",
    "            ndcg_score_ = ndcg_k(test_y.cpu().flatten(), valid_pred, gain_scheme='const', k=10)\n",
    "            ndcg_scores.append(ndcg_score_)\n",
    "            print(f\"epoch: {epoch + 1}.\\tNumber of swapped pairs: \"\n",
    "                  f\"{valid_swapped_pairs}/{total_pairs}\\t\"\n",
    "            f\"nDCG_at_10: {ndcg_score_:.4f}\")\n",
    "        \n",
    "    print(f'Mean NDCG: {np.mean(ndcg_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5.\tNumber of swapped pairs: 4581.0/9453\tnDCG_at_10: 0.3998\n",
      "epoch: 5.\tNumber of swapped pairs: 1928.0/4371\tnDCG_at_10: 0.4825\n",
      "epoch: 5.\tNumber of swapped pairs: 1273.0/3655\tnDCG_at_10: 0.3562\n",
      "epoch: 5.\tNumber of swapped pairs: 5920.0/10878\tnDCG_at_10: 0.2025\n",
      "epoch: 5.\tNumber of swapped pairs: 3405.0/7503\tnDCG_at_10: 0.4183\n",
      "epoch: 5.\tNumber of swapped pairs: 6796.0/14028\tnDCG_at_10: 0.3871\n",
      "epoch: 5.\tNumber of swapped pairs: 3112.0/7260\tnDCG_at_10: 0.4653\n",
      "epoch: 5.\tNumber of swapped pairs: 3758.0/9316\tnDCG_at_10: 0.3245\n",
      "epoch: 5.\tNumber of swapped pairs: 707.0/1711\tnDCG_at_10: 0.3703\n",
      "epoch: 5.\tNumber of swapped pairs: 2669.0/6555\tnDCG_at_10: 0.1894\n",
      "epoch: 5.\tNumber of swapped pairs: 3387.0/8646\tnDCG_at_10: 0.3169\n",
      "epoch: 5.\tNumber of swapped pairs: 2111.0/3570\tnDCG_at_10: 0.0000\n",
      "epoch: 5.\tNumber of swapped pairs: 9245.0/19503\tnDCG_at_10: 0.2560\n",
      "epoch: 5.\tNumber of swapped pairs: 3348.0/7875\tnDCG_at_10: 0.3336\n",
      "epoch: 5.\tNumber of swapped pairs: 3610.0/7875\tnDCG_at_10: 0.1420\n",
      "epoch: 5.\tNumber of swapped pairs: 4009.0/9591\tnDCG_at_10: 0.3535\n",
      "epoch: 5.\tNumber of swapped pairs: 2059.0/4005\tnDCG_at_10: 0.0000\n",
      "epoch: 5.\tNumber of swapped pairs: 3481.0/7503\tnDCG_at_10: 0.2627\n",
      "epoch: 5.\tNumber of swapped pairs: 8115.0/17205\tnDCG_at_10: 0.5409\n",
      "epoch: 5.\tNumber of swapped pairs: 2726.0/6903\tnDCG_at_10: 0.6047\n",
      "epoch: 5.\tNumber of swapped pairs: 242.0/435\tnDCG_at_10: 0.2424\n",
      "epoch: 5.\tNumber of swapped pairs: 3203.0/7875\tnDCG_at_10: 0.4392\n",
      "epoch: 5.\tNumber of swapped pairs: 463.0/861\tnDCG_at_10: 0.1283\n",
      "epoch: 5.\tNumber of swapped pairs: 6552.0/13695\tnDCG_at_10: 0.3253\n",
      "epoch: 5.\tNumber of swapped pairs: 1378.0/3003\tnDCG_at_10: 0.2634\n",
      "epoch: 5.\tNumber of swapped pairs: 1288.0/2926\tnDCG_at_10: 0.5722\n",
      "epoch: 5.\tNumber of swapped pairs: 4415.0/11628\tnDCG_at_10: 0.4803\n",
      "epoch: 5.\tNumber of swapped pairs: 1193.0/3321\tnDCG_at_10: 0.6779\n",
      "epoch: 5.\tNumber of swapped pairs: 2895.0/7021\tnDCG_at_10: 0.4021\n",
      "epoch: 5.\tNumber of swapped pairs: 1808.0/4371\tnDCG_at_10: 0.2801\n",
      "epoch: 5.\tNumber of swapped pairs: 346.0/903\tnDCG_at_10: 0.6058\n",
      "epoch: 5.\tNumber of swapped pairs: 2781.0/6903\tnDCG_at_10: 0.7568\n",
      "epoch: 5.\tNumber of swapped pairs: 2799.0/6786\tnDCG_at_10: 0.5266\n",
      "epoch: 5.\tNumber of swapped pairs: 12156.0/26106\tnDCG_at_10: 0.1631\n",
      "epoch: 5.\tNumber of swapped pairs: 7622.0/16836\tnDCG_at_10: 0.3369\n",
      "epoch: 5.\tNumber of swapped pairs: 1849.0/4465\tnDCG_at_10: 0.4336\n",
      "epoch: 5.\tNumber of swapped pairs: 1775.0/4095\tnDCG_at_10: 0.2842\n",
      "epoch: 5.\tNumber of swapped pairs: 2301.0/5995\tnDCG_at_10: 0.2701\n",
      "epoch: 5.\tNumber of swapped pairs: 4285.0/11781\tnDCG_at_10: 0.8204\n",
      "epoch: 5.\tNumber of swapped pairs: 6740.0/13041\tnDCG_at_10: 0.3631\n",
      "epoch: 5.\tNumber of swapped pairs: 4195.0/9045\tnDCG_at_10: 0.4293\n",
      "epoch: 5.\tNumber of swapped pairs: 478.0/1596\tnDCG_at_10: 0.7968\n",
      "epoch: 5.\tNumber of swapped pairs: 906.0/2211\tnDCG_at_10: 0.5936\n",
      "epoch: 5.\tNumber of swapped pairs: 30228.0/68265\tnDCG_at_10: 0.4544\n",
      "epoch: 5.\tNumber of swapped pairs: 2231.0/5151\tnDCG_at_10: 0.1054\n",
      "epoch: 5.\tNumber of swapped pairs: 2225.0/4950\tnDCG_at_10: 0.4392\n",
      "epoch: 5.\tNumber of swapped pairs: 1019.0/2556\tnDCG_at_10: 0.4493\n",
      "epoch: 5.\tNumber of swapped pairs: 6964.0/16471\tnDCG_at_10: 0.5096\n",
      "epoch: 5.\tNumber of swapped pairs: 1457.0/3570\tnDCG_at_10: 0.7219\n",
      "epoch: 5.\tNumber of swapped pairs: 13629.0/25425\tnDCG_at_10: 0.0000\n",
      "epoch: 5.\tNumber of swapped pairs: 12382.0/26565\tnDCG_at_10: 0.1052\n",
      "epoch: 5.\tNumber of swapped pairs: 848.0/1596\tnDCG_at_10: 0.1772\n",
      "epoch: 5.\tNumber of swapped pairs: 3419.0/8256\tnDCG_at_10: 0.4366\n",
      "epoch: 5.\tNumber of swapped pairs: 707.0/2850\tnDCG_at_10: 0.5997\n",
      "epoch: 5.\tNumber of swapped pairs: 1709.0/3240\tnDCG_at_10: 0.1299\n",
      "epoch: 5.\tNumber of swapped pairs: 579.0/1540\tnDCG_at_10: 0.6583\n",
      "epoch: 5.\tNumber of swapped pairs: 1178.0/2145\tnDCG_at_10: 0.3185\n",
      "epoch: 5.\tNumber of swapped pairs: 3819.0/7503\tnDCG_at_10: 0.1429\n",
      "epoch: 5.\tNumber of swapped pairs: 3525.0/7626\tnDCG_at_10: 0.6526\n",
      "epoch: 5.\tNumber of swapped pairs: 2783.0/6555\tnDCG_at_10: 0.2189\n",
      "epoch: 5.\tNumber of swapped pairs: 7444.0/15576\tnDCG_at_10: 0.3800\n",
      "epoch: 5.\tNumber of swapped pairs: 1822.0/4005\tnDCG_at_10: 0.3471\n",
      "epoch: 5.\tNumber of swapped pairs: 2487.0/4656\tnDCG_at_10: 0.2480\n",
      "epoch: 5.\tNumber of swapped pairs: 604.0/1326\tnDCG_at_10: 0.3354\n",
      "epoch: 5.\tNumber of swapped pairs: 1665.0/4560\tnDCG_at_10: 0.6738\n",
      "epoch: 5.\tNumber of swapped pairs: 2439.0/5356\tnDCG_at_10: 0.5052\n",
      "epoch: 5.\tNumber of swapped pairs: 5074.0/10011\tnDCG_at_10: 0.1535\n",
      "epoch: 5.\tNumber of swapped pairs: 1305.0/3741\tnDCG_at_10: 0.5787\n",
      "epoch: 5.\tNumber of swapped pairs: 2658.0/5050\tnDCG_at_10: 0.5755\n",
      "epoch: 5.\tNumber of swapped pairs: 1841.0/3916\tnDCG_at_10: 0.5028\n",
      "epoch: 5.\tNumber of swapped pairs: 1034.0/2628\tnDCG_at_10: 0.3463\n",
      "epoch: 5.\tNumber of swapped pairs: 6699.0/14028\tnDCG_at_10: 0.4378\n",
      "epoch: 5.\tNumber of swapped pairs: 347.0/903\tnDCG_at_10: 0.6292\n",
      "epoch: 5.\tNumber of swapped pairs: 3893.0/8911\tnDCG_at_10: 0.1206\n",
      "epoch: 5.\tNumber of swapped pairs: 630.0/1275\tnDCG_at_10: 0.1091\n",
      "epoch: 5.\tNumber of swapped pairs: 1108.0/2211\tnDCG_at_10: 0.4393\n",
      "epoch: 5.\tNumber of swapped pairs: 359.0/820\tnDCG_at_10: 0.3237\n",
      "epoch: 5.\tNumber of swapped pairs: 2726.0/6786\tnDCG_at_10: 0.5525\n",
      "epoch: 5.\tNumber of swapped pairs: 1150.0/3240\tnDCG_at_10: 0.4978\n",
      "epoch: 5.\tNumber of swapped pairs: 1375.0/3160\tnDCG_at_10: 0.4720\n",
      "epoch: 5.\tNumber of swapped pairs: 2334.0/4560\tnDCG_at_10: 0.1069\n",
      "epoch: 5.\tNumber of swapped pairs: 6030.0/13203\tnDCG_at_10: 0.3292\n",
      "epoch: 5.\tNumber of swapped pairs: 1839.0/4186\tnDCG_at_10: 0.3885\n",
      "epoch: 5.\tNumber of swapped pairs: 5559.0/13695\tnDCG_at_10: 0.8059\n",
      "epoch: 5.\tNumber of swapped pairs: 395.0/861\tnDCG_at_10: 0.7791\n",
      "epoch: 5.\tNumber of swapped pairs: 4527.0/12090\tnDCG_at_10: 0.4187\n",
      "epoch: 5.\tNumber of swapped pairs: 5729.0/12246\tnDCG_at_10: 0.3826\n",
      "epoch: 5.\tNumber of swapped pairs: nan/1\tnDCG_at_10: 1.0000\n",
      "Mean NDCG: 0.39950448274612427\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for query_test in msrank_10k_test['query'].unique():\n",
    "            test_x = torch.as_tensor(msrank_10k_test.loc[msrank_10k_test['query']==query_test, 'feature_2':].values, dtype=torch.float32).to(device)\n",
    "            test_y = torch.as_tensor(msrank_10k_test.loc[msrank_10k_test['query']==query_test, 'target'].values, dtype=torch.float32).to(device)\n",
    "\n",
    "            total_pairs = len(test_x) * (len(test_x) - 1) // 2\n",
    "            \n",
    "            valid_pred = ranknet_model.predict(test_x).cpu().flatten()\n",
    "            \n",
    "            valid_swapped_pairs = -(sts.kendalltau(test_y.cpu().numpy(), valid_pred.numpy()).statistic * total_pairs - total_pairs) // 2\n",
    "            ndcg_score_ = ndcg_k(test_y.cpu().flatten(), valid_pred, gain_scheme='const', k=10)\n",
    "            ndcg_scores.append(ndcg_score_)\n",
    "            print(f\"epoch: {epoch + 1}.\\tNumber of swapped pairs: \"\n",
    "                  f\"{valid_swapped_pairs}/{total_pairs}\\t\"\n",
    "            f\"nDCG_at_10: {ndcg_score_:.4f}\")\n",
    "        \n",
    "print(f'Mean NDCG: {np.mean(ndcg_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Синтетические данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(N_train, N_valid, vector_dim):\n",
    "    fake_weights = torch.randn(vector_dim, 1)\n",
    "\n",
    "    X_train = torch.randn(N_train, vector_dim)\n",
    "    X_valid = torch.randn(N_valid, vector_dim)\n",
    "\n",
    "    ys_train_score = torch.mm(X_train, fake_weights)\n",
    "    ys_train_score += torch.randn_like(ys_train_score)\n",
    "\n",
    "    ys_valid_score = torch.mm(X_valid, fake_weights)\n",
    "    ys_valid_score += torch.randn_like(ys_valid_score)\n",
    "\n",
    "#     bins = [-1, 1]  # 3 relevances\n",
    "    bins = [-1, 0, 1, 2]  # 5 relevances\n",
    "    ys_train_rel = torch.Tensor(\n",
    "        np.digitize(ys_train_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "    ys_valid_rel = torch.Tensor(\n",
    "        np.digitize(ys_valid_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "\n",
    "    return X_train, X_valid, ys_train_rel, ys_valid_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 1000\n",
    "N_valid = 500\n",
    "\n",
    "vector_dim = 100\n",
    "epochs = 2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "X_train, X_valid, ys_train, ys_valid = make_dataset(N_train, N_valid, vector_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of comparison: 499500\n",
      "Classes balance:\n",
      "0.5    202335\n",
      "0.0    154062\n",
      "1.0    143103\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1, 1),\n",
       " (0, 2, 0.5),\n",
       " (0, 3, 1),\n",
       " (0, 4, 1),\n",
       " (0, 5, 0.5),\n",
       " (0, 6, 0.5),\n",
       " (0, 7, 1),\n",
       " (0, 8, 0.5),\n",
       " (0, 9, 1),\n",
       " (0, 10, 1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 if i-th score larger than j-th\n",
    "\n",
    "comparison = []\n",
    "ys_to_check = ys_train.flatten().numpy()\n",
    "\n",
    "for i, idx1 in enumerate(ys_to_check):\n",
    "    for j, idx2 in enumerate(ys_to_check):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        if idx1 > idx2:\n",
    "            comparison.append((i, j, 1))  # i должен быть отранжирован выше j\n",
    "        elif idx1 < idx2:\n",
    "            comparison.append((i, j, 0))  # j должен быть отранжирован выше i\n",
    "        else:\n",
    "            comparison.append((i, j, 0.5))  # одинаковый ранг\n",
    "\n",
    "print(f'Length of comparison: {len(comparison)}')\n",
    "print(f'Classes balance:\\n{pd.Series(np.array([x[2] for x in comparison])).value_counts()}')\n",
    "\n",
    "comparison[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499500.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000 * 999) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthPairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, comparison):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.comparison = comparison\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comparison)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i, j, target = self.comparison[index]\n",
    "        x_i, x_j = self.data[i], self.data[j]\n",
    "\n",
    "        return torch.as_tensor(x_i, dtype=torch.float32),\\\n",
    "        torch.as_tensor(x_j, dtype=torch.float32),\\\n",
    "        torch.as_tensor(target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dataset = SynthPairDataset(X_train, comparison)\n",
    "synth_dataloader = torch.utils.data.DataLoader(synth_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6010e-01, -3.5654e-01, -3.0648e-01,  ...,  1.5710e-01,\n",
      "         -7.0745e-02,  2.3923e-01],\n",
      "        [ 5.9007e-02, -2.0888e-01, -4.9197e-01,  ..., -4.6880e-02,\n",
      "          1.0705e+00,  8.4041e-01],\n",
      "        [ 2.6172e-01, -1.7634e-03,  6.1484e-01,  ..., -4.5866e-01,\n",
      "         -1.3954e+00,  5.9419e-01],\n",
      "        ...,\n",
      "        [ 2.3660e-01,  5.8804e-02, -6.9478e-02,  ..., -5.6859e-01,\n",
      "          1.0640e+00, -2.1690e+00],\n",
      "        [ 8.1490e-01, -1.1789e+00, -1.2862e-01,  ...,  1.1786e+00,\n",
      "          1.3115e-01,  1.0842e+00],\n",
      "        [-7.7179e-01, -2.6162e-01, -3.7023e-02,  ...,  4.9731e-01,\n",
      "         -4.6563e-02,  5.4360e-01]])\n",
      "tensor([[-0.5818,  0.9190, -0.8213,  ...,  0.2124, -0.1681,  0.0421],\n",
      "        [-1.0465,  0.0703,  0.6797,  ..., -1.7304, -0.3119,  0.7299],\n",
      "        [-0.5743,  0.0293,  1.0397,  ..., -0.1790,  1.5311,  0.3444],\n",
      "        ...,\n",
      "        [ 0.0120,  0.3378,  0.0336,  ...,  0.2011, -0.7678, -0.8371],\n",
      "        [-0.2948, -0.1830,  0.8458,  ...,  0.4807, -1.6280, -1.9756],\n",
      "        [-0.8793,  1.6957, -0.9194,  ..., -0.7747, -0.1727,  0.6246]])\n",
      "tensor([0.0000, 0.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.0000, 0.5000, 1.0000, 1.0000, 0.5000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "        0.0000, 0.5000, 1.0000, 0.0000, 0.5000, 0.5000, 0.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.5000, 0.5000, 1.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "for first, second, tgt in synth_dataloader:\n",
    "    print(first)\n",
    "    print(second)\n",
    "    print(tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7088, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model works\n",
    "\n",
    "ranknet_model = RankNet(num_input_features=100)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "preds = ranknet_model(first, second)\n",
    "criterion(preds, tgt.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model = RankNet(num_input_features=100, hidden_dim=16)\n",
    "ranknet_model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(ranknet_model.parameters())\n",
    "\n",
    "synth_dataset = SynthPairDataset(X_train, comparison)\n",
    "synth_dataloader = torch.utils.data.DataLoader(synth_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Number of swapped pairs: 63783.0/124750\tnDCG_at_100: 0.4547\n",
      "Number of swapped pairs: 19038.0/124750\tnDCG_at_100: 1.0000\n",
      "Number of swapped pairs: 21343.0/124750\tnDCG_at_100: 0.9980\n",
      "Number of swapped pairs: 22901.0/124750\tnDCG_at_100: 0.9782\n",
      "Number of swapped pairs: 23531.0/124750\tnDCG_at_100: 0.9805\n",
      "Number of swapped pairs: 24154.0/124750\tnDCG_at_100: 0.9744\n",
      "Number of swapped pairs: 24366.0/124750\tnDCG_at_100: 0.9777\n",
      "Number of swapped pairs: 24758.0/124750\tnDCG_at_100: 0.9700\n",
      "Number of swapped pairs: 24924.0/124750\tnDCG_at_100: 0.9649\n",
      "Number of swapped pairs: 24961.0/124750\tnDCG_at_100: 0.9630\n",
      "Number of swapped pairs: 25069.0/124750\tnDCG_at_100: 0.9691\n",
      "Number of swapped pairs: 25242.0/124750\tnDCG_at_100: 0.9647\n",
      "Number of swapped pairs: 25100.0/124750\tnDCG_at_100: 0.9619\n",
      "Number of swapped pairs: 25039.0/124750\tnDCG_at_100: 0.9701\n",
      "Number of swapped pairs: 25192.0/124750\tnDCG_at_100: 0.9697\n",
      "Number of swapped pairs: 25121.0/124750\tnDCG_at_100: 0.9623\n",
      "Train loss: 0.3091944767968194\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "num_batches = len(synth_dataset)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_losses = []\n",
    "    for it, (batch_x1, batch_x2, tgt) in enumerate(synth_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_x1 = batch_x1.to(device)\n",
    "        batch_x2 = batch_x2.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        batch_pred = ranknet_model(batch_x1, batch_x2)\n",
    "        batch_loss = criterion(batch_pred, tgt.view(-1, 1))\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(batch_loss.item() * len(batch_x1))\n",
    "\n",
    "        if it % 1000 == 0:\n",
    "            with torch.no_grad():\n",
    "                total_pairs = len(X_valid) * (len(X_valid) - 1) // 2\n",
    "                \n",
    "                valid_pred = ranknet_model.predict(X_valid.to(device)).cpu().flatten()\n",
    "                \n",
    "                valid_swapped_pairs = -(sts.kendalltau(ys_valid.numpy(), valid_pred.numpy()).statistic * total_pairs - total_pairs) // 2\n",
    "                ndcg_score_ = ndcg_k(ys_valid.flatten(), valid_pred, gain_scheme='const', k=100)\n",
    "                print(f\"Number of swapped pairs: \"\n",
    "                      f\"{valid_swapped_pairs}/{total_pairs}\\t\"\n",
    "                f\"nDCG_at_100: {ndcg_score_:.4f}\")\n",
    "                \n",
    "    print(f'Train loss: {np.sum(train_losses) / num_batches}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1VndCJKcF5O"
   },
   "source": [
    "# ListNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1737623870490,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "Z8-WfsdxcF5O"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1737623961825,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "0np813CAcF5O"
   },
   "outputs": [],
   "source": [
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_1):\n",
    "        logits = self.model(input_1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD3Vzn8QdZUi"
   },
   "source": [
    "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$\n",
    "\n",
    "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1737624014031,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "vEjM7O4ocF5P"
   },
   "outputs": [],
   "source": [
    "def listnet_ce_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i))\n",
    "\n",
    "def listnet_kl_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i/P_y_i))\n",
    "\n",
    "\n",
    "def make_dataset(N_train, N_valid, vector_dim):\n",
    "    fake_weights = torch.randn(vector_dim, 1)\n",
    "\n",
    "    X_train = torch.randn(N_train, vector_dim)\n",
    "    X_valid = torch.randn(N_valid, vector_dim)\n",
    "\n",
    "    ys_train_score = torch.mm(X_train, fake_weights)\n",
    "    ys_train_score += torch.randn_like(ys_train_score)\n",
    "\n",
    "    ys_valid_score = torch.mm(X_valid, fake_weights)\n",
    "    ys_valid_score += torch.randn_like(ys_valid_score)\n",
    "\n",
    "#     bins = [-1, 1]  # 3 relevances\n",
    "    bins = [-1, 0, 1, 2]  # 5 relevances\n",
    "    ys_train_rel = torch.Tensor(\n",
    "        np.digitize(ys_train_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "    ys_valid_rel = torch.Tensor(\n",
    "        np.digitize(ys_valid_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "\n",
    "    return X_train, X_valid, ys_train_rel, ys_valid_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 5643,
     "status": "ok",
     "timestamp": 1737624025567,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "-8p3lZEqcF5P"
   },
   "outputs": [],
   "source": [
    "N_train = 1000\n",
    "N_valid = 500\n",
    "\n",
    "vector_dim = 100\n",
    "epochs = 2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "X_train, X_valid, ys_train, ys_valid = make_dataset(N_train, N_valid, vector_dim)\n",
    "\n",
    "net = ListNet(num_input_features=vector_dim)\n",
    "opt = torch.optim.Adam(net.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737624025568,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "EXuUWyKacF5P",
    "outputId": "408c67aa-33ce-4fc4-984e-80804e894f28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16757,
     "status": "ok",
     "timestamp": 1737624094188,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "XxDX1FXncF5P",
    "outputId": "645ffea2-08c2-41f4-e174-8bbbbf6e77f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1.\tNumber of swapped pairs: 65481/124750\tnDCG: 0.8216\n",
      "epoch: 1.\tNumber of swapped pairs: 62606/124750\tnDCG: 0.8362\n",
      "epoch: 1.\tNumber of swapped pairs: 59760/124750\tnDCG: 0.8553\n",
      "epoch: 1.\tNumber of swapped pairs: 57234/124750\tnDCG: 0.8702\n",
      "epoch: 1.\tNumber of swapped pairs: 54528/124750\tnDCG: 0.8853\n",
      "epoch: 1.\tNumber of swapped pairs: 51845/124750\tnDCG: 0.9033\n",
      "epoch: 1.\tNumber of swapped pairs: 49097/124750\tnDCG: 0.9222\n",
      "epoch: 2.\tNumber of swapped pairs: 48541/124750\tnDCG: 0.9240\n",
      "epoch: 2.\tNumber of swapped pairs: 46233/124750\tnDCG: 0.9352\n",
      "epoch: 2.\tNumber of swapped pairs: 44302/124750\tnDCG: 0.9443\n",
      "epoch: 2.\tNumber of swapped pairs: 42614/124750\tnDCG: 0.9529\n",
      "epoch: 2.\tNumber of swapped pairs: 40890/124750\tnDCG: 0.9613\n",
      "epoch: 2.\tNumber of swapped pairs: 39246/124750\tnDCG: 0.9678\n",
      "epoch: 2.\tNumber of swapped pairs: 37845/124750\tnDCG: 0.9719\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    idx = torch.randperm(N_train)\n",
    "\n",
    "    X_train = X_train[idx]\n",
    "    ys_train = ys_train[idx]\n",
    "\n",
    "    cur_batch = 0\n",
    "    for it in range(N_train // batch_size):\n",
    "        batch_X = X_train[cur_batch: cur_batch + batch_size]\n",
    "        batch_ys = ys_train[cur_batch: cur_batch + batch_size]\n",
    "        cur_batch += batch_size\n",
    "\n",
    "        opt.zero_grad()\n",
    "        if len(batch_X) > 0:\n",
    "            batch_pred = net(batch_X)\n",
    "            batch_loss = listnet_kl_loss(batch_ys, batch_pred)\n",
    "#             batch_loss = listnet_ce_loss(batch_ys, batch_pred)\n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_pred = net(X_valid)\n",
    "                valid_swapped_pairs = num_swapped_pairs(ys_valid.flatten(),\n",
    "                                                        valid_pred.flatten())\n",
    "                ndcg_score = ndcg(ys_valid.flatten(), valid_pred.flatten())\n",
    "            print(f\"epoch: {epoch + 1}.\\tNumber of swapped pairs: \"\n",
    "                  f\"{valid_swapped_pairs}/{N_valid * (N_valid - 1) // 2}\\t\"\n",
    "                  f\"nDCG: {ndcg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgakHYb-e5FZ"
   },
   "source": [
    "# Task solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "error",
     "timestamp": 1737624385009,
     "user": {
      "displayName": "Roman Safronenkov",
      "userId": "04023794386653200418"
     },
     "user_tz": -180
    },
    "id": "ayfgP4vse2V_",
    "outputId": "9431a9b0-01f1-4361-a06c-27b757aaf7be"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, hidden_dim),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_1: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.model(input_1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_epochs: int = 5, listnet_hidden_dim: int = 30,\n",
    "                 lr: float = 0.001, ndcg_top_k: int = 10):\n",
    "        self._prepare_data()\n",
    "        self.num_input_features = self.X_train.shape[1]\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        self.model = self._create_model(\n",
    "            self.num_input_features, listnet_hidden_dim)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        \n",
    "        self.X_train = self._scale_features_in_query_groups(X_train, self.query_ids_train)\n",
    "        self.X_test = self._scale_features_in_query_groups(X_test, self.query_ids_test)\n",
    "\n",
    "        self.ys_train = torch.as_tensor(y_train, dtype=torch.float32)\n",
    "        self.ys_test = torch.as_tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        scaled_features = np.zeros_like(inp_feat_array)\n",
    "        \n",
    "        for query in np.unique(inp_query_ids):\n",
    "            idxs = np.where(inp_query_ids == query)[0]\n",
    "            scaled_features[idxs] = StandardScaler().fit_transform(inp_feat_array[idxs])\n",
    "        return torch.as_tensor(scaled_features, dtype=torch.float32)\n",
    "\n",
    "    def _create_model(self, listnet_num_input_features: int,\n",
    "                      listnet_hidden_dim: int) -> torch.nn.Module:\n",
    "        torch.manual_seed(0)\n",
    "        net = ListNet(listnet_num_input_features, listnet_hidden_dim)\n",
    "        return net\n",
    "\n",
    "    def fit(self) -> List[float]:\n",
    "        ndcgs = []\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self._train_one_epoch()\n",
    "\n",
    "            ndcg = self._eval_test_set()\n",
    "            ndcgs.append(ndcg)\n",
    "            print(f'Epoch: {epoch+1}. NDCG_{self.ndcg_top_k}: {ndcg}')\n",
    "        return ndcgs\n",
    "\n",
    "    def _calc_loss(self, batch_ys: torch.FloatTensor,\n",
    "                   batch_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        P_y_i = torch.softmax(batch_ys, dim=0)\n",
    "        P_z_i = torch.softmax(batch_pred, dim=0)\n",
    "        return -torch.sum(P_y_i * torch.log(P_z_i))\n",
    "\n",
    "    def _train_one_epoch(self) -> None:\n",
    "        self.model.train()\n",
    "        for query in np.unique(self.query_ids_train):\n",
    "            query_idxs = np.where(self.query_ids_train == query)[0]\n",
    "            query_x = self.X_train[query_idxs]\n",
    "            query_y = self.ys_train[query_idxs]\n",
    "            \n",
    "            # здесь можно добавить итерацию по батчам\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            preds = self.model(query_x).flatten()\n",
    "            loss = self._calc_loss(query_y, preds)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def _eval_test_set(self) -> float:\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            ndcgs = []\n",
    "            for query in np.unique(self.query_ids_test):\n",
    "                query_idxs = np.where(self.query_ids_test == query)[0]\n",
    "                query_x = self.X_test[query_idxs]\n",
    "                query_y = self.ys_test[query_idxs].flatten()\n",
    "                \n",
    "                preds = self.model(query_x).flatten()\n",
    "                ndcg = self._ndcg_k(query_y, preds, ndcg_top_k=self.ndcg_top_k)\n",
    "\n",
    "                ndcgs.append(ndcg)\n",
    "            return np.mean(ndcgs)\n",
    "\n",
    "    def _ndcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "                ndcg_top_k: int) -> float:\n",
    "        \n",
    "        def compute_gain(y_value: float, gain_scheme: str) -> float:\n",
    "            assert gain_scheme in ['const', 'exp2']\n",
    "            if gain_scheme == 'const':\n",
    "                return y_value\n",
    "            elif gain_scheme == 'exp2':\n",
    "                return 2 ** y_value - 1\n",
    "        \n",
    "        \n",
    "        def dcg_k(ys_true: Tensor, ys_pred: Tensor, gain_scheme: str, k: int) -> float:\n",
    "            dcg_value = 0\n",
    "            _, sorted_ys_pred_idx = sort(ys_pred, descending=True)\n",
    "            for i, rel in enumerate(ys_true[sorted_ys_pred_idx][:k]):\n",
    "                dcg_value += compute_gain(rel, gain_scheme=gain_scheme) / log2(i+2)\n",
    "            return dcg_value\n",
    "\n",
    "        # расчет по экспоненциальной формуле\n",
    "        dcg_value = dcg_k(ys_true, ys_pred, gain_scheme='exp2', k=ndcg_top_k)\n",
    "        perfect_dcg = dcg_k(ys_true, ys_true, gain_scheme='exp2', k=ndcg_top_k)\n",
    "        \n",
    "        return dcg_value / perfect_dcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "dsLw4YTje_Nu"
   },
   "outputs": [],
   "source": [
    "solution = Solution(listnet_hidden_dim=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. NDCG_10: 0.41444405913352966\n",
      "Epoch: 2. NDCG_10: 0.43271610140800476\n",
      "Epoch: 3. NDCG_10: 0.4335741698741913\n",
      "Epoch: 4. NDCG_10: 0.4383959472179413\n",
      "Epoch: 5. NDCG_10: 0.43431270122528076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41444406, 0.4327161, 0.43357417, 0.43839595, 0.4343127]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "uplift",
   "language": "python",
   "name": "uplift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
