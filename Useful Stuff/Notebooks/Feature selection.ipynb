{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc430f5a-a85f-46f3-b59c-c0899b271c96",
   "metadata": {},
   "source": [
    "# Ноутбук по отбору признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc81f7-8fa8-497e-9b70-6f6f1dc24abe",
   "metadata": {},
   "source": [
    "[Пример ноутбука в котором идет речь про отбор признаков](https://github.com/RomanSafronenkov/mlcourse.ai/blob/main/jupyter_russian/topic06_features/topic6_feature_engineering_feature_selection_russian.ipynb)\n",
    "\n",
    "[Sequential Feature Selection с объяснениями](https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/#sequentialfeatureselector)\n",
    "\n",
    "[О том, почему плох встроенный в RandomForest feature_importance](https://explained.ai/rf-importance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54ca4cc-a2d7-4fc3-bf24-6bc3f1a9b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/MyProjects/Data Science/uplift/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfcbe25-5b18-487a-a32d-988a6ac738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим искусственный датасет, в котором будут информативные признаки, их дубликаты, их комбинации и шумовые признаки\n",
    "x, y = make_classification(\n",
    "    n_samples=10000, n_features=100, n_informative=15, n_redundant=5, n_repeated=5, n_clusters_per_class=4, shift=0.8, scale=3.0, shuffle=False)\n",
    "\n",
    "# если не ставить параметр shuffle в True, то сначала будут идти информативные признаки, потом комбинации и потом повторы, после них - мусор\n",
    "# так удобнее оценить как это все работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bfad0a-c7f1-44b9-9e6b-a64928f46694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9567004795353707"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x, y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88678b01-1301-47b5-8fc7-2e596afdf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureSelector(ABC):\n",
    "    def __init__(self, n_folds=5):\n",
    "        self.n_folds = n_folds\n",
    "        self.importances = None\n",
    "\n",
    "    def fit(self, x, y, **importances_kwargs):\n",
    "        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True)  # можно число фолдов и прочие параметры\n",
    "\n",
    "        self.importances = pd.DataFrame({'feature': np.arange(x.shape[1])})\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(x, y)):\n",
    "            x_train, y_train = x[train_index], y[train_index]\n",
    "            x_val, y_val = x[val_index], y[val_index]\n",
    "\n",
    "            model = LGBMClassifier(max_depth=5, n_estimators=500, learning_rate=0.05, verbose=-100)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            imp = self._get_importances_from_model(model, x_val, y_val, **importances_kwargs)\n",
    "\n",
    "            self.importances[f'importance_{i}'] = imp\n",
    "\n",
    "    def get_selected_features(self, threshold):\n",
    "        assert self.importances is not None, 'Сначала нужно обучить, вызвав метод fit'\n",
    "\n",
    "        # сделаем отдельно для 0 итерации\n",
    "        imps = self.importances.loc[:, ['feature', 'importance_0']].sort_values('importance_0', ascending=False)  # выберем важности признаков с 0 итерации\n",
    "        imps['importance_0'] /= imps['importance_0'].sum()\n",
    "        imps['cumsum'] = imps['importance_0'].cumsum()  # так как мы их отнормировали, может посчитать кумулятивную сумму\n",
    "        features = imps.loc[imps['cumsum'] <= threshold, 'feature'].tolist()  # возьмем только те признаки, которые по кумулятивной сумме удовлетворяют\n",
    "        \n",
    "        best_features = set(features)  # сделаем множество\n",
    "        for i in range(1, self.n_folds):\n",
    "            imps = self.importances.loc[:, ['feature', f'importance_{i}']].sort_values(f'importance_{i}', ascending=False)\n",
    "            imps[f'importance_{i}'] /= imps[f'importance_{i}'].sum()\n",
    "            imps['cumsum'] = imps[f'importance_{i}'].cumsum()\n",
    "            features = imps.loc[imps['cumsum'] <= threshold, 'feature'].tolist()\n",
    "\n",
    "            best_features &= set(features)  # смотрим на пересечения множеств на разных итерациях кросс-валидации\n",
    "\n",
    "        return list(best_features)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _get_importances_from_model(self, model, x, y, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01b768a-e47b-4d1a-bcbc-2e9a3ae58641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор признаков с использованием встроеного feature_importance\n",
    "class LGMFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, importance_type='split'):\n",
    "        return model.booster_.feature_importance(importance_type=importance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea39737-a6a5-4d18-bc56-879d50fdf2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 s, sys: 163 ms, total: 25.2 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgm_fs = LGMFeatureSelection()\n",
    "lgm_fs.fit(x, y, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de006691-65fa-49bc-bf0d-9a50386d2ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>350</td>\n",
       "      <td>371</td>\n",
       "      <td>335</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>386</td>\n",
       "      <td>362</td>\n",
       "      <td>387</td>\n",
       "      <td>412</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>415</td>\n",
       "      <td>405</td>\n",
       "      <td>414</td>\n",
       "      <td>401</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>281</td>\n",
       "      <td>240</td>\n",
       "      <td>269</td>\n",
       "      <td>237</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>429</td>\n",
       "      <td>365</td>\n",
       "      <td>396</td>\n",
       "      <td>413</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>490</td>\n",
       "      <td>455</td>\n",
       "      <td>495</td>\n",
       "      <td>481</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>275</td>\n",
       "      <td>298</td>\n",
       "      <td>263</td>\n",
       "      <td>297</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>328</td>\n",
       "      <td>279</td>\n",
       "      <td>294</td>\n",
       "      <td>332</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>347</td>\n",
       "      <td>348</td>\n",
       "      <td>359</td>\n",
       "      <td>369</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>291</td>\n",
       "      <td>252</td>\n",
       "      <td>288</td>\n",
       "      <td>315</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>322</td>\n",
       "      <td>253</td>\n",
       "      <td>302</td>\n",
       "      <td>268</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>296</td>\n",
       "      <td>266</td>\n",
       "      <td>262</td>\n",
       "      <td>304</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>517</td>\n",
       "      <td>497</td>\n",
       "      <td>481</td>\n",
       "      <td>490</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>356</td>\n",
       "      <td>304</td>\n",
       "      <td>373</td>\n",
       "      <td>316</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>356</td>\n",
       "      <td>318</td>\n",
       "      <td>409</td>\n",
       "      <td>396</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>309</td>\n",
       "      <td>279</td>\n",
       "      <td>280</td>\n",
       "      <td>307</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>254</td>\n",
       "      <td>265</td>\n",
       "      <td>291</td>\n",
       "      <td>281</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>177</td>\n",
       "      <td>157</td>\n",
       "      <td>143</td>\n",
       "      <td>154</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>171</td>\n",
       "      <td>165</td>\n",
       "      <td>148</td>\n",
       "      <td>129</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>249</td>\n",
       "      <td>240</td>\n",
       "      <td>243</td>\n",
       "      <td>254</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0           361           350           371           335   \n",
       "1         1           386           362           387           412   \n",
       "2         2           415           405           414           401   \n",
       "3         3           281           240           269           237   \n",
       "4         4           429           365           396           413   \n",
       "5         5           490           455           495           481   \n",
       "6         6           275           298           263           297   \n",
       "7         7           328           279           294           332   \n",
       "8         8           347           348           359           369   \n",
       "9         9           291           252           288           315   \n",
       "10       10           322           253           302           268   \n",
       "11       11           296           266           262           304   \n",
       "12       12           517           497           481           490   \n",
       "13       13           356           304           373           316   \n",
       "14       14           356           318           409           396   \n",
       "15       15           309           279           280           307   \n",
       "16       16           254           265           291           281   \n",
       "17       17           177           157           143           154   \n",
       "18       18           171           165           148           129   \n",
       "19       19           249           240           243           254   \n",
       "\n",
       "    importance_4  \n",
       "0            349  \n",
       "1            383  \n",
       "2            415  \n",
       "3            330  \n",
       "4            443  \n",
       "5            407  \n",
       "6            326  \n",
       "7            339  \n",
       "8            332  \n",
       "9            293  \n",
       "10           295  \n",
       "11           280  \n",
       "12           510  \n",
       "13           329  \n",
       "14           390  \n",
       "15           304  \n",
       "16           251  \n",
       "17           190  \n",
       "18           171  \n",
       "19           240  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2449fe0-b092-4f41-9825-631bf2e26c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs = lgm_fs.get_selected_features(threshold=0.7)\n",
    "len(best_features_lgm_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d8f0c2-ce91-4c0f-b006-46a92ac88dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs  # видно, что идут по порядку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29535fe-3a53-4e98-8115-c81b16ecbf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644985004458443"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_lgm_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6c2ad2-f4cc-442b-a9ff-b9179fc05ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем тоже самое, но с помощью shap values\n",
    "class ShapFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, feature_perturbation='tree_path_dependent'):\n",
    "        explainer = shap.TreeExplainer(model, feature_perturbation=feature_perturbation)\n",
    "        shap_values = explainer.shap_values(x)\n",
    "\n",
    "        if isinstance(shap_values, list):\n",
    "            importances = np.abs(shap_values[1]).mean(0)\n",
    "        else:\n",
    "            importances = np.abs(shap_values).mean(0)\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53241cd3-5d92-4b39-a8c4-5bc0a9b43f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 192 ms, total: 1min 5s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shap_fs = ShapFeatureSelection()\n",
    "shap_fs.fit(x, y, feature_perturbation='tree_path_dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd28bdf-6f84-4874-aad4-0b8f59f11606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.750796</td>\n",
       "      <td>0.739108</td>\n",
       "      <td>0.727017</td>\n",
       "      <td>0.738715</td>\n",
       "      <td>0.716016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.562528</td>\n",
       "      <td>0.555469</td>\n",
       "      <td>0.507830</td>\n",
       "      <td>0.541028</td>\n",
       "      <td>0.534878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.321572</td>\n",
       "      <td>0.375776</td>\n",
       "      <td>0.357566</td>\n",
       "      <td>0.315690</td>\n",
       "      <td>0.343478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084946</td>\n",
       "      <td>0.075137</td>\n",
       "      <td>0.083525</td>\n",
       "      <td>0.088487</td>\n",
       "      <td>0.072988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.395545</td>\n",
       "      <td>0.340122</td>\n",
       "      <td>0.361653</td>\n",
       "      <td>0.372098</td>\n",
       "      <td>0.333939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.804741</td>\n",
       "      <td>0.798588</td>\n",
       "      <td>0.771174</td>\n",
       "      <td>0.779608</td>\n",
       "      <td>0.762330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.099124</td>\n",
       "      <td>0.127984</td>\n",
       "      <td>0.111789</td>\n",
       "      <td>0.129219</td>\n",
       "      <td>0.092679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.145370</td>\n",
       "      <td>0.163453</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.143696</td>\n",
       "      <td>0.135688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.220041</td>\n",
       "      <td>0.193617</td>\n",
       "      <td>0.198519</td>\n",
       "      <td>0.186115</td>\n",
       "      <td>0.187533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.103831</td>\n",
       "      <td>0.105477</td>\n",
       "      <td>0.100209</td>\n",
       "      <td>0.104462</td>\n",
       "      <td>0.098064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>0.161055</td>\n",
       "      <td>0.161651</td>\n",
       "      <td>0.176316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.237206</td>\n",
       "      <td>0.262350</td>\n",
       "      <td>0.245834</td>\n",
       "      <td>0.233253</td>\n",
       "      <td>0.215309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.791592</td>\n",
       "      <td>0.747561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.241872</td>\n",
       "      <td>0.233996</td>\n",
       "      <td>0.248514</td>\n",
       "      <td>0.261821</td>\n",
       "      <td>0.250308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.394078</td>\n",
       "      <td>0.382676</td>\n",
       "      <td>0.369138</td>\n",
       "      <td>0.378897</td>\n",
       "      <td>0.371747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.335518</td>\n",
       "      <td>0.306889</td>\n",
       "      <td>0.301345</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.328921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.256980</td>\n",
       "      <td>0.260259</td>\n",
       "      <td>0.254053</td>\n",
       "      <td>0.254734</td>\n",
       "      <td>0.230808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.201983</td>\n",
       "      <td>0.192048</td>\n",
       "      <td>0.177655</td>\n",
       "      <td>0.221558</td>\n",
       "      <td>0.216113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.071963</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>0.077775</td>\n",
       "      <td>0.099765</td>\n",
       "      <td>0.123630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>0.126918</td>\n",
       "      <td>0.130189</td>\n",
       "      <td>0.117099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0      0.750796      0.739108      0.727017      0.738715   \n",
       "1         1      0.562528      0.555469      0.507830      0.541028   \n",
       "2         2      0.321572      0.375776      0.357566      0.315690   \n",
       "3         3      0.084946      0.075137      0.083525      0.088487   \n",
       "4         4      0.395545      0.340122      0.361653      0.372098   \n",
       "5         5      0.804741      0.798588      0.771174      0.779608   \n",
       "6         6      0.099124      0.127984      0.111789      0.129219   \n",
       "7         7      0.145370      0.163453      0.143607      0.143696   \n",
       "8         8      0.220041      0.193617      0.198519      0.186115   \n",
       "9         9      0.103831      0.105477      0.100209      0.104462   \n",
       "10       10      0.160238      0.137174      0.161055      0.161651   \n",
       "11       11      0.237206      0.262350      0.245834      0.233253   \n",
       "12       12      0.827485      0.784983      0.796380      0.791592   \n",
       "13       13      0.241872      0.233996      0.248514      0.261821   \n",
       "14       14      0.394078      0.382676      0.369138      0.378897   \n",
       "15       15      0.335518      0.306889      0.301345      0.304878   \n",
       "16       16      0.256980      0.260259      0.254053      0.254734   \n",
       "17       17      0.201983      0.192048      0.177655      0.221558   \n",
       "18       18      0.071963      0.057369      0.077775      0.099765   \n",
       "19       19      0.155488      0.084666      0.126918      0.130189   \n",
       "\n",
       "    importance_4  \n",
       "0       0.716016  \n",
       "1       0.534878  \n",
       "2       0.343478  \n",
       "3       0.072988  \n",
       "4       0.333939  \n",
       "5       0.762330  \n",
       "6       0.092679  \n",
       "7       0.135688  \n",
       "8       0.187533  \n",
       "9       0.098064  \n",
       "10      0.176316  \n",
       "11      0.215309  \n",
       "12      0.747561  \n",
       "13      0.250308  \n",
       "14      0.371747  \n",
       "15      0.328921  \n",
       "16      0.230808  \n",
       "17      0.216113  \n",
       "18      0.123630  \n",
       "19      0.117099  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6753630-f72b-4129-a1e5-9b5e985dd7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_shap_fs = shap_fs.get_selected_features(threshold=0.85)\n",
    "len(best_features_shap_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "def42639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_shap_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c6581c-9cd6-4a87-af58-287553de47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642100994230404"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_shap_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b11cb11-fa8f-45b3-a4df-25896887a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# самый интуитивно понятный метод, но самый долгий - permutation importance\n",
    "class PIFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, **permutation_kwargs):\n",
    "        importances = np.abs(permutation_importance(model, x, y, **permutation_kwargs)['importances_mean'])\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff965a9f-4faf-418f-ae2f-93628861da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 557 ms, total: 1min 34s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pi_fs = PIFeatureSelection()\n",
    "pi_fs.fit(x, y, scoring='roc_auc', n_jobs=-1, n_repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ba9558-7501-4b8d-871f-a8be0eb69b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.041881</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.047403</td>\n",
       "      <td>0.042914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.037718</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>0.033416</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>0.029483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017671</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.017859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.029871</td>\n",
       "      <td>0.021749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.070125</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.066079</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.054080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.011085</td>\n",
       "      <td>0.008549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.011636</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.011487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.005918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.005891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.007782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>0.052906</td>\n",
       "      <td>0.059771</td>\n",
       "      <td>0.061131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.010542</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.011753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.024470</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.019123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>0.009455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.007561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.003866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0      0.041881      0.039535      0.045238      0.047403   \n",
       "1         1      0.037718      0.031919      0.033416      0.033701   \n",
       "2         2      0.017671      0.018634      0.020620      0.020181   \n",
       "3         3      0.002808      0.003254      0.002846      0.003017   \n",
       "4         4      0.025036      0.024792      0.022989      0.029871   \n",
       "5         5      0.070125      0.057745      0.066079      0.068766   \n",
       "6         6      0.004505      0.003887      0.002299      0.003179   \n",
       "7         7      0.009651      0.007468      0.008905      0.011085   \n",
       "8         8      0.010120      0.010996      0.011636      0.012031   \n",
       "9         9      0.004242      0.004496      0.006520      0.005576   \n",
       "10       10      0.003198      0.005032      0.006029      0.005814   \n",
       "11       11      0.007498      0.007242      0.009809      0.007042   \n",
       "12       12      0.056948      0.055638      0.052906      0.059771   \n",
       "13       13      0.010542      0.012644      0.011863      0.012449   \n",
       "14       14      0.021250      0.022990      0.024470      0.022019   \n",
       "15       15      0.011406      0.010812      0.011881      0.011650   \n",
       "16       16      0.006228      0.005925      0.008329      0.007195   \n",
       "17       17      0.004027      0.002884      0.003639      0.003810   \n",
       "18       18      0.000815      0.001741      0.001658      0.001080   \n",
       "19       19      0.003141      0.002360      0.003100      0.006206   \n",
       "\n",
       "    importance_4  \n",
       "0       0.042914  \n",
       "1       0.029483  \n",
       "2       0.017859  \n",
       "3       0.002194  \n",
       "4       0.021749  \n",
       "5       0.054080  \n",
       "6       0.003585  \n",
       "7       0.008549  \n",
       "8       0.011487  \n",
       "9       0.005918  \n",
       "10      0.005891  \n",
       "11      0.007782  \n",
       "12      0.061131  \n",
       "13      0.011753  \n",
       "14      0.019123  \n",
       "15      0.009455  \n",
       "16      0.007561  \n",
       "17      0.003122  \n",
       "18      0.001581  \n",
       "19      0.003866  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0caa64a-2fe7-4231-908a-a761cffc36a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_pi_fs = pi_fs.get_selected_features(threshold=0.99)\n",
    "len(best_features_pi_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32428acc-8308-433c-b1f9-c425a7a75329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 41, 94]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_pi_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e645f68a-e3f0-4a7b-b57d-d789fb2aad9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635214953930229"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_pi_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ad44e-dbab-4b4e-9747-cc9580b1c50c",
   "metadata": {},
   "source": [
    "# Жадные методы отбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "090d6e82-9a20-4118-8d8c-748312a449cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialForwardFeatureSelection:\n",
    "    def __init__(self, model, n_folds, k, smooth=False, stratified=True, scoring='roc_auc'):\n",
    "        self.model = model\n",
    "        self.n_folds = n_folds\n",
    "        self.k = k\n",
    "        self.stratified = True\n",
    "        self.smooth = smooth\n",
    "        self.scoring = scoring\n",
    "\n",
    "    def _find_feature_to_add(self, x, y, cur_subset, set_to_choose_from):\n",
    "        best_score = float('-inf')\n",
    "        best_feature = None\n",
    "\n",
    "        print('*'*30)\n",
    "        print('Looking for feature to ADD...')\n",
    "\n",
    "        for feature in set_to_choose_from:\n",
    "            cur_subset_copy = cur_subset.copy()\n",
    "            cur_subset_copy += [feature]\n",
    "\n",
    "            subset_x = x[:, cur_subset_copy]\n",
    "            if self.stratified:\n",
    "                cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "            else:\n",
    "                cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "            score = cross_val_score(estimator=self.model, X=subset_x, y=y, cv=cv, scoring=self.scoring).mean()\n",
    "            if score > best_score:\n",
    "                best_feature = feature\n",
    "                best_score = score\n",
    "                \n",
    "        print(f'Best score = {best_score:.4f}')\n",
    "        return best_feature\n",
    "\n",
    "    def _find_feature_to_delete(self, x, y, cur_subset):\n",
    "        if self.stratified:\n",
    "            cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "        else:\n",
    "            cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "        best_score = cross_val_score(estimator=self.model, X=x[:, cur_subset], y=y, cv=cv, scoring=self.scoring).mean()\n",
    "        worst_feature = None\n",
    "\n",
    "        print('='*30)\n",
    "        print('Looking for feature to DELETE...')\n",
    "        print(f'Best score = {best_score:.4f}')\n",
    "\n",
    "        for feature in cur_subset:\n",
    "            cur_subset_copy = cur_subset.copy()\n",
    "            del cur_subset_copy[cur_subset_copy.index(feature)]\n",
    "\n",
    "            subset_x = x[:, cur_subset_copy]\n",
    "            if self.stratified:\n",
    "                cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "            else:\n",
    "                cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "            score = cross_val_score(estimator=self.model, X=subset_x, y=y, cv=cv, scoring=self.scoring).mean()\n",
    "            if score > best_score:\n",
    "                worst_feature = feature\n",
    "                best_score = score\n",
    "        return worst_feature\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        best_features = []\n",
    "        set_to_choose_from = list(range(x.shape[1]))\n",
    "\n",
    "        best_feature = self._find_feature_to_add(x=x, y=y, cur_subset=best_features, set_to_choose_from=set_to_choose_from)\n",
    "        best_features += [best_feature]\n",
    "        print(f'Added feature {best_feature}, current subset = {best_features}')\n",
    "        del set_to_choose_from[set_to_choose_from.index(best_feature)]\n",
    "\n",
    "        while len(best_features) < self.k:\n",
    "            best_feature = self._find_feature_to_add(x=x, y=y, cur_subset=best_features, set_to_choose_from=set_to_choose_from)\n",
    "            best_features += [best_feature]\n",
    "            print(f'Added feature {best_feature}, current subset = {best_features}')\n",
    "            del set_to_choose_from[set_to_choose_from.index(best_feature)]\n",
    "\n",
    "            if len(best_features) > 2 and self.smooth:\n",
    "                worst_feature = self._find_feature_to_delete(x=x, y=y, cur_subset=best_features)\n",
    "                if worst_feature == best_feature:\n",
    "                    break\n",
    "\n",
    "                if worst_feature is not None:\n",
    "                    del best_features[best_features.index(worst_feature)]\n",
    "                    print(f'Deleted feature {worst_feature}, current subset = {best_features}')\n",
    "                    set_to_choose_from += [worst_feature]\n",
    "\n",
    "                    while len(best_features) > 2:\n",
    "                        worst_feature = self._find_feature_to_delete(x=x, y=y, cur_subset=best_features)\n",
    "                        if worst_feature is None:\n",
    "                            break\n",
    "                        del best_features[best_features.index(worst_feature)]\n",
    "                        print(f'Deleted feature {worst_feature}, current subset = {best_features}')\n",
    "                        set_to_choose_from += [worst_feature]\n",
    "        return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "458ba976-ac38-4b6b-b42f-9098aeca7332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.6676\n",
      "Added feature 0, current subset = [0]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7425\n",
      "Added feature 12, current subset = [0, 12]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7948\n",
      "Added feature 5, current subset = [0, 12, 5]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8323\n",
      "Added feature 1, current subset = [0, 12, 5, 1]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8632\n",
      "Added feature 2, current subset = [0, 12, 5, 1, 2]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8893\n",
      "Added feature 15, current subset = [0, 12, 5, 1, 2, 15]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9056\n",
      "Added feature 21, current subset = [0, 12, 5, 1, 2, 15, 21]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9205\n",
      "Added feature 8, current subset = [0, 12, 5, 1, 2, 15, 21, 8]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9329\n",
      "Added feature 22, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9468\n",
      "Added feature 7, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9527\n",
      "Added feature 20, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9579\n",
      "Added feature 13, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9612\n",
      "Added feature 10, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9647\n",
      "Added feature 3, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9664\n",
      "Added feature 9, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3, 9]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9682\n",
      "Added feature 6, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3, 9, 6]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9692\n",
      "Added feature 18, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3, 9, 6, 18]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9694\n",
      "Added feature 4, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3, 9, 6, 18, 4]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9690\n",
      "Added feature 11, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3, 9, 6, 18, 4, 11]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9691\n",
      "Added feature 14, current subset = [0, 12, 5, 1, 2, 15, 21, 8, 22, 7, 20, 13, 10, 3, 9, 6, 18, 4, 11, 14]\n",
      "CPU times: user 2h 30min, sys: 4min 16s, total: 2h 34min 17s\n",
      "Wall time: 1h 17min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# самый долгий\n",
    "\n",
    "seq_fs = SequentialForwardFeatureSelection(\n",
    "    model=LGBMClassifier(max_depth=5, n_estimators=500, learning_rate=0.05, verbose=-100),\n",
    "    n_folds=5,\n",
    "    k=20)\n",
    "best_features_seq_fs = seq_fs.fit(x, y)\n",
    "len(best_features_seq_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b9eb5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_features_seq_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ed9ba2fe-5506-465a-b94e-d0f76c056213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579893735297735"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_seq_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "050d05da-d997-4046-a874-8d4feff051c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19},\n",
       " {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19},\n",
       " {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 40})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(best_features_lgm_fs) & set(best_features_shap_fs), set(best_features_lgm_fs) & set(best_features_pi_fs), set(best_features_pi_fs) & set(best_features_shap_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e4b81-090e-4e20-b9c7-8353f74938b4",
   "metadata": {},
   "source": [
    "# Но что, если признаков очень много?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fddfadb1-f207-4c98-854d-6da2b1c297f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=100000, n_features=1000, n_informative=35, n_redundant=7, n_repeated=8, n_clusters_per_class=4, shift=0.8, scale=3.0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c05a2460-10f2-47f1-8a7c-e587736f6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18min 55s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgm_fs = LGMFeatureSelection()\n",
    "lgm_fs.fit(x, y, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0a51dedf-b861-4909-bcb4-8437841eb45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699239396992393"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x, y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d0068d78-e0c6-4fdd-895a-c36014a29863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>358</td>\n",
       "      <td>349</td>\n",
       "      <td>396</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>378</td>\n",
       "      <td>361</td>\n",
       "      <td>366</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>246</td>\n",
       "      <td>245</td>\n",
       "      <td>255</td>\n",
       "      <td>260</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>306</td>\n",
       "      <td>299</td>\n",
       "      <td>305</td>\n",
       "      <td>293</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>314</td>\n",
       "      <td>294</td>\n",
       "      <td>298</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>401</td>\n",
       "      <td>398</td>\n",
       "      <td>375</td>\n",
       "      <td>376</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>269</td>\n",
       "      <td>259</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>319</td>\n",
       "      <td>326</td>\n",
       "      <td>333</td>\n",
       "      <td>313</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>257</td>\n",
       "      <td>269</td>\n",
       "      <td>279</td>\n",
       "      <td>249</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>276</td>\n",
       "      <td>257</td>\n",
       "      <td>250</td>\n",
       "      <td>261</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>283</td>\n",
       "      <td>295</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>327</td>\n",
       "      <td>335</td>\n",
       "      <td>371</td>\n",
       "      <td>329</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>433</td>\n",
       "      <td>408</td>\n",
       "      <td>450</td>\n",
       "      <td>428</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>256</td>\n",
       "      <td>254</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>258</td>\n",
       "      <td>281</td>\n",
       "      <td>272</td>\n",
       "      <td>276</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>261</td>\n",
       "      <td>267</td>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>366</td>\n",
       "      <td>332</td>\n",
       "      <td>357</td>\n",
       "      <td>348</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>241</td>\n",
       "      <td>209</td>\n",
       "      <td>207</td>\n",
       "      <td>240</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>296</td>\n",
       "      <td>312</td>\n",
       "      <td>292</td>\n",
       "      <td>293</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>205</td>\n",
       "      <td>230</td>\n",
       "      <td>228</td>\n",
       "      <td>215</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0           360           358           349           396   \n",
       "1         1           370           378           361           366   \n",
       "2         2           246           245           255           260   \n",
       "3         3           306           299           305           293   \n",
       "4         4           283           314           294           298   \n",
       "5         5           401           398           375           376   \n",
       "6         6           269           259           266           263   \n",
       "7         7           319           326           333           313   \n",
       "8         8           257           269           279           249   \n",
       "9         9           276           257           250           261   \n",
       "10       10           283           295           285           285   \n",
       "11       11           327           335           371           329   \n",
       "12       12           433           408           450           428   \n",
       "13       13           263           247           256           254   \n",
       "14       14           258           281           272           276   \n",
       "15       15           261           267           277           278   \n",
       "16       16           366           332           357           348   \n",
       "17       17           241           209           207           240   \n",
       "18       18           296           312           292           293   \n",
       "19       19           205           230           228           215   \n",
       "\n",
       "    importance_4  \n",
       "0            354  \n",
       "1            367  \n",
       "2            288  \n",
       "3            313  \n",
       "4            302  \n",
       "5            396  \n",
       "6            251  \n",
       "7            352  \n",
       "8            286  \n",
       "9            273  \n",
       "10           264  \n",
       "11           351  \n",
       "12           419  \n",
       "13           226  \n",
       "14           251  \n",
       "15           264  \n",
       "16           324  \n",
       "17           216  \n",
       "18           267  \n",
       "19           216  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e10167c0-e9d0-407d-a379-c8348f9a3d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs = lgm_fs.get_selected_features(threshold=0.85)\n",
    "len(best_features_lgm_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7f6a87e9-74ff-425b-b28d-ed40080b6c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699724176997242"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_lgm_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "99286aad-15fe-4178-9eb7-0ea996abd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# видимо имеет смысл осторожнее выбирать отсечку, либо объединять результаты нескольких методов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uplift",
   "language": "python",
   "name": "uplift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
