{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc430f5a-a85f-46f3-b59c-c0899b271c96",
   "metadata": {},
   "source": [
    "# Ноутбук по отбору признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc81f7-8fa8-497e-9b70-6f6f1dc24abe",
   "metadata": {},
   "source": [
    "[Пример ноутбука в котором идет речь про отбор признаков](https://github.com/RomanSafronenkov/mlcourse.ai/blob/main/jupyter_russian/topic06_features/topic6_feature_engineering_feature_selection_russian.ipynb)\n",
    "\n",
    "[Sequential Feature Selection с объяснениями](https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/#sequentialfeatureselector)\n",
    "\n",
    "[О том, почему плох встроенный в RandomForest feature_importance](https://explained.ai/rf-importance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b54ca4cc-a2d7-4fc3-bf24-6bc3f1a9b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfcbe25-5b18-487a-a32d-988a6ac738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим искусственный датасет, в котором будут информативные признаки, их дубликаты, их комбинации и шумовые признаки\n",
    "x, y = make_classification(\n",
    "    n_samples=10000, n_features=100, n_informative=15, n_redundant=5, n_repeated=5, n_clusters_per_class=4, shift=0.8, scale=3.0, shuffle=False)\n",
    "\n",
    "# если не ставить параметр shuffle в True, то сначала будут идти информативные признаки, потом комбинации и потом повторы, после них - мусор\n",
    "# так удобнее оценить как это все работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55bfad0a-c7f1-44b9-9e6b-a64928f46694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491041689783689"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x, y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "88678b01-1301-47b5-8fc7-2e596afdf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureSelector(ABC):\n",
    "    def __init__(self, n_folds=5):\n",
    "        self.n_folds = n_folds\n",
    "        self.importances = None\n",
    "\n",
    "    def fit(self, x, y, **importances_kwargs):\n",
    "        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True)  # можно число фолдов и прочие параметры\n",
    "\n",
    "        self.importances = pd.DataFrame({'feature': np.arange(x.shape[1])})\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(x, y)):\n",
    "            x_train, y_train = x[train_index], y[train_index]\n",
    "            x_val, y_val = x[val_index], y[val_index]\n",
    "\n",
    "            model = LGBMClassifier(max_depth=5, n_estimators=500, learning_rate=0.05, verbose=-100)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            imp = self._get_importances_from_model(model, x_val, y_val, **importances_kwargs)\n",
    "\n",
    "            self.importances[f'importance_{i}'] = imp\n",
    "\n",
    "    def get_selected_features(self, threshold):\n",
    "        assert self.importances is not None, 'Сначала нужно обучить, вызвав метод fit'\n",
    "\n",
    "        # сделаем отдельно для 0 итерации\n",
    "        imps = self.importances.loc[:, ['feature', 'importance_0']].sort_values('importance_0', ascending=False)  # выберем важности признаков с 0 итерации\n",
    "        imps['importance_0'] /= imps['importance_0'].sum()\n",
    "        imps['cumsum'] = imps['importance_0'].cumsum()  # так как мы их отнормировали, может посчитать кумулятивную сумму\n",
    "        features = imps.loc[imps['cumsum'] <= threshold, 'feature'].tolist()  # возьмем только те признаки, которые по кумулятивной сумме удовлетворяют\n",
    "        \n",
    "        best_features = set(features)  # сделаем множество\n",
    "        for i in range(self.n_folds):\n",
    "            imps = self.importances.loc[:, ['feature', f'importance_{i}']].sort_values(f'importance_{i}', ascending=False)\n",
    "            imps[f'importance_{i}'] /= imps[f'importance_{i}'].sum()\n",
    "            imps['cumsum'] = imps[f'importance_{i}'].cumsum()\n",
    "            features = imps.loc[imps['cumsum'] <= threshold, 'feature'].tolist()\n",
    "\n",
    "            best_features &= set(features)  # смотрим на пересечения множеств на разных итерациях кросс-валидации\n",
    "\n",
    "        return list(best_features)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _get_importances_from_model(self, model, x, y, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d01b768a-e47b-4d1a-bcbc-2e9a3ae58641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор признаков с использованием встроеного feature_importance\n",
    "class LGMFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, importance_type='split'):\n",
    "        return model.booster_.feature_importance(importance_type=importance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6ea39737-a6a5-4d18-bc56-879d50fdf2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26.1 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgm_fs = LGMFeatureSelection()\n",
    "lgm_fs.fit(x, y, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de006691-65fa-49bc-bf0d-9a50386d2ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>494</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>529</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>283</td>\n",
       "      <td>265</td>\n",
       "      <td>292</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>274</td>\n",
       "      <td>325</td>\n",
       "      <td>259</td>\n",
       "      <td>317</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>458</td>\n",
       "      <td>481</td>\n",
       "      <td>466</td>\n",
       "      <td>436</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>399</td>\n",
       "      <td>413</td>\n",
       "      <td>382</td>\n",
       "      <td>420</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>318</td>\n",
       "      <td>369</td>\n",
       "      <td>324</td>\n",
       "      <td>370</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>342</td>\n",
       "      <td>375</td>\n",
       "      <td>328</td>\n",
       "      <td>343</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>336</td>\n",
       "      <td>334</td>\n",
       "      <td>318</td>\n",
       "      <td>337</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>398</td>\n",
       "      <td>380</td>\n",
       "      <td>340</td>\n",
       "      <td>376</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>322</td>\n",
       "      <td>324</td>\n",
       "      <td>309</td>\n",
       "      <td>333</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>331</td>\n",
       "      <td>351</td>\n",
       "      <td>321</td>\n",
       "      <td>328</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>334</td>\n",
       "      <td>387</td>\n",
       "      <td>337</td>\n",
       "      <td>350</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>342</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>338</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>388</td>\n",
       "      <td>417</td>\n",
       "      <td>390</td>\n",
       "      <td>432</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>218</td>\n",
       "      <td>288</td>\n",
       "      <td>260</td>\n",
       "      <td>299</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>276</td>\n",
       "      <td>304</td>\n",
       "      <td>315</td>\n",
       "      <td>310</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>202</td>\n",
       "      <td>270</td>\n",
       "      <td>213</td>\n",
       "      <td>221</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>224</td>\n",
       "      <td>253</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>272</td>\n",
       "      <td>284</td>\n",
       "      <td>320</td>\n",
       "      <td>291</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>141</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0           494           481           504           529   \n",
       "1         1           251           283           265           292   \n",
       "2         2           274           325           259           317   \n",
       "3         3           458           481           466           436   \n",
       "4         4           399           413           382           420   \n",
       "5         5           318           369           324           370   \n",
       "6         6           342           375           328           343   \n",
       "7         7           336           334           318           337   \n",
       "8         8           398           380           340           376   \n",
       "9         9           322           324           309           333   \n",
       "10       10           331           351           321           328   \n",
       "11       11           334           387           337           350   \n",
       "12       12           342           269           269           338   \n",
       "13       13           388           417           390           432   \n",
       "14       14           218           288           260           299   \n",
       "15       15           276           304           315           310   \n",
       "16       16           202           270           213           221   \n",
       "17       17           224           253           214           215   \n",
       "18       18           272           284           320           291   \n",
       "19       19            81           127           127           141   \n",
       "\n",
       "    importance_4  \n",
       "0            483  \n",
       "1            274  \n",
       "2            296  \n",
       "3            548  \n",
       "4            415  \n",
       "5            295  \n",
       "6            312  \n",
       "7            333  \n",
       "8            364  \n",
       "9            302  \n",
       "10           299  \n",
       "11           348  \n",
       "12           301  \n",
       "13           415  \n",
       "14           259  \n",
       "15           270  \n",
       "16           201  \n",
       "17           185  \n",
       "18           235  \n",
       "19           152  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2449fe0-b092-4f41-9825-631bf2e26c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs = lgm_fs.get_selected_features(threshold=0.7)\n",
    "len(best_features_lgm_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "91d8f0c2-ce91-4c0f-b006-46a92ac88dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs  # видно, что идут по порядку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d29535fe-3a53-4e98-8115-c81b16ecbf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609643760995761"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_lgm_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5b6c2ad2-f4cc-442b-a9ff-b9179fc05ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем тоже самое, но с помощью shap values\n",
    "class ShapFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, feature_perturbation='tree_path_dependent'):\n",
    "        explainer = shap.TreeExplainer(model, feature_perturbation=feature_perturbation)\n",
    "        shap_values = explainer.shap_values(x)\n",
    "\n",
    "        if isinstance(shap_values, list):\n",
    "            importances = np.abs(shap_values[1]).mean(0)\n",
    "        else:\n",
    "            importances = np.abs(shap_values).mean(0)\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53241cd3-5d92-4b39-a8c4-5bc0a9b43f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 58.7 s\n",
      "Wall time: 8.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shap_fs = ShapFeatureSelection()\n",
    "shap_fs.fit(x, y, feature_perturbation='tree_path_dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0dd28bdf-6f84-4874-aad4-0b8f59f11606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.250060</td>\n",
       "      <td>0.247857</td>\n",
       "      <td>0.266522</td>\n",
       "      <td>0.240047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.098704</td>\n",
       "      <td>0.085731</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.077808</td>\n",
       "      <td>0.096485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.276469</td>\n",
       "      <td>0.255460</td>\n",
       "      <td>0.232303</td>\n",
       "      <td>0.268888</td>\n",
       "      <td>0.246585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.435923</td>\n",
       "      <td>0.398038</td>\n",
       "      <td>0.441741</td>\n",
       "      <td>0.407917</td>\n",
       "      <td>0.435214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.552919</td>\n",
       "      <td>0.582388</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>0.543746</td>\n",
       "      <td>0.574057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.083296</td>\n",
       "      <td>0.091279</td>\n",
       "      <td>0.070517</td>\n",
       "      <td>0.075708</td>\n",
       "      <td>0.081022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.104519</td>\n",
       "      <td>0.100954</td>\n",
       "      <td>0.098028</td>\n",
       "      <td>0.104270</td>\n",
       "      <td>0.111093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.786311</td>\n",
       "      <td>0.724123</td>\n",
       "      <td>0.734011</td>\n",
       "      <td>0.720951</td>\n",
       "      <td>0.710266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.164116</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.171061</td>\n",
       "      <td>0.150240</td>\n",
       "      <td>0.162141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.202259</td>\n",
       "      <td>0.208244</td>\n",
       "      <td>0.234636</td>\n",
       "      <td>0.203320</td>\n",
       "      <td>0.213477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.548664</td>\n",
       "      <td>0.597530</td>\n",
       "      <td>0.563737</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.590980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.229489</td>\n",
       "      <td>0.237884</td>\n",
       "      <td>0.239424</td>\n",
       "      <td>0.237155</td>\n",
       "      <td>0.243899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>0.118848</td>\n",
       "      <td>0.107464</td>\n",
       "      <td>0.107262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.510972</td>\n",
       "      <td>0.520636</td>\n",
       "      <td>0.446374</td>\n",
       "      <td>0.508315</td>\n",
       "      <td>0.470744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.093479</td>\n",
       "      <td>0.096206</td>\n",
       "      <td>0.097483</td>\n",
       "      <td>0.092589</td>\n",
       "      <td>0.084372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.238127</td>\n",
       "      <td>0.248439</td>\n",
       "      <td>0.238149</td>\n",
       "      <td>0.225404</td>\n",
       "      <td>0.240829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.134188</td>\n",
       "      <td>0.125965</td>\n",
       "      <td>0.134872</td>\n",
       "      <td>0.119780</td>\n",
       "      <td>0.131228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.101863</td>\n",
       "      <td>0.100717</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>0.103350</td>\n",
       "      <td>0.105585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.226182</td>\n",
       "      <td>0.232253</td>\n",
       "      <td>0.214644</td>\n",
       "      <td>0.206655</td>\n",
       "      <td>0.216434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.069368</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.052119</td>\n",
       "      <td>0.040187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0      0.245900      0.250060      0.247857      0.266522   \n",
       "1         1      0.098704      0.085731      0.086442      0.077808   \n",
       "2         2      0.276469      0.255460      0.232303      0.268888   \n",
       "3         3      0.435923      0.398038      0.441741      0.407917   \n",
       "4         4      0.552919      0.582388      0.567416      0.543746   \n",
       "5         5      0.083296      0.091279      0.070517      0.075708   \n",
       "6         6      0.104519      0.100954      0.098028      0.104270   \n",
       "7         7      0.786311      0.724123      0.734011      0.720951   \n",
       "8         8      0.164116      0.184706      0.171061      0.150240   \n",
       "9         9      0.202259      0.208244      0.234636      0.203320   \n",
       "10       10      0.548664      0.597530      0.563737      0.589744   \n",
       "11       11      0.229489      0.237884      0.239424      0.237155   \n",
       "12       12      0.113727      0.112911      0.118848      0.107464   \n",
       "13       13      0.510972      0.520636      0.446374      0.508315   \n",
       "14       14      0.093479      0.096206      0.097483      0.092589   \n",
       "15       15      0.238127      0.248439      0.238149      0.225404   \n",
       "16       16      0.134188      0.125965      0.134872      0.119780   \n",
       "17       17      0.101863      0.100717      0.090456      0.103350   \n",
       "18       18      0.226182      0.232253      0.214644      0.206655   \n",
       "19       19      0.069368      0.035215      0.034916      0.052119   \n",
       "\n",
       "    importance_4  \n",
       "0       0.240047  \n",
       "1       0.096485  \n",
       "2       0.246585  \n",
       "3       0.435214  \n",
       "4       0.574057  \n",
       "5       0.081022  \n",
       "6       0.111093  \n",
       "7       0.710266  \n",
       "8       0.162141  \n",
       "9       0.213477  \n",
       "10      0.590980  \n",
       "11      0.243899  \n",
       "12      0.107262  \n",
       "13      0.470744  \n",
       "14      0.084372  \n",
       "15      0.240829  \n",
       "16      0.131228  \n",
       "17      0.105585  \n",
       "18      0.216434  \n",
       "19      0.040187  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b6753630-f72b-4129-a1e5-9b5e985dd7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_shap_fs = shap_fs.get_selected_features(threshold=0.85)\n",
    "len(best_features_shap_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "07c6581c-9cd6-4a87-af58-287553de47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589849753321753"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_shap_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4b11cb11-fa8f-45b3-a4df-25896887a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# самый интуитивно понятный метод, но самый долгий - permutation importance\n",
    "class PIFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, **permutation_kwargs):\n",
    "        importances = np.abs(permutation_importance(model, x, y, **permutation_kwargs)['importances_mean'])\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ff965a9f-4faf-418f-ae2f-93628861da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 21s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pi_fs = PIFeatureSelection()\n",
    "pi_fs.fit(x, y, scoring='roc_auc', n_jobs=-1, n_repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66ba9558-7501-4b8d-871f-a8be0eb69b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>0.019858</td>\n",
       "      <td>0.026744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013286</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>0.013163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>0.036937</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.033870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.050503</td>\n",
       "      <td>0.048746</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.048314</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.006055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.050586</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.055311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.013104</td>\n",
       "      <td>0.012576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.014616</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>0.009947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.051569</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.041123</td>\n",
       "      <td>0.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.015670</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.016854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.007861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.028095</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>0.032798</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.042926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.006322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.010402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.013809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0      0.016977      0.023224      0.021263      0.019858   \n",
       "1         1      0.005612      0.005995      0.007382      0.005180   \n",
       "2         2      0.013286      0.010998      0.012470      0.010906   \n",
       "3         3      0.037278      0.034350      0.036937      0.036076   \n",
       "4         4      0.050503      0.048746      0.046275      0.048314   \n",
       "5         5      0.007538      0.006291      0.007801      0.006257   \n",
       "6         6      0.006517      0.006845      0.009251      0.007541   \n",
       "7         7      0.065181      0.050586      0.052449      0.051802   \n",
       "8         8      0.013044      0.015069      0.013926      0.013104   \n",
       "9         9      0.013535      0.014616      0.013846      0.011580   \n",
       "10       10      0.051569      0.044671      0.046835      0.041123   \n",
       "11       11      0.015670      0.014982      0.020648      0.016562   \n",
       "12       12      0.011185      0.009804      0.008103      0.007377   \n",
       "13       13      0.028095      0.029563      0.032798      0.031153   \n",
       "14       14      0.004727      0.006051      0.005872      0.005032   \n",
       "15       15      0.010520      0.010051      0.011433      0.012008   \n",
       "16       16      0.003851      0.003155      0.002589      0.004884   \n",
       "17       17      0.004231      0.003676      0.003152      0.004004   \n",
       "18       18      0.013853      0.012927      0.014022      0.014689   \n",
       "19       19      0.001894      0.001575      0.001263      0.001050   \n",
       "\n",
       "    importance_4  \n",
       "0       0.026744  \n",
       "1       0.007730  \n",
       "2       0.013163  \n",
       "3       0.033870  \n",
       "4       0.047768  \n",
       "5       0.005641  \n",
       "6       0.006055  \n",
       "7       0.055311  \n",
       "8       0.012576  \n",
       "9       0.009947  \n",
       "10      0.041549  \n",
       "11      0.016854  \n",
       "12      0.007861  \n",
       "13      0.042926  \n",
       "14      0.006322  \n",
       "15      0.010402  \n",
       "16      0.004110  \n",
       "17      0.004136  \n",
       "18      0.013809  \n",
       "19      0.001430  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f0caa64a-2fe7-4231-908a-a761cffc36a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_pi_fs = pi_fs.get_selected_features(threshold=0.99)\n",
    "len(best_features_pi_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32428acc-8308-433c-b1f9-c425a7a75329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 40]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_pi_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e645f68a-e3f0-4a7b-b57d-d789fb2aad9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604289764385765"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_pi_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ad44e-dbab-4b4e-9747-cc9580b1c50c",
   "metadata": {},
   "source": [
    "# Жадные методы отбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "090d6e82-9a20-4118-8d8c-748312a449cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialForwardFeatureSelection:\n",
    "    def __init__(self, model, n_folds, k, stratified=True, scoring='roc_auc'):\n",
    "        self.model = model\n",
    "        self.n_folds = n_folds\n",
    "        self.k = k\n",
    "        self.stratified = True\n",
    "        self.scoring = scoring\n",
    "\n",
    "    def _find_feature_to_add(self, x, y, cur_subset, set_to_choose_from):\n",
    "        best_score = float('-inf')\n",
    "        best_feature = None\n",
    "\n",
    "        print('*'*30)\n",
    "        print('Looking for feature to ADD...')\n",
    "\n",
    "        for feature in set_to_choose_from:\n",
    "            cur_subset_copy = cur_subset.copy()\n",
    "            cur_subset_copy += [feature]\n",
    "\n",
    "            subset_x = x[:, cur_subset_copy]\n",
    "            if self.stratified:\n",
    "                cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "            else:\n",
    "                cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "            score = cross_val_score(estimator=self.model, X=subset_x, y=y, cv=cv, scoring=self.scoring).mean()\n",
    "            if score > best_score:\n",
    "                best_feature = feature\n",
    "                best_score = score\n",
    "                \n",
    "        print(f'Best score = {best_score:.4f}')\n",
    "        return best_feature\n",
    "\n",
    "    def _find_feature_to_delete(self, x, y, cur_subset):\n",
    "        if self.stratified:\n",
    "            cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "        else:\n",
    "            cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "        best_score = cross_val_score(estimator=self.model, X=x[:, cur_subset], y=y, cv=cv, scoring=self.scoring).mean()\n",
    "        worst_feature = None\n",
    "\n",
    "        print('='*30)\n",
    "        print('Looking for feature to DELETE...')\n",
    "        print(f'Best score = {best_score:.4f}')\n",
    "\n",
    "        for feature in cur_subset:\n",
    "            cur_subset_copy = cur_subset.copy()\n",
    "            del cur_subset_copy[cur_subset_copy.index(feature)]\n",
    "\n",
    "            subset_x = x[:, cur_subset_copy]\n",
    "            if self.stratified:\n",
    "                cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "            else:\n",
    "                cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "            score = cross_val_score(estimator=self.model, X=subset_x, y=y, cv=cv, scoring=self.scoring).mean()\n",
    "            if score > best_score:\n",
    "                worst_feature = feature\n",
    "                best_score = score\n",
    "        return worst_feature\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        best_features = []\n",
    "        set_to_choose_from = list(range(x.shape[1]))\n",
    "\n",
    "        best_feature = self._find_feature_to_add(x=x, y=y, cur_subset=best_features, set_to_choose_from=set_to_choose_from)\n",
    "        best_features += [best_feature]\n",
    "        print(f'Added feature {best_feature}, current subset = {best_features}')\n",
    "        del set_to_choose_from[set_to_choose_from.index(best_feature)]\n",
    "\n",
    "        while len(best_features) < self.k:\n",
    "            best_feature = self._find_feature_to_add(x=x, y=y, cur_subset=best_features, set_to_choose_from=set_to_choose_from)\n",
    "            best_features += [best_feature]\n",
    "            print(f'Added feature {best_feature}, current subset = {best_features}')\n",
    "            del set_to_choose_from[set_to_choose_from.index(best_feature)]\n",
    "\n",
    "            if len(best_features) > 2:\n",
    "                worst_feature = self._find_feature_to_delete(x=x, y=y, cur_subset=best_features)\n",
    "                if worst_feature == best_feature:\n",
    "                    break\n",
    "\n",
    "                if worst_feature is not None:\n",
    "                    del best_features[best_features.index(worst_feature)]\n",
    "                    print(f'Deleted feature {worst_feature}, current subset = {best_features}')\n",
    "                    set_to_choose_from += [worst_feature]\n",
    "\n",
    "                    while len(best_features) > 2:\n",
    "                        worst_feature = self._find_feature_to_delete(x=x, y=y, cur_subset=best_features)\n",
    "                        if worst_feature is None:\n",
    "                            break\n",
    "                        del best_features[best_features.index(worst_feature)]\n",
    "                        print(f'Deleted feature {worst_feature}, current subset = {best_features}')\n",
    "                        set_to_choose_from += [worst_feature]\n",
    "        return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "458ba976-ac38-4b6b-b42f-9098aeca7332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.6613\n",
      "Added feature 7, current subset = [7]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7168\n",
      "Added feature 10, current subset = [7, 10]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7557\n",
      "Added feature 22, current subset = [7, 10, 22]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.7526\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7961\n",
      "Added feature 24, current subset = [7, 10, 22, 24]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.7964\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8342\n",
      "Added feature 13, current subset = [7, 10, 22, 24, 13]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.8325\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8685\n",
      "Added feature 3, current subset = [7, 10, 22, 24, 13, 3]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.8677\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8937\n",
      "Added feature 18, current subset = [7, 10, 22, 24, 13, 3, 18]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.8926\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9090\n",
      "Added feature 11, current subset = [7, 10, 22, 24, 13, 3, 18, 11]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9100\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9234\n",
      "Added feature 0, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9231\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9313\n",
      "Added feature 5, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9327\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9392\n",
      "Added feature 1, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9397\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9452\n",
      "Added feature 8, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1, 8]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9452\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9545\n",
      "Added feature 9, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1, 8, 9]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9527\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9578\n",
      "Added feature 14, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9565\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9613\n",
      "Added feature 12, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9618\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9643\n",
      "Added feature 6, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9654\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9657\n",
      "Added feature 2, current subset = [7, 10, 22, 24, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9639\n",
      "Deleted feature 24, current subset = [7, 10, 22, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9655\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9663\n",
      "Added feature 20, current subset = [7, 10, 22, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9658\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9657\n",
      "Added feature 17, current subset = [7, 10, 22, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20, 17]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9659\n",
      "Deleted feature 10, current subset = [7, 22, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20, 17]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9649\n",
      "Deleted feature 17, current subset = [7, 22, 13, 3, 18, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9651\n",
      "Deleted feature 18, current subset = [7, 22, 13, 3, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9654\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9654\n",
      "Added feature 18, current subset = [7, 22, 13, 3, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20, 18]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9649\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9663\n",
      "Added feature 16, current subset = [7, 22, 13, 3, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20, 18, 16]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9648\n",
      "Deleted feature 7, current subset = [22, 13, 3, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20, 18, 16]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9644\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9656\n",
      "Added feature 19, current subset = [22, 13, 3, 11, 0, 5, 1, 8, 9, 14, 12, 6, 2, 20, 18, 16, 19]\n",
      "==============================\n",
      "Looking for feature to DELETE...\n",
      "Best score = 0.9644\n",
      "CPU times: total: 4h 17min 48s\n",
      "Wall time: 42min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# самый долгий\n",
    "\n",
    "%%time\n",
    "seq_fs = SequentialForwardFeatureSelection(\n",
    "    model=LGBMClassifier(max_depth=5, n_estimators=500, learning_rate=0.05, verbose=-100),\n",
    "    n_folds=5,\n",
    "    k=50)\n",
    "best_features_seq_fs = seq_fs.fit(x, y)\n",
    "len(best_features_seq_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ed9ba2fe-5506-465a-b94e-d0f76c056213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579893735297735"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_seq_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "050d05da-d997-4046-a874-8d4feff051c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19},\n",
       " {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19},\n",
       " {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 40})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(best_features_lgm_fs) & set(best_features_shap_fs), set(best_features_lgm_fs) & set(best_features_pi_fs), set(best_features_pi_fs) & set(best_features_shap_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e4b81-090e-4e20-b9c7-8353f74938b4",
   "metadata": {},
   "source": [
    "# Но что если признаков очень много?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fddfadb1-f207-4c98-854d-6da2b1c297f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=100000, n_features=1000, n_informative=35, n_redundant=7, n_repeated=8, n_clusters_per_class=4, shift=0.8, scale=3.0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c05a2460-10f2-47f1-8a7c-e587736f6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18min 55s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgm_fs = LGMFeatureSelection()\n",
    "lgm_fs.fit(x, y, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0a51dedf-b861-4909-bcb4-8437841eb45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699239396992393"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x, y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d0068d78-e0c6-4fdd-895a-c36014a29863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>358</td>\n",
       "      <td>349</td>\n",
       "      <td>396</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>378</td>\n",
       "      <td>361</td>\n",
       "      <td>366</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>246</td>\n",
       "      <td>245</td>\n",
       "      <td>255</td>\n",
       "      <td>260</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>306</td>\n",
       "      <td>299</td>\n",
       "      <td>305</td>\n",
       "      <td>293</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>314</td>\n",
       "      <td>294</td>\n",
       "      <td>298</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>401</td>\n",
       "      <td>398</td>\n",
       "      <td>375</td>\n",
       "      <td>376</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>269</td>\n",
       "      <td>259</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>319</td>\n",
       "      <td>326</td>\n",
       "      <td>333</td>\n",
       "      <td>313</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>257</td>\n",
       "      <td>269</td>\n",
       "      <td>279</td>\n",
       "      <td>249</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>276</td>\n",
       "      <td>257</td>\n",
       "      <td>250</td>\n",
       "      <td>261</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>283</td>\n",
       "      <td>295</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>327</td>\n",
       "      <td>335</td>\n",
       "      <td>371</td>\n",
       "      <td>329</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>433</td>\n",
       "      <td>408</td>\n",
       "      <td>450</td>\n",
       "      <td>428</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>256</td>\n",
       "      <td>254</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>258</td>\n",
       "      <td>281</td>\n",
       "      <td>272</td>\n",
       "      <td>276</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>261</td>\n",
       "      <td>267</td>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>366</td>\n",
       "      <td>332</td>\n",
       "      <td>357</td>\n",
       "      <td>348</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>241</td>\n",
       "      <td>209</td>\n",
       "      <td>207</td>\n",
       "      <td>240</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>296</td>\n",
       "      <td>312</td>\n",
       "      <td>292</td>\n",
       "      <td>293</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>205</td>\n",
       "      <td>230</td>\n",
       "      <td>228</td>\n",
       "      <td>215</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0           360           358           349           396   \n",
       "1         1           370           378           361           366   \n",
       "2         2           246           245           255           260   \n",
       "3         3           306           299           305           293   \n",
       "4         4           283           314           294           298   \n",
       "5         5           401           398           375           376   \n",
       "6         6           269           259           266           263   \n",
       "7         7           319           326           333           313   \n",
       "8         8           257           269           279           249   \n",
       "9         9           276           257           250           261   \n",
       "10       10           283           295           285           285   \n",
       "11       11           327           335           371           329   \n",
       "12       12           433           408           450           428   \n",
       "13       13           263           247           256           254   \n",
       "14       14           258           281           272           276   \n",
       "15       15           261           267           277           278   \n",
       "16       16           366           332           357           348   \n",
       "17       17           241           209           207           240   \n",
       "18       18           296           312           292           293   \n",
       "19       19           205           230           228           215   \n",
       "\n",
       "    importance_4  \n",
       "0            354  \n",
       "1            367  \n",
       "2            288  \n",
       "3            313  \n",
       "4            302  \n",
       "5            396  \n",
       "6            251  \n",
       "7            352  \n",
       "8            286  \n",
       "9            273  \n",
       "10           264  \n",
       "11           351  \n",
       "12           419  \n",
       "13           226  \n",
       "14           251  \n",
       "15           264  \n",
       "16           324  \n",
       "17           216  \n",
       "18           267  \n",
       "19           216  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e10167c0-e9d0-407d-a379-c8348f9a3d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs = lgm_fs.get_selected_features(threshold=0.85)\n",
    "len(best_features_lgm_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7f6a87e9-74ff-425b-b28d-ed40080b6c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699724176997242"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_lgm_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "99286aad-15fe-4178-9eb7-0ea996abd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# видимо имеет смысл осторожнее выбирать отсечку, либо объединять результаты нескольких методов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hardml",
   "language": "python",
   "name": "hardml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
