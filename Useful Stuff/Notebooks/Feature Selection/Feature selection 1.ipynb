{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc430f5a-a85f-46f3-b59c-c0899b271c96",
   "metadata": {},
   "source": [
    "# Ноутбук по отбору признаков №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc81f7-8fa8-497e-9b70-6f6f1dc24abe",
   "metadata": {},
   "source": [
    "[Пример ноутбука в котором идет речь про отбор признаков](https://github.com/RomanSafronenkov/mlcourse.ai/blob/main/jupyter_russian/topic06_features/topic6_feature_engineering_feature_selection_russian.ipynb)\n",
    "\n",
    "[Sequential Feature Selection с объяснениями](https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/#sequentialfeatureselector)\n",
    "\n",
    "[О том, почему плох встроенный в RandomForest feature_importance](https://explained.ai/rf-importance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54ca4cc-a2d7-4fc3-bf24-6bc3f1a9b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfcbe25-5b18-487a-a32d-988a6ac738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим искусственный датасет, в котором будут информативные признаки, их дубликаты, их комбинации и шумовые признаки\n",
    "x, y = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=100,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    weights=(0.8, 0.2),\n",
    "    n_classes=2,\n",
    "    n_repeated=5,\n",
    "    n_clusters_per_class=4,\n",
    "    shift=0.8,\n",
    "    scale=3.0,\n",
    "    shuffle=False)\n",
    "\n",
    "# если не ставить параметр shuffle в True, то сначала будут идти информативные признаки, потом комбинации и потом повторы, после них - мусор\n",
    "# так удобнее оценить как это все работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bfad0a-c7f1-44b9-9e6b-a64928f46694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 140 ms, total: 12.5 s\n",
      "Wall time: 6.33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9565867283810144"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# замерим метрику на кросс валидации\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x, y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88678b01-1301-47b5-8fc7-2e596afdf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureSelector(ABC):\n",
    "    def __init__(self, n_folds=5):\n",
    "        self.n_folds = n_folds\n",
    "        self.importances = None\n",
    "\n",
    "    def fit(self, x, y, **importances_kwargs):\n",
    "        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True)  # можно число фолдов и прочие параметры\n",
    "\n",
    "        self.importances = pd.DataFrame({'feature': np.arange(x.shape[1])})\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(x, y)):\n",
    "            x_train, y_train = x[train_index], y[train_index]\n",
    "            x_val, y_val = x[val_index], y[val_index]\n",
    "\n",
    "            model = LGBMClassifier(max_depth=5, n_estimators=500, learning_rate=0.05, verbose=-100)\n",
    "            model.fit(x_train, y_train, eval_set=(x_val, y_val))\n",
    "\n",
    "            imp = self._get_importances_from_model(model, x_val, y_val, **importances_kwargs)\n",
    "\n",
    "            self.importances[f'importance_{i}'] = imp\n",
    "\n",
    "    def get_selected_features(self, threshold):\n",
    "        assert self.importances is not None, 'Сначала нужно обучить, вызвав метод fit'\n",
    "\n",
    "        # сделаем отдельно для 0 итерации\n",
    "        imps = self.importances.loc[:, ['feature', 'importance_0']].sort_values('importance_0', ascending=False)  # выберем важности признаков с 0 итерации\n",
    "        imps['importance_0'] /= imps['importance_0'].sum()\n",
    "        imps['cumsum'] = imps['importance_0'].cumsum()  # так как мы их отнормировали, может посчитать кумулятивную сумму\n",
    "        features = imps.loc[imps['cumsum'] <= threshold, 'feature'].tolist()  # возьмем только те признаки, которые по кумулятивной сумме удовлетворяют\n",
    "        \n",
    "        best_features = set(features)  # сделаем множество\n",
    "        for i in range(1, self.n_folds):\n",
    "            imps = self.importances.loc[:, ['feature', f'importance_{i}']].sort_values(f'importance_{i}', ascending=False)\n",
    "            imps[f'importance_{i}'] /= imps[f'importance_{i}'].sum()\n",
    "            imps['cumsum'] = imps[f'importance_{i}'].cumsum()\n",
    "            features = imps.loc[imps['cumsum'] <= threshold, 'feature'].tolist()\n",
    "\n",
    "            best_features &= set(features)  # смотрим на пересечения множеств на разных итерациях кросс-валидации\n",
    "\n",
    "        return list(best_features)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _get_importances_from_model(self, model, x, y, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01b768a-e47b-4d1a-bcbc-2e9a3ae58641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор признаков с использованием встроеного feature_importance\n",
    "class LGMFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, importance_type='split'):\n",
    "        return model.booster_.feature_importance(importance_type=importance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea39737-a6a5-4d18-bc56-879d50fdf2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 203 ms, total: 27.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgm_fs = LGMFeatureSelection()\n",
    "lgm_fs.fit(x, y, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de006691-65fa-49bc-bf0d-9a50386d2ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>281</td>\n",
       "      <td>310</td>\n",
       "      <td>291</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>298</td>\n",
       "      <td>342</td>\n",
       "      <td>363</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>382</td>\n",
       "      <td>386</td>\n",
       "      <td>438</td>\n",
       "      <td>431</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>346</td>\n",
       "      <td>330</td>\n",
       "      <td>345</td>\n",
       "      <td>322</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>427</td>\n",
       "      <td>403</td>\n",
       "      <td>451</td>\n",
       "      <td>401</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>388</td>\n",
       "      <td>362</td>\n",
       "      <td>389</td>\n",
       "      <td>384</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>327</td>\n",
       "      <td>302</td>\n",
       "      <td>340</td>\n",
       "      <td>326</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>381</td>\n",
       "      <td>373</td>\n",
       "      <td>372</td>\n",
       "      <td>379</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>410</td>\n",
       "      <td>415</td>\n",
       "      <td>411</td>\n",
       "      <td>377</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>366</td>\n",
       "      <td>308</td>\n",
       "      <td>362</td>\n",
       "      <td>378</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>252</td>\n",
       "      <td>257</td>\n",
       "      <td>285</td>\n",
       "      <td>252</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>305</td>\n",
       "      <td>278</td>\n",
       "      <td>285</td>\n",
       "      <td>270</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>445</td>\n",
       "      <td>392</td>\n",
       "      <td>470</td>\n",
       "      <td>402</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>358</td>\n",
       "      <td>321</td>\n",
       "      <td>345</td>\n",
       "      <td>333</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>328</td>\n",
       "      <td>243</td>\n",
       "      <td>298</td>\n",
       "      <td>293</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>270</td>\n",
       "      <td>231</td>\n",
       "      <td>265</td>\n",
       "      <td>247</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>272</td>\n",
       "      <td>266</td>\n",
       "      <td>258</td>\n",
       "      <td>239</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>251</td>\n",
       "      <td>221</td>\n",
       "      <td>263</td>\n",
       "      <td>308</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>200</td>\n",
       "      <td>159</td>\n",
       "      <td>217</td>\n",
       "      <td>191</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>215</td>\n",
       "      <td>199</td>\n",
       "      <td>205</td>\n",
       "      <td>210</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0           283           281           310           291   \n",
       "1         1           330           298           342           363   \n",
       "2         2           382           386           438           431   \n",
       "3         3           346           330           345           322   \n",
       "4         4           427           403           451           401   \n",
       "5         5           388           362           389           384   \n",
       "6         6           327           302           340           326   \n",
       "7         7           381           373           372           379   \n",
       "8         8           410           415           411           377   \n",
       "9         9           366           308           362           378   \n",
       "10       10           252           257           285           252   \n",
       "11       11           305           278           285           270   \n",
       "12       12           445           392           470           402   \n",
       "13       13           358           321           345           333   \n",
       "14       14           328           243           298           293   \n",
       "15       15           270           231           265           247   \n",
       "16       16           272           266           258           239   \n",
       "17       17           251           221           263           308   \n",
       "18       18           200           159           217           191   \n",
       "19       19           215           199           205           210   \n",
       "\n",
       "    importance_4  \n",
       "0            277  \n",
       "1            305  \n",
       "2            383  \n",
       "3            364  \n",
       "4            397  \n",
       "5            373  \n",
       "6            328  \n",
       "7            419  \n",
       "8            383  \n",
       "9            369  \n",
       "10           208  \n",
       "11           326  \n",
       "12           427  \n",
       "13           331  \n",
       "14           309  \n",
       "15           245  \n",
       "16           229  \n",
       "17           280  \n",
       "18           216  \n",
       "19           225  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2449fe0-b092-4f41-9825-631bf2e26c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs = lgm_fs.get_selected_features(threshold=0.5)\n",
    "len(best_features_lgm_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d8f0c2-ce91-4c0f-b006-46a92ac88dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs  # видно, что идут по порядку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29535fe-3a53-4e98-8115-c81b16ecbf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598983935857557"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_lgm_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6c2ad2-f4cc-442b-a9ff-b9179fc05ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем тоже самое, но с помощью shap values\n",
    "class ShapFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, \n",
    "                                    is_multiclass=False, feature_perturbation='tree_path_dependent'):\n",
    "        explainer = shap.TreeExplainer(model, feature_perturbation=feature_perturbation)\n",
    "        shap_values = explainer.shap_values(x)  # for each class, for each instance\n",
    "\n",
    "        if is_multiclass:\n",
    "            if isinstance(shap_values, list):\n",
    "                # if shap_values in list of n_classes np.arrays of shape [n_samples, n_features]\n",
    "                importances = []\n",
    "                for cls_ in shap_values:\n",
    "                    cls_value = np.abs(cls_).mean(axis=0)\n",
    "                    importances.append(cls_value.reshape(1, -1))\n",
    "                    \n",
    "                importances = np.concatenate(importances).mean(axis=0)\n",
    "            else:\n",
    "                # if shap_values in np.array of shape [n_samples, n_features, n_classes]\n",
    "                importances = np.abs(shap_values).mean(axis=(0, 2))\n",
    "        else:\n",
    "            if isinstance(shap_values, list):\n",
    "                # if shap_values in list of n_classes np.arrays of shape [n_samples, n_features]\n",
    "                importances = np.abs(shap_values[1]).mean(axis=0)\n",
    "            else:\n",
    "                # if shap_values in np.array of shape [n_samples, n_features]\n",
    "                importances = np.abs(shap_values).mean(axis=0)\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53241cd3-5d92-4b39-a8c4-5bc0a9b43f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 220 ms, total: 1min 7s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shap_fs = ShapFeatureSelection()\n",
    "shap_fs.fit(x, y, is_multiclass=False, feature_perturbation='tree_path_dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd28bdf-6f84-4874-aad4-0b8f59f11606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.120331</td>\n",
       "      <td>0.165546</td>\n",
       "      <td>0.158914</td>\n",
       "      <td>0.119959</td>\n",
       "      <td>0.151279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.222161</td>\n",
       "      <td>0.231679</td>\n",
       "      <td>0.242651</td>\n",
       "      <td>0.240228</td>\n",
       "      <td>0.217469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.669277</td>\n",
       "      <td>0.695947</td>\n",
       "      <td>0.707646</td>\n",
       "      <td>0.577635</td>\n",
       "      <td>0.693196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.296354</td>\n",
       "      <td>0.328124</td>\n",
       "      <td>0.328912</td>\n",
       "      <td>0.337846</td>\n",
       "      <td>0.311341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.180501</td>\n",
       "      <td>0.167048</td>\n",
       "      <td>0.191106</td>\n",
       "      <td>0.178394</td>\n",
       "      <td>0.186488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.184131</td>\n",
       "      <td>0.160086</td>\n",
       "      <td>0.216943</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.195159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.387192</td>\n",
       "      <td>0.367869</td>\n",
       "      <td>0.424341</td>\n",
       "      <td>0.386944</td>\n",
       "      <td>0.379377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.408509</td>\n",
       "      <td>0.421378</td>\n",
       "      <td>0.426364</td>\n",
       "      <td>0.445890</td>\n",
       "      <td>0.423986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.469104</td>\n",
       "      <td>0.487378</td>\n",
       "      <td>0.497010</td>\n",
       "      <td>0.458392</td>\n",
       "      <td>0.467936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.290803</td>\n",
       "      <td>0.208366</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.205376</td>\n",
       "      <td>0.270807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.182596</td>\n",
       "      <td>0.219580</td>\n",
       "      <td>0.167171</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.200575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.113682</td>\n",
       "      <td>0.110079</td>\n",
       "      <td>0.111123</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.116773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.242287</td>\n",
       "      <td>0.271608</td>\n",
       "      <td>0.231927</td>\n",
       "      <td>0.249889</td>\n",
       "      <td>0.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.223335</td>\n",
       "      <td>0.194517</td>\n",
       "      <td>0.267489</td>\n",
       "      <td>0.196398</td>\n",
       "      <td>0.226917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.285386</td>\n",
       "      <td>0.199718</td>\n",
       "      <td>0.242868</td>\n",
       "      <td>0.202230</td>\n",
       "      <td>0.210988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.247342</td>\n",
       "      <td>0.264840</td>\n",
       "      <td>0.208306</td>\n",
       "      <td>0.188295</td>\n",
       "      <td>0.242154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.204701</td>\n",
       "      <td>0.227234</td>\n",
       "      <td>0.194544</td>\n",
       "      <td>0.190388</td>\n",
       "      <td>0.225643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.415248</td>\n",
       "      <td>0.422027</td>\n",
       "      <td>0.411517</td>\n",
       "      <td>0.521159</td>\n",
       "      <td>0.441481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>0.095339</td>\n",
       "      <td>0.091940</td>\n",
       "      <td>0.074110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.224178</td>\n",
       "      <td>0.182277</td>\n",
       "      <td>0.174305</td>\n",
       "      <td>0.156588</td>\n",
       "      <td>0.193763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0      0.120331      0.165546      0.158914      0.119959   \n",
       "1         1      0.222161      0.231679      0.242651      0.240228   \n",
       "2         2      0.669277      0.695947      0.707646      0.577635   \n",
       "3         3      0.296354      0.328124      0.328912      0.337846   \n",
       "4         4      0.180501      0.167048      0.191106      0.178394   \n",
       "5         5      0.184131      0.160086      0.216943      0.180900   \n",
       "6         6      0.387192      0.367869      0.424341      0.386944   \n",
       "7         7      0.408509      0.421378      0.426364      0.445890   \n",
       "8         8      0.469104      0.487378      0.497010      0.458392   \n",
       "9         9      0.290803      0.208366      0.263158      0.205376   \n",
       "10       10      0.182596      0.219580      0.167171      0.226700   \n",
       "11       11      0.113682      0.110079      0.111123      0.090316   \n",
       "12       12      0.242287      0.271608      0.231927      0.249889   \n",
       "13       13      0.223335      0.194517      0.267489      0.196398   \n",
       "14       14      0.285386      0.199718      0.242868      0.202230   \n",
       "15       15      0.247342      0.264840      0.208306      0.188295   \n",
       "16       16      0.204701      0.227234      0.194544      0.190388   \n",
       "17       17      0.415248      0.422027      0.411517      0.521159   \n",
       "18       18      0.082090      0.063879      0.095339      0.091940   \n",
       "19       19      0.224178      0.182277      0.174305      0.156588   \n",
       "\n",
       "    importance_4  \n",
       "0       0.151279  \n",
       "1       0.217469  \n",
       "2       0.693196  \n",
       "3       0.311341  \n",
       "4       0.186488  \n",
       "5       0.195159  \n",
       "6       0.379377  \n",
       "7       0.423986  \n",
       "8       0.467936  \n",
       "9       0.270807  \n",
       "10      0.200575  \n",
       "11      0.116773  \n",
       "12      0.254400  \n",
       "13      0.226917  \n",
       "14      0.210988  \n",
       "15      0.242154  \n",
       "16      0.225643  \n",
       "17      0.441481  \n",
       "18      0.074110  \n",
       "19      0.193763  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6753630-f72b-4129-a1e5-9b5e985dd7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_shap_fs = shap_fs.get_selected_features(threshold=0.7)\n",
    "len(best_features_shap_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def42639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_shap_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c6581c-9cd6-4a87-af58-287553de47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573755867341873"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_shap_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b11cb11-fa8f-45b3-a4df-25896887a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# самый интуитивно понятный метод, но самый долгий - permutation importance\n",
    "class PIFeatureSelection(BaseFeatureSelector):\n",
    "    def __init__(self, n_folds=5):\n",
    "        super().__init__(n_folds)\n",
    "\n",
    "    def _get_importances_from_model(self, model, x, y, **permutation_kwargs):\n",
    "        importances = np.abs(permutation_importance(model, x, y, **permutation_kwargs)['importances_mean'])\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff965a9f-4faf-418f-ae2f-93628861da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 584 ms, total: 1min 32s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pi_fs = PIFeatureSelection()\n",
    "pi_fs.fit(x, y, scoring='roc_auc', n_jobs=-1, n_repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ba9558-7501-4b8d-871f-a8be0eb69b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.007356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.065422</td>\n",
       "      <td>0.051706</td>\n",
       "      <td>0.058040</td>\n",
       "      <td>0.064037</td>\n",
       "      <td>0.061156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.027245</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>0.024216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>0.012671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>0.009414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.021520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.031906</td>\n",
       "      <td>0.023593</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>0.033559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.024956</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.023377</td>\n",
       "      <td>0.020393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.014154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.007741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>0.027509</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.017057</td>\n",
       "      <td>0.020801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.008728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.011235</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.010226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.006172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>0.005149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.014869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.002858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.004269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0      0.007658      0.009207      0.008020      0.005870   \n",
       "1         1      0.013441      0.016086      0.016447      0.016244   \n",
       "2         2      0.065422      0.051706      0.058040      0.064037   \n",
       "3         3      0.027245      0.024070      0.025101      0.025620   \n",
       "4         4      0.015680      0.014505      0.018136      0.016353   \n",
       "5         5      0.016307      0.013991      0.009891      0.012967   \n",
       "6         6      0.022708      0.023358      0.023931      0.024563   \n",
       "7         7      0.030663      0.031906      0.023593      0.037504   \n",
       "8         8      0.024956      0.035135      0.030942      0.023377   \n",
       "9         9      0.019669      0.015248      0.013680      0.018604   \n",
       "10       10      0.006375      0.006726      0.010022      0.006963   \n",
       "11       11      0.003765      0.006999      0.006544      0.004381   \n",
       "12       12      0.022585      0.027509      0.020097      0.017057   \n",
       "13       13      0.015190      0.012772      0.010730      0.010766   \n",
       "14       14      0.013483      0.011235      0.012267      0.011329   \n",
       "15       15      0.006674      0.006633      0.004074      0.003552   \n",
       "16       16      0.006163      0.005158      0.006862      0.007602   \n",
       "17       17      0.020437      0.015331      0.021106      0.015433   \n",
       "18       18      0.003654      0.003752      0.004905      0.001888   \n",
       "19       19      0.004822      0.003259      0.006601      0.006636   \n",
       "\n",
       "    importance_4  \n",
       "0       0.007356  \n",
       "1       0.012049  \n",
       "2       0.061156  \n",
       "3       0.024216  \n",
       "4       0.012671  \n",
       "5       0.009414  \n",
       "6       0.021520  \n",
       "7       0.033559  \n",
       "8       0.020393  \n",
       "9       0.014154  \n",
       "10      0.005741  \n",
       "11      0.007741  \n",
       "12      0.020801  \n",
       "13      0.008728  \n",
       "14      0.010226  \n",
       "15      0.006172  \n",
       "16      0.005149  \n",
       "17      0.014869  \n",
       "18      0.002858  \n",
       "19      0.004269  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0caa64a-2fe7-4231-908a-a761cffc36a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_pi_fs = pi_fs.get_selected_features(threshold=0.99)\n",
    "len(best_features_pi_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32428acc-8308-433c-b1f9-c425a7a75329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 48]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_pi_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e645f68a-e3f0-4a7b-b57d-d789fb2aad9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647061050989001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_pi_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ad44e-dbab-4b4e-9747-cc9580b1c50c",
   "metadata": {},
   "source": [
    "# Жадные методы отбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "090d6e82-9a20-4118-8d8c-748312a449cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialForwardFeatureSelection:\n",
    "    def __init__(self, model, n_folds, k, smooth=False, stratified=True, scoring='roc_auc'):\n",
    "        self.model = model\n",
    "        self.n_folds = n_folds\n",
    "        self.k = k\n",
    "        self.stratified = True\n",
    "        self.smooth = smooth\n",
    "        self.scoring = scoring\n",
    "\n",
    "    def _find_feature_to_add(self, x, y, cur_subset, set_to_choose_from):\n",
    "        best_score = float('-inf')\n",
    "        best_feature = None\n",
    "\n",
    "        print('*'*30)\n",
    "        print('Looking for feature to ADD...')\n",
    "\n",
    "        for feature in set_to_choose_from:\n",
    "            cur_subset_copy = cur_subset.copy()\n",
    "            cur_subset_copy += [feature]\n",
    "\n",
    "            subset_x = x[:, cur_subset_copy]\n",
    "            if self.stratified:\n",
    "                cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "            else:\n",
    "                cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "            score = cross_val_score(estimator=self.model, X=subset_x, y=y, cv=cv, scoring=self.scoring).mean()\n",
    "            if score > best_score:\n",
    "                best_feature = feature\n",
    "                best_score = score\n",
    "                \n",
    "        print(f'Best score = {best_score:.4f}')\n",
    "        return best_feature\n",
    "\n",
    "    def _find_feature_to_delete(self, x, y, cur_subset):\n",
    "        if self.stratified:\n",
    "            cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "        else:\n",
    "            cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "        best_score = cross_val_score(estimator=self.model, X=x[:, cur_subset], y=y, cv=cv, scoring=self.scoring).mean()\n",
    "        worst_feature = None\n",
    "\n",
    "        print('='*30)\n",
    "        print('Looking for feature to DELETE...')\n",
    "        print(f'Best score = {best_score:.4f}')\n",
    "\n",
    "        for feature in cur_subset:\n",
    "            cur_subset_copy = cur_subset.copy()\n",
    "            del cur_subset_copy[cur_subset_copy.index(feature)]\n",
    "\n",
    "            subset_x = x[:, cur_subset_copy]\n",
    "            if self.stratified:\n",
    "                cv = StratifiedKFold(n_splits=self.n_folds, shuffle=True)\n",
    "            else:\n",
    "                cv = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "            score = cross_val_score(estimator=self.model, X=subset_x, y=y, cv=cv, scoring=self.scoring).mean()\n",
    "            if score > best_score:\n",
    "                worst_feature = feature\n",
    "                best_score = score\n",
    "        return worst_feature\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        best_features = []\n",
    "        set_to_choose_from = list(range(x.shape[1]))\n",
    "\n",
    "        best_feature = self._find_feature_to_add(x=x, y=y, cur_subset=best_features, set_to_choose_from=set_to_choose_from)\n",
    "        best_features += [best_feature]\n",
    "        print(f'Added feature {best_feature}, current subset = {best_features}')\n",
    "        del set_to_choose_from[set_to_choose_from.index(best_feature)]\n",
    "\n",
    "        while len(best_features) < self.k:\n",
    "            best_feature = self._find_feature_to_add(x=x, y=y, cur_subset=best_features, set_to_choose_from=set_to_choose_from)\n",
    "            best_features += [best_feature]\n",
    "            print(f'Added feature {best_feature}, current subset = {best_features}')\n",
    "            del set_to_choose_from[set_to_choose_from.index(best_feature)]\n",
    "\n",
    "            if len(best_features) > 2 and self.smooth:\n",
    "                worst_feature = self._find_feature_to_delete(x=x, y=y, cur_subset=best_features)\n",
    "                if worst_feature == best_feature:\n",
    "                    break\n",
    "\n",
    "                if worst_feature is not None:\n",
    "                    del best_features[best_features.index(worst_feature)]\n",
    "                    print(f'Deleted feature {worst_feature}, current subset = {best_features}')\n",
    "                    set_to_choose_from += [worst_feature]\n",
    "\n",
    "                    while len(best_features) > 2:\n",
    "                        worst_feature = self._find_feature_to_delete(x=x, y=y, cur_subset=best_features)\n",
    "                        if worst_feature is None:\n",
    "                            break\n",
    "                        del best_features[best_features.index(worst_feature)]\n",
    "                        print(f'Deleted feature {worst_feature}, current subset = {best_features}')\n",
    "                        set_to_choose_from += [worst_feature]\n",
    "        return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "458ba976-ac38-4b6b-b42f-9098aeca7332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.6847\n",
      "Added feature 17, current subset = [17]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7158\n",
      "Added feature 10, current subset = [17, 10]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7603\n",
      "Added feature 12, current subset = [17, 10, 12]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.7989\n",
      "Added feature 4, current subset = [17, 10, 12, 4]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8329\n",
      "Added feature 19, current subset = [17, 10, 12, 4, 19]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8607\n",
      "Added feature 9, current subset = [17, 10, 12, 4, 19, 9]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.8878\n",
      "Added feature 7, current subset = [17, 10, 12, 4, 19, 9, 7]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9084\n",
      "Added feature 15, current subset = [17, 10, 12, 4, 19, 9, 7, 15]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9234\n",
      "Added feature 2, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9345\n",
      "Added feature 8, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9422\n",
      "Added feature 5, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9491\n",
      "Added feature 11, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9533\n",
      "Added feature 14, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9568\n",
      "Added feature 0, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9609\n",
      "Added feature 1, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0, 1]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9644\n",
      "Added feature 3, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0, 1, 3]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9659\n",
      "Added feature 13, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0, 1, 3, 13]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9667\n",
      "Added feature 18, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0, 1, 3, 13, 18]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9683\n",
      "Added feature 6, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0, 1, 3, 13, 18, 6]\n",
      "******************************\n",
      "Looking for feature to ADD...\n",
      "Best score = 0.9686\n",
      "Added feature 16, current subset = [17, 10, 12, 4, 19, 9, 7, 15, 2, 8, 5, 11, 14, 0, 1, 3, 13, 18, 6, 16]\n",
      "CPU times: user 2h 32min 23s, sys: 4min 14s, total: 2h 36min 37s\n",
      "Wall time: 1h 18min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# самый долгий\n",
    "\n",
    "seq_fs = SequentialForwardFeatureSelection(\n",
    "    model=LGBMClassifier(max_depth=5, n_estimators=500, learning_rate=0.05, verbose=-100),\n",
    "    n_folds=5,\n",
    "    k=20)\n",
    "best_features_seq_fs = seq_fs.fit(x, y)\n",
    "len(best_features_seq_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b9eb5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_features_seq_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed9ba2fe-5506-465a-b94e-d0f76c056213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967245532858651"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_seq_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "050d05da-d997-4046-a874-8d4feff051c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 14},\n",
       " {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14},\n",
       " {1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(best_features_lgm_fs) & set(best_features_shap_fs), set(best_features_lgm_fs) & set(best_features_pi_fs), set(best_features_pi_fs) & set(best_features_shap_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e4b81-090e-4e20-b9c7-8353f74938b4",
   "metadata": {},
   "source": [
    "# Но что, если признаков очень много?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fddfadb1-f207-4c98-854d-6da2b1c297f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=100000, n_features=1000, n_informative=35, n_redundant=7, n_repeated=8, n_clusters_per_class=4, shift=0.8, scale=3.0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c05a2460-10f2-47f1-8a7c-e587736f6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 52s, sys: 1.78 s, total: 18min 54s\n",
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgm_fs = LGMFeatureSelection()\n",
    "lgm_fs.fit(x, y, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a51dedf-b861-4909-bcb4-8437841eb45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619693773393131"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x, y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0068d78-e0c6-4fdd-895a-c36014a29863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>208</td>\n",
       "      <td>206</td>\n",
       "      <td>224</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>458</td>\n",
       "      <td>423</td>\n",
       "      <td>432</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>414</td>\n",
       "      <td>444</td>\n",
       "      <td>439</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "      <td>344</td>\n",
       "      <td>360</td>\n",
       "      <td>343</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>281</td>\n",
       "      <td>283</td>\n",
       "      <td>265</td>\n",
       "      <td>298</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>199</td>\n",
       "      <td>206</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>458</td>\n",
       "      <td>469</td>\n",
       "      <td>468</td>\n",
       "      <td>413</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>244</td>\n",
       "      <td>231</td>\n",
       "      <td>224</td>\n",
       "      <td>208</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>266</td>\n",
       "      <td>305</td>\n",
       "      <td>286</td>\n",
       "      <td>293</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "      <td>231</td>\n",
       "      <td>250</td>\n",
       "      <td>247</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>305</td>\n",
       "      <td>271</td>\n",
       "      <td>276</td>\n",
       "      <td>272</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>209</td>\n",
       "      <td>194</td>\n",
       "      <td>152</td>\n",
       "      <td>181</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>232</td>\n",
       "      <td>250</td>\n",
       "      <td>260</td>\n",
       "      <td>222</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>242</td>\n",
       "      <td>250</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>164</td>\n",
       "      <td>171</td>\n",
       "      <td>177</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>238</td>\n",
       "      <td>255</td>\n",
       "      <td>238</td>\n",
       "      <td>265</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>402</td>\n",
       "      <td>396</td>\n",
       "      <td>395</td>\n",
       "      <td>344</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>236</td>\n",
       "      <td>271</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>328</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>305</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>232</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>221</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance_0  importance_1  importance_2  importance_3  \\\n",
       "0         0           202           208           206           224   \n",
       "1         1           487           458           423           432   \n",
       "2         2           435           414           444           439   \n",
       "3         3           341           344           360           343   \n",
       "4         4           281           283           265           298   \n",
       "5         5           190           191           199           206   \n",
       "6         6           458           469           468           413   \n",
       "7         7           244           231           224           208   \n",
       "8         8           266           305           286           293   \n",
       "9         9           244           231           250           247   \n",
       "10       10           305           271           276           272   \n",
       "11       11           209           194           152           181   \n",
       "12       12           232           250           260           222   \n",
       "13       13           251           252           242           250   \n",
       "14       14           164           171           177           171   \n",
       "15       15           238           255           238           265   \n",
       "16       16           402           396           395           344   \n",
       "17       17           236           271           245           245   \n",
       "18       18           328           338           300           305   \n",
       "19       19           232           222           229           221   \n",
       "\n",
       "    importance_4  \n",
       "0            208  \n",
       "1            457  \n",
       "2            465  \n",
       "3            310  \n",
       "4            280  \n",
       "5            190  \n",
       "6            453  \n",
       "7            200  \n",
       "8            292  \n",
       "9            243  \n",
       "10           288  \n",
       "11           202  \n",
       "12           257  \n",
       "13           256  \n",
       "14           174  \n",
       "15           275  \n",
       "16           414  \n",
       "17           236  \n",
       "18           320  \n",
       "19           239  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_fs.importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e10167c0-e9d0-407d-a379-c8348f9a3d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lgm_fs = lgm_fs.get_selected_features(threshold=0.85)\n",
    "len(best_features_lgm_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f6a87e9-74ff-425b-b28d-ed40080b6c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9621921054749389"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замерим метрику на кросс валидации с отобранными признаками\n",
    "cross_val_score(LGBMClassifier(verbose=-100), x[:, best_features_lgm_fs], y, cv=StratifiedKFold(n_splits=5, shuffle=True), scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99286aad-15fe-4178-9eb7-0ea996abd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# видимо имеет смысл осторожнее выбирать отсечку, либо объединять результаты нескольких методов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uplift",
   "language": "python",
   "name": "uplift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
