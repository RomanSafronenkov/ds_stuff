{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5091a627-c565-4fc0-8278-be3b486c4bad",
   "metadata": {},
   "source": [
    "# Notebook for visualizing how backward pass is performed step by step through different layers with comparison with torch autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a740f52-ea61-4384-bcc4-663cb9934229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Union\n",
    "from IPython.display import HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b487cbcd-9344-433a-9fe4-d886f3d4830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens =  136\n"
     ]
    }
   ],
   "source": [
    "BOS, EOS = ' ', '\\n'\n",
    "\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:128], axis=1) \\\n",
    "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
    "            .tolist()\n",
    "\n",
    "tokens = list(set(''.join(lines)))\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print('num_tokens = ', num_tokens)\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "\n",
    "def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first=True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, data))\n",
    "    data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_ix = [token_to_id[c] for c in data[i]]\n",
    "        data_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        data_ix = np.transpose(data_ix)\n",
    "\n",
    "    return data_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024104d1-36d2-40ae-88f5-8564481f7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        return self.forward(x, grad)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37479b61-d101-4842-93aa-c74412712114",
   "metadata": {},
   "source": [
    "# emb check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288445f6-69a1-4f84-b836-072acc078598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(BaseLayer):\n",
    "    def __init__(self, n_input, emb_dim, pad_idx=None):\n",
    "        self.n_input = n_input\n",
    "        self.emb_dim = emb_dim\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.weights = np.random.normal(scale=np.sqrt(2/(n_input+emb_dim)), size=(n_input, emb_dim))\n",
    "\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.weights_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.weights_optimizer.set_weight(self.weights)\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        self.input = x\n",
    "        return self.weights[x]\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        weights_grad = np.zeros_like(self.weights)\n",
    "        input_shape_len = len(self.input.shape)\n",
    "\n",
    "        if input_shape_len == 2:\n",
    "            for batch_n, s in enumerate(self.input):\n",
    "                for i, emb_i in enumerate(s):\n",
    "                    weights_grad[emb_i] += output_error[batch_n][i]\n",
    "\n",
    "        elif input_shape_len == 1:\n",
    "            for i, emb_i in enumerate(self.input):\n",
    "                weights_grad[emb_i] += output_error[i]\n",
    "\n",
    "        if self.pad_idx is not None:\n",
    "            weights_grad[self.pad_idx] = 0\n",
    "\n",
    "        # self.weights = self.weights_optimizer.step(weights_grad)\n",
    "        return weights_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35730b0d-e52c-4ce9-aa9b-d2a935159e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (136, 16)\n",
      "Forward совпадает: True\n",
      "Градиенты совпадают True\n"
     ]
    }
   ],
   "source": [
    "# проверка на то, что градиент эмбеддингов считается правильно\n",
    "\n",
    "emb = Embedding(len(token_to_id), 16)\n",
    "print(\"Embeddings shape:\", emb.weights.shape)\n",
    "\n",
    "torch_emb = torch.nn.Embedding(len(token_to_id), 16)\n",
    "torch_emb.weight.data = torch.as_tensor(emb.weights)\n",
    "\n",
    "torch_out = torch_emb(torch.as_tensor(sample))\n",
    "\n",
    "print(\"Forward совпадает:\", np.allclose(torch_out.detach().numpy(), emb(sample)))\n",
    "\n",
    "check_error = np.random.normal(0, 100, torch_out.shape)\n",
    "check_error_torch = torch.tensor(check_error)\n",
    "\n",
    "torch_out.backward(check_error_torch)\n",
    "\n",
    "print(\"Градиенты совпадают\", np.allclose(torch_emb.weight.grad.detach().numpy(), emb.backward(check_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9b90e-64ec-4927-b265-659782fade5c",
   "metadata": {},
   "source": [
    "# conv1d check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a41a1e-3f9c-4e3c-a7b0-85a0c178645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dVanilla(BaseLayer):\n",
    "    \"\"\"\n",
    "    Сверточный слой, со страйдом 1 и без паддингов, для 1 предложения, не батча\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        scale = np.sqrt(1/(in_channels*kernel_size))\n",
    "        self.kernel = np.random.uniform(-scale, scale, size=(out_channels, in_channels, kernel_size))\n",
    "        self.bias = np.random.uniform(-scale, scale, size=(out_channels))\n",
    "\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.kernel_optimizer = copy.copy(optimizer)\n",
    "        self.bias_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.kernel_optimizer.set_weight(self.kernel)\n",
    "        self.bias_optimizer.set_weight(self.bias)\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        self.input = x\n",
    "\n",
    "        self.output_len = x.shape[0] - self.kernel_size + 1\n",
    "        output = np.zeros(shape=(self.output_len, self.out_channels))\n",
    "\n",
    "        for kernel_i, ker in enumerate(self.kernel):\n",
    "            for i in range(self.output_len):\n",
    "                output[i:self.kernel_size+i, kernel_i] = self.bias[kernel_i] + np.sum(x[i:self.kernel_size+i, :] * ker.T)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        dy_dkernel = np.zeros(shape=self.kernel.shape)\n",
    "        dy_dbias = np.zeros(shape=self.bias.shape)\n",
    "        dy_dx = np.zeros(shape=self.input.shape)\n",
    "\n",
    "        for kernel_i, ker in enumerate(self.kernel):\n",
    "            helper_k = np.zeros(shape=ker.T.shape)\n",
    "\n",
    "            for i in range(self.output_len):\n",
    "                helper_k += self.input[i:self.kernel_size+i, :] * output_error[i, kernel_i]\n",
    "                dy_dx[i:self.kernel_size+i, :] += ker.T * output_error[i, kernel_i]\n",
    "\n",
    "            dy_dkernel[kernel_i] = helper_k.T\n",
    "            dy_dbias[kernel_i] = np.sum(output_error[:, kernel_i])\n",
    "\n",
    "        # self.kernel = self.kernel_optimizer.step(dy_dkernel)\n",
    "        # self.bias = self.bias_optimizer.step(dy_dbias)\n",
    "\n",
    "        # return dy_dx\n",
    "        return dy_dkernel, dy_dbias, dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dbbea5d-0dc8-4c77-9574-349d24d48e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода свертки: (126, 4)\n",
      "Градиент по входу совпадает: True\n",
      "Градиент по смещениям совпадает: True\n",
      "Градиент по ядру совпадает: True\n"
     ]
    }
   ],
   "source": [
    "sample = to_matrix(np.random.choice(lines, size=5), token_to_id, max_len=130)\n",
    "\n",
    "emb = Embedding(len(token_to_id), 16)\n",
    "encoded_data = emb(sample[0])\n",
    "\n",
    "conv = Conv1dVanilla(16, 4, 5)\n",
    "torch_conv = torch.nn.Conv1d(16, 4, 5)\n",
    "torch_conv.weight.data = torch.as_tensor(conv.kernel)\n",
    "torch_conv.bias.data = torch.as_tensor(conv.bias)\n",
    "\n",
    "torch_input = torch.tensor(encoded_data[np.newaxis, :], dtype=torch.float64, requires_grad=True)\n",
    "torch_out = torch_conv(torch_input.permute(0, 2, 1))  # permute потому что torch на вход принимает формат [BATCH_SIZE, EMB_DIM, SENTENCE_LEN]\n",
    "\n",
    "# проверка что forward работает также как у torch, \n",
    "print(\"Vanilla Forward такой же как и torch forward:\", np.allclose(torch_out.permute(0, 2, 1).detach().numpy(), conv(encoded_data)))\n",
    "\n",
    "print(\"Shape выхода свертки:\", conv(encoded_data).shape)\n",
    "\n",
    "# случайная ошибка, которая приходит \"сверху\" от вышестоящих слоев, по размеру она совпадает с выходом слоя\n",
    "check_error = np.random.normal(loc=-3, scale=100, size=(conv(encoded_data).shape))\n",
    "check_error_torch = torch.tensor(np.transpose(check_error[np.newaxis, :], (0, 2, 1)))\n",
    "\n",
    "torch_out.backward(check_error_torch)  # считаем градиенты для всех тензоров, которые участвуют в forward проходе\n",
    "kernel_grad, bias_grad, in_error = conv.backward(check_error)  # тоже самое, только в ручном слое\n",
    "\n",
    "# проверка градиентов весов и входа\n",
    "print(\"Градиент по входу совпадает:\", np.allclose(torch_input.grad.detach().numpy(), in_error))\n",
    "print(\"Градиент по смещениям совпадает:\", np.allclose(torch_conv.bias.grad.detach().numpy(), bias_grad))\n",
    "print(\"Градиент по ядру совпадает:\", np.allclose(torch_conv.weight.grad.detach().numpy(), kernel_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c312b6-4da3-40dd-b5d9-d3ce8346f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(BaseLayer):\n",
    "    \"\"\"\n",
    "    Сверточный слой, со страйдом 1 и без паддингов, для батча\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        scale = np.sqrt(1/(in_channels*kernel_size))\n",
    "        self.kernel = np.random.uniform(-scale, scale, size=(out_channels, in_channels, kernel_size))\n",
    "        self.bias = np.random.uniform(-scale, scale, size=(out_channels))\n",
    "\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.kernel_optimizer = copy.copy(optimizer)\n",
    "        self.bias_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.kernel_optimizer.set_weight(self.kernel)\n",
    "        self.bias_optimizer.set_weight(self.bias)\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        \"\"\"\n",
    "        Работает с битчами вида [BATCH_SIZE, SENTENCE_LEN, EMB_DIM]\n",
    "        \"\"\"\n",
    "        self.input = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.input_len = x.shape[1]\n",
    "        self.output_len = self.input_len - self.kernel_size + 1\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for sentence in x:\n",
    "            result.append(self._forward_for_one(sentence))\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "    def _forward_for_one(self, x):\n",
    "        \"\"\"\n",
    "        Просто свертка для 1 предложения\n",
    "        \"\"\"\n",
    "        output = np.zeros(shape=(self.output_len, self.out_channels))\n",
    "\n",
    "        # для каждого выходного канала и ядра, отвечающего за этот канал\n",
    "        for kernel_i, ker in enumerate(self.kernel):\n",
    "            # по выходной длине\n",
    "            for i in range(self.output_len):\n",
    "                # умножаем срез по размеру ядра на ядро и суммируем\n",
    "                output[i:self.kernel_size+i, kernel_i] = self.bias[kernel_i] + np.sum(x[i:self.kernel_size+i, :] * ker.T)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        \"\"\"\n",
    "        Градиенты по всем батчу\n",
    "        \"\"\"\n",
    "        dy_dkernels = []\n",
    "        dy_dbiass = []\n",
    "        dy_dxs = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            dy_dkernel, dy_dbias, dy_dx = self._calc_grad_for_one(output_error[i], self.input[i])\n",
    "            dy_dkernels.append(dy_dkernel)\n",
    "            dy_dbiass.append(dy_dbias)\n",
    "            dy_dxs.append(dy_dx)\n",
    "\n",
    "        dy_dkernels = np.sum(np.array(dy_dkernels), axis=0)  # суммируем градиенты по батчу\n",
    "        dy_dbiass = np.sum(np.array(dy_dbiass), axis=0)\n",
    "        dy_dxs = np.array(dy_dxs)\n",
    "\n",
    "        # self.kernel = self.kernel_optimizer.step(dy_dkernels)  # делаем шаг спуска по сумме градиентов\n",
    "        # self.bias = self.bias_optimizer.step(dy_dbiass)\n",
    "\n",
    "        # return dy_dxs\n",
    "        return dy_dkernels, dy_dbiass, dy_dxs\n",
    "\n",
    "    def _calc_grad_for_one(self, output_error, x):\n",
    "        dy_dkernel = np.zeros(shape=self.kernel.shape)\n",
    "        dy_dbias = np.zeros(shape=self.bias.shape)\n",
    "        dy_dx = np.zeros(shape=x.shape)\n",
    "\n",
    "        for kernel_i, ker in enumerate(self.kernel):\n",
    "            helper_k = np.zeros(shape=ker.T.shape)\n",
    "\n",
    "            for i in range(self.output_len):\n",
    "                helper_k += x[i:self.kernel_size+i, :] * output_error[i, kernel_i]\n",
    "                dy_dx[i:self.kernel_size+i, :] += ker.T * output_error[i, kernel_i]\n",
    "\n",
    "            dy_dkernel[kernel_i] = helper_k.T\n",
    "            dy_dbias[kernel_i] = np.sum(output_error[:, kernel_i])\n",
    "\n",
    "        return dy_dkernel, dy_dbias, dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e00fb2-d638-4a0c-8dc3-c7433a146f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода свертки: (5, 126, 4)\n",
      "Градиент по входу совпадает: True\n",
      "Градиент по смещениям совпадает: True\n",
      "Градиент по ядру совпадает: True\n"
     ]
    }
   ],
   "source": [
    "# тоже самое, только теперь ручная свертка умеет работать с батчами, np.newaxis теперь не нужен, размер входа будет [BATCH_SIZE, SENTENCE_LEN, EMB_DIM]\n",
    "\n",
    "sample = to_matrix(np.random.choice(lines, size=5), token_to_id, max_len=130)\n",
    "\n",
    "emb = Embedding(len(token_to_id), 16)\n",
    "encoded_data = emb(sample) # батч из 5 предложений\n",
    "\n",
    "conv = Conv1d(16, 4, 5)\n",
    "torch_conv = torch.nn.Conv1d(16, 4, 5)\n",
    "torch_conv.weight.data = torch.as_tensor(conv.kernel)\n",
    "torch_conv.bias.data = torch.as_tensor(conv.bias)\n",
    "\n",
    "torch_input = torch.tensor(encoded_data, dtype=torch.float64, requires_grad=True)\n",
    "torch_out = torch_conv(torch_input.permute(0, 2, 1))  # permute потому что torch на вход принимает формат [BATCH_SIZE, EMB_DIM, SENTENCE_LEN]\n",
    "\n",
    "# проверка что forward работает также как у torch, \n",
    "print(\"Vanilla Forward такой же как и torch forward:\", np.allclose(torch_out.permute(0, 2, 1).detach().numpy(), conv(encoded_data)))\n",
    "\n",
    "print(\"Shape выхода свертки:\", conv(encoded_data).shape)\n",
    "\n",
    "# случайная ошибка, которая приходит \"сверху\" от вышестоящих слоев, по размеру она совпадает с выходом слоя\n",
    "check_error = np.random.normal(loc=-3, scale=100, size=(conv(encoded_data).shape))\n",
    "check_error_torch = torch.tensor(np.transpose(check_error, (0, 2, 1)))\n",
    "\n",
    "torch_out.backward(check_error_torch)  # считаем градиенты для всех тензоров, которые участвуют в forward проходе\n",
    "kernel_grad, bias_grad, in_error = conv.backward(check_error)  # тоже самое, только в ручном слое\n",
    "\n",
    "# проверка градиентов весов и входа\n",
    "print(\"Градиент по входу совпадает:\", np.allclose(torch_input.grad.detach().numpy(), in_error))\n",
    "print(\"Градиент по смещениям совпадает:\", np.allclose(torch_conv.bias.grad.detach().numpy(), bias_grad))\n",
    "print(\"Градиент по ядру совпадает:\", np.allclose(torch_conv.weight.grad.detach().numpy(), kernel_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c935dff-a20e-40be-89b1-19b839e1c5ce",
   "metadata": {},
   "source": [
    "# linear check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9cde34-2484-494d-ba65-d1f14c97018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(BaseLayer):\n",
    "    \"\"\"\n",
    "    Linear class permorms ordinary FC layer in neural networks\n",
    "    Parameters:\n",
    "    n_input - size of input neurons\n",
    "    n_output - size of output neurons\n",
    "    Methods:\n",
    "    set_optimizer(optimizer) - is used for setting an optimizer for gradient descent\n",
    "    forward(x) - performs forward pass of the layer\n",
    "    backward(output_error, learning_rate) - performs backward pass of the layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_input: int, n_output: int) -> None:\n",
    "        super().__init__()\n",
    "        self.input = None\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.w = np.random.normal(scale=np.sqrt(2 / (n_input + n_output)), size=(n_input, n_output))\n",
    "        self.b = np.random.normal(scale=np.sqrt(2 / (n_input + n_output)), size=(1, n_output))\n",
    "\n",
    "        self.w_optimizer = None\n",
    "        self.b_optimizer = None\n",
    "\n",
    "    def set_optimizer(self, optimizer) -> None:\n",
    "        self.w_optimizer = copy.copy(optimizer)\n",
    "        self.b_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.w_optimizer.set_weight(self.w)\n",
    "        self.b_optimizer.set_weight(self.b)\n",
    "\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        self.input = x\n",
    "        return x.dot(self.w) + self.b\n",
    "\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        # assert self.w_optimizer is not None and self.b_optimizer is not None, 'You should set an optimizer'\n",
    "        w_grad = self.input.T.dot(output_error)\n",
    "        b_grad = np.ones((1, len(output_error))).dot(output_error)\n",
    "        input_error = output_error.dot(self.w.T)\n",
    "\n",
    "        # self.w = self.w_optimizer.step(w_grad)\n",
    "        # self.b = self.b_optimizer.step(b_grad)\n",
    "        return w_grad, b_grad, input_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4f48bc-8fed-49f0-b7a1-643be42d4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода линейного слоя: (100, 25)\n",
      "Градиент по входу совпадает: True\n",
      "Градиент по смещениям совпадает: True\n",
      "Градиент по ядру совпадает: True\n"
     ]
    }
   ],
   "source": [
    "# проверка того, что линейный слой работает правильно, транспонирование весов происходит потому, что домножение на веса в моем слое справа\n",
    "\n",
    "sample = np.random.normal(loc=0, scale=100, size=(100, 16))\n",
    "\n",
    "linear = Linear(16, 25)\n",
    "torch_linear = torch.nn.Linear(16, 25)\n",
    "torch_linear.weight.data = torch.as_tensor(linear.w.T)\n",
    "torch_linear.bias.data = torch.as_tensor(linear.b)\n",
    "\n",
    "torch_input = torch.tensor(sample, dtype=torch.float64, requires_grad=True)\n",
    "torch_out = torch_linear(torch_input)\n",
    "\n",
    "# проверка что forward работает также как у torch, \n",
    "print(\"Vanilla Forward такой же как и torch forward:\", np.allclose(torch_out.detach().numpy(), linear(sample)))\n",
    "\n",
    "print(\"Shape выхода линейного слоя:\", linear(sample).shape)\n",
    "\n",
    "# случайная ошибка, которая приходит \"сверху\" от вышестоящих слоев, по размеру она совпадает с выходом слоя\n",
    "check_error = np.random.normal(loc=-3, scale=100, size=(linear(sample).shape))\n",
    "check_error_torch = torch.tensor(check_error)\n",
    "\n",
    "torch_out.backward(check_error_torch)  # считаем градиенты для всех тензоров, которые участвуют в forward проходе\n",
    "kernel_grad, bias_grad, in_error = linear.backward(check_error)  # тоже самое, только в ручном слое\n",
    "\n",
    "# проверка градиентов весов и входа\n",
    "print(\"Градиент по входу совпадает:\", np.allclose(torch_input.grad.detach().numpy(), in_error))\n",
    "print(\"Градиент по смещениям совпадает:\", np.allclose(torch_linear.bias.grad.detach().numpy(), bias_grad))\n",
    "print(\"Градиент по ядру совпадает:\", np.allclose(torch_linear.weight.grad.detach().numpy(), kernel_grad.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2710d3c-e393-40ef-9ea8-4779a39bb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear3d(BaseLayer):\n",
    "    \"\"\"\n",
    "    Linear class permorms ordinary FC layer in neural networks\n",
    "    Parameters:\n",
    "    n_input - size of input neurons\n",
    "    n_output - size of output neurons\n",
    "    Methods:\n",
    "    set_optimizer(optimizer) - is used for setting an optimizer for gradient descent\n",
    "    forward(x) - performs forward pass of the layer\n",
    "    backward(output_error, learning_rate) - performs backward pass of the layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_input: int, n_output: int) -> None:\n",
    "        super().__init__()\n",
    "        self.input = None\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.w = np.random.normal(scale=np.sqrt(2 / (n_input + n_output)), size=(n_input, n_output))\n",
    "        self.b = np.random.normal(scale=np.sqrt(2 / (n_input + n_output)), size=(1, n_output))\n",
    "\n",
    "        self.w_optimizer = None\n",
    "        self.b_optimizer = None\n",
    "\n",
    "    def set_optimizer(self, optimizer) -> None:\n",
    "        self.w_optimizer = copy.copy(optimizer)\n",
    "        self.b_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.w_optimizer.set_weight(self.w)\n",
    "        self.b_optimizer.set_weight(self.b)\n",
    "\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        self.input = x\n",
    "        return np.matmul(x, self.w) + self.b  # the same as @\n",
    "\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        # assert self.w_optimizer is not None and self.b_optimizer is not None, 'You should set an optimizer'\n",
    "        # перемножаем последние 2 измерения друг с другом с помощью matmul и суммируем\n",
    "        w_grad = np.sum(np.transpose(self.input, (0, 2, 1)) @ output_error, axis=0)\n",
    "        b_grad = np.sum(output_error, axis=(0, 1))\n",
    "        input_error = output_error @ self.w.T\n",
    "\n",
    "        # self.w = self.w_optimizer.step(w_grad)\n",
    "        # self.b = self.b_optimizer.step(b_grad)\n",
    "        return w_grad, b_grad, input_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e859cd5d-9307-4e26-a1b5-739ef0dbc75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода линейного слоя: (100, 32, 25)\n",
      "Градиент по входу совпадает: True\n",
      "Градиент по смещениям совпадает: True\n",
      "Градиент по ядру совпадает: True\n"
     ]
    }
   ],
   "source": [
    "# проверка того, что линейный слой для 3-х измерений работает правильно, транспонирование весов происходит потому, что домножение на веса в моем слое справа\n",
    "\n",
    "sample = np.random.normal(loc=0, scale=100, size=(100, 32, 16))\n",
    "\n",
    "linear = Linear3d(16, 25)\n",
    "torch_linear = torch.nn.Linear(16, 25)\n",
    "torch_linear.weight.data = torch.as_tensor(linear.w.T)\n",
    "torch_linear.bias.data = torch.as_tensor(linear.b)\n",
    "\n",
    "torch_input = torch.tensor(sample, dtype=torch.float64, requires_grad=True)\n",
    "torch_out = torch_linear(torch_input)\n",
    "\n",
    "# проверка что forward работает также как у torch, \n",
    "print(\"Vanilla Forward такой же как и torch forward:\", np.allclose(torch_out.detach().numpy(), linear(sample)))\n",
    "\n",
    "print(\"Shape выхода линейного слоя:\", linear(sample).shape)\n",
    "\n",
    "# случайная ошибка, которая приходит \"сверху\" от вышестоящих слоев, по размеру она совпадает с выходом слоя\n",
    "check_error = np.random.normal(loc=-3, scale=100, size=(linear(sample).shape))\n",
    "check_error_torch = torch.tensor(check_error)\n",
    "\n",
    "torch_out.backward(check_error_torch)  # считаем градиенты для всех тензоров, которые участвуют в forward проходе\n",
    "kernel_grad, bias_grad, in_error = linear.backward(check_error)  # тоже самое, только в ручном слое\n",
    "\n",
    "# проверка градиентов весов и входа\n",
    "print(\"Градиент по входу совпадает:\", np.allclose(torch_input.grad.detach().numpy(), in_error))\n",
    "print(\"Градиент по смещениям совпадает:\", np.allclose(torch_linear.bias.grad.detach().numpy(), bias_grad))\n",
    "print(\"Градиент по ядру совпадает:\", np.allclose(torch_linear.weight.grad.detach().numpy(), kernel_grad.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1626fa1-bf58-4950-bac1-d65ea7c07b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.01432425e+04,  8.54376029e+04, -2.03543253e+04,\n",
       "        -4.57779690e+04,  5.93759573e+04,  2.26119128e+04,\n",
       "        -8.51991229e+04,  5.65570757e+04,  4.50999740e+04,\n",
       "        -2.50116531e+04,  8.52174259e+04,  2.23094183e+04,\n",
       "        -8.94199095e+04, -8.94775158e+04,  2.22095782e+04,\n",
       "        -6.91201388e+04, -4.39176286e+04,  8.89706282e+04,\n",
       "         5.34499053e+03, -1.94521761e+04,  6.32939855e+04,\n",
       "         6.96434504e+04,  8.53401340e+04,  5.01143782e+04,\n",
       "        -7.60784954e+04],\n",
       "       [ 6.17063591e+04, -4.19896315e+04,  9.91427993e+04,\n",
       "         1.14313845e+05,  5.81959143e+02, -6.69621451e+03,\n",
       "         4.03134117e+04, -5.59623141e+04,  9.22817574e+03,\n",
       "         1.03086575e+04, -9.23303077e+04,  4.44231216e+04,\n",
       "         8.54574455e+03, -8.02838840e+04, -6.68541904e+04,\n",
       "         5.35844574e+04,  5.14282893e+04,  6.01799688e+04,\n",
       "        -2.77477396e+04,  2.56258701e+04,  7.69994258e+04,\n",
       "        -4.83805158e+04, -1.61227823e+04, -7.18813760e+04,\n",
       "         1.91162720e+04],\n",
       "       [-6.43196195e+03,  2.85943068e+04,  7.61148934e+04,\n",
       "        -6.04528481e+04,  5.39112343e+04, -2.73549685e+04,\n",
       "         8.18865948e+04, -1.19564120e+04, -6.47928037e+04,\n",
       "        -6.74145118e+04, -1.64903649e+04, -5.03867739e+04,\n",
       "         6.85091951e+04, -3.67886232e+04, -8.09100871e+04,\n",
       "         1.12168875e+05, -6.07137833e+03,  8.77014446e+03,\n",
       "        -5.89049841e+04, -4.26330622e+03, -6.69647010e+04,\n",
       "         2.31559486e+04,  2.86741705e+04, -6.82024013e+04,\n",
       "         8.96264365e+04],\n",
       "       [ 8.82013033e+04, -7.18974313e+04, -4.07454324e+04,\n",
       "        -6.69838547e+04,  3.48733878e+04,  5.82743112e+04,\n",
       "        -5.63209482e+04, -2.10009258e+04, -1.10125215e+04,\n",
       "         3.06200662e+04, -1.45292581e+04, -2.07763975e+04,\n",
       "        -5.28951326e+04,  3.43558194e+04,  1.04160406e+04,\n",
       "        -7.53106377e+04,  6.46263613e+04,  2.39872023e+04,\n",
       "        -8.61524743e+04, -2.10662606e+04,  3.01164764e+04,\n",
       "        -1.28600460e+04, -4.60819881e+04, -4.47666774e+04,\n",
       "         5.20162576e+04],\n",
       "       [ 9.04417718e+04, -2.96251467e+04,  1.23445646e+04,\n",
       "        -5.63304920e+04, -4.17252721e+04,  7.51662928e+03,\n",
       "         2.59489148e+04,  3.91920769e+03, -5.44512442e+03,\n",
       "         6.31484708e+04, -6.82598115e+03,  1.38556600e+04,\n",
       "         5.42001634e+04,  6.09227607e+04, -6.01418406e+04,\n",
       "         4.55604747e+04,  1.02982785e+05, -5.68101863e+04,\n",
       "         3.82747823e+04, -4.92870496e+03,  5.97591221e+04,\n",
       "        -4.48040463e+04, -2.81440432e+04, -2.00480931e+04,\n",
       "         9.02961357e+04],\n",
       "       [-4.08433954e+04, -3.24589443e+04,  8.27597849e+04,\n",
       "         2.11153807e+04,  2.80789410e+04,  2.86301668e+04,\n",
       "        -6.37535865e+04, -3.75775315e+04, -4.70409997e+04,\n",
       "        -1.73970328e+04, -5.43174765e+04,  8.87094236e+03,\n",
       "        -1.41114804e+04,  1.40682557e+04, -5.56017198e+03,\n",
       "         6.17246819e+04,  6.26059817e+04, -1.80419951e+04,\n",
       "         2.06144310e+03,  7.82742675e+04,  9.44649153e+01,\n",
       "         1.52212086e+04, -4.54814423e+04,  1.01800088e+04,\n",
       "         3.81718400e+03],\n",
       "       [-8.54124606e+04,  1.36634893e+05, -1.21782879e+05,\n",
       "        -9.73964690e+04,  5.08716075e+04, -2.29185675e+04,\n",
       "         4.48346049e+03, -9.77196345e+04, -9.97606650e+04,\n",
       "         7.43398567e+04,  1.03614814e+05, -8.84064558e+04,\n",
       "         4.99230320e+04, -6.98907828e+03, -6.63533382e+04,\n",
       "        -6.01679917e+04, -5.41234657e+04, -5.69527625e+04,\n",
       "        -1.24163323e+05,  1.04482456e+05, -7.71440094e+04,\n",
       "        -6.51512858e+03,  5.64719168e+04,  6.87352442e+04,\n",
       "        -2.44112531e+04],\n",
       "       [ 4.95699954e+03, -9.58167329e+04,  6.73570467e+04,\n",
       "         1.23268407e+05, -3.91877066e+04, -9.24307915e+04,\n",
       "         4.29559037e+04, -3.68858275e+04,  5.74921490e+03,\n",
       "         6.56770291e+04, -7.43499023e+04, -5.26046282e+02,\n",
       "        -4.28394988e+04, -1.44879431e+05, -3.99526565e+04,\n",
       "         1.11814255e+05,  5.90031624e+04, -7.77898966e+04,\n",
       "        -8.99972257e+04,  1.95182331e+04, -4.69663501e+03,\n",
       "        -6.08365243e+04, -1.72637219e+05,  4.62340502e+04,\n",
       "         6.22871376e+04],\n",
       "       [ 4.39878732e+04,  3.68598481e+04,  2.79494120e+04,\n",
       "        -8.42818937e+03, -1.38919353e+04, -7.10015543e+04,\n",
       "        -5.10066503e+04,  2.08161510e+04,  1.58302902e+04,\n",
       "        -7.10045299e+03, -7.30017222e+03, -1.23396452e+03,\n",
       "         3.26408713e+04,  5.42744728e+03,  7.73105083e+04,\n",
       "        -4.38779394e+04, -8.42844693e+04, -7.12972771e+04,\n",
       "        -2.18646617e+04, -2.59846200e+04, -5.28870444e+03,\n",
       "         9.75431103e+03,  1.51375893e+04, -6.26497656e+04,\n",
       "         6.55968123e+04],\n",
       "       [-7.72231140e+04,  4.25327538e+04,  5.50752930e+03,\n",
       "        -1.56319200e+04, -6.54039495e+04,  2.98089392e+04,\n",
       "        -3.78623139e+04, -2.85127659e+04,  2.18061533e+04,\n",
       "        -1.65125912e+04, -3.23449036e+04,  6.52937004e+04,\n",
       "         6.22884923e+04,  9.73373239e+04,  1.87772304e+04,\n",
       "        -1.76589963e+04, -6.17865341e+04, -7.23850645e+04,\n",
       "         2.90351088e+04,  2.64041690e+04, -1.72888230e+04,\n",
       "         7.69665425e+04, -3.38159778e+04,  1.12866742e+05,\n",
       "        -7.47558686e+04],\n",
       "       [-5.64472957e+04,  1.15785437e+04,  6.10291053e+04,\n",
       "        -2.38676851e+04,  4.83718078e+04,  1.08193972e+04,\n",
       "         4.34800739e+04, -1.81506955e+04, -3.85507126e+04,\n",
       "        -4.50692644e+04,  6.46126980e+04,  3.64116545e+04,\n",
       "        -2.84181163e+04, -9.49500166e+03, -3.91976346e+04,\n",
       "         3.60588879e+04,  6.00395531e+04,  1.47653074e+05,\n",
       "        -5.09578074e+04,  6.96711722e+04, -1.33770416e+03,\n",
       "         6.46024330e+04,  1.20520938e+05, -1.07519422e+05,\n",
       "        -1.13656100e+04],\n",
       "       [-6.65361295e+04,  1.64434895e+04,  1.54335858e+04,\n",
       "         1.10538160e+04,  8.80915357e+04,  6.22724476e+04,\n",
       "         5.27492080e+04, -7.50234076e+04,  7.63989380e+03,\n",
       "        -5.83563879e+04,  5.90758345e+04,  7.73193636e+04,\n",
       "         2.80840139e+04, -1.38141999e+04, -4.77267259e+03,\n",
       "        -2.93321962e+04, -2.87853109e+04,  6.80064054e+04,\n",
       "         2.20113585e+04,  1.02717504e+05, -5.21195419e+04,\n",
       "         2.84323835e+04,  1.67041577e+04,  1.51480658e+05,\n",
       "        -5.84739807e+04],\n",
       "       [ 5.91788905e+04, -9.44884167e+04,  1.69688853e+05,\n",
       "         6.48503399e+04,  1.84514376e+05,  1.22652922e+05,\n",
       "         1.47264013e+04,  1.27025271e+05,  1.76443382e+04,\n",
       "        -1.07445727e+05, -1.64869159e+05,  1.25753006e+05,\n",
       "        -5.36290202e+04,  7.15265338e+04,  9.65922914e+04,\n",
       "        -1.07191646e+05, -1.03278165e+04,  6.63417820e+04,\n",
       "        -4.26941694e+04,  8.61192684e+03, -8.21378654e+03,\n",
       "         2.21854468e+04, -8.59882835e+04,  1.18890296e+05,\n",
       "        -7.11754632e+04],\n",
       "       [ 6.29377344e+04,  8.13900521e+04,  7.81265439e+03,\n",
       "         1.02808057e+05, -3.82727831e+04, -1.00624052e+05,\n",
       "         7.47282010e+04,  6.14085943e+04, -2.46810126e+04,\n",
       "        -9.89564264e+04, -7.60697975e+04,  9.34842033e+04,\n",
       "        -6.39742384e+04, -3.19239378e+04, -8.55954852e+04,\n",
       "         5.56510892e+04,  5.29724520e+04,  8.20638349e+04,\n",
       "         6.49999627e+03, -5.55431833e+04,  7.21956164e+04,\n",
       "         2.66714997e+04, -2.62592333e+04, -6.59588912e+04,\n",
       "        -5.74222157e+04],\n",
       "       [-7.70559870e+04,  1.83553058e+04, -1.26322182e+04,\n",
       "         3.34251414e+04, -6.00776517e+03, -4.18874072e+04,\n",
       "         1.00071823e+05, -6.31063403e+04,  7.47192108e+03,\n",
       "         1.20648193e+05,  3.34270723e+04,  5.85985638e+04,\n",
       "         1.00166594e+05, -4.28571588e+04,  1.29933740e+04,\n",
       "        -3.84216858e+04, -1.94664296e+03,  3.98786000e+04,\n",
       "        -5.31166855e+04, -9.99097271e+04, -9.17926688e+04,\n",
       "        -3.05654444e+04,  6.03774711e+04,  8.65050607e+04,\n",
       "        -9.17964122e+04],\n",
       "       [-1.95680177e+04, -5.92864861e+04, -6.66752282e+04,\n",
       "        -2.00100679e+04, -5.81785335e+03,  2.70409775e+04,\n",
       "         1.96388338e+04,  3.42490264e+04, -4.31955344e+04,\n",
       "         5.02941239e+03, -6.04269024e+04, -4.45683481e+04,\n",
       "        -5.20886064e+04,  1.28801592e+05,  3.38340327e+04,\n",
       "        -1.96647643e+04, -1.70992894e+04, -6.24878256e+04,\n",
       "         1.72999008e+04, -1.91791014e+03, -4.71869833e+04,\n",
       "        -1.16745271e+04,  7.06966627e+03, -1.31099163e+04,\n",
       "        -6.24062950e+03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(sample, (0, 2, 1))[1].dot(check_error[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9afc29a5-9c1d-4354-b212-44cae08b5129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.01432425e+04,  8.54376029e+04, -2.03543253e+04,\n",
       "        -4.57779690e+04,  5.93759573e+04,  2.26119128e+04,\n",
       "        -8.51991229e+04,  5.65570757e+04,  4.50999740e+04,\n",
       "        -2.50116531e+04,  8.52174259e+04,  2.23094183e+04,\n",
       "        -8.94199095e+04, -8.94775158e+04,  2.22095782e+04,\n",
       "        -6.91201388e+04, -4.39176286e+04,  8.89706282e+04,\n",
       "         5.34499053e+03, -1.94521761e+04,  6.32939855e+04,\n",
       "         6.96434504e+04,  8.53401340e+04,  5.01143782e+04,\n",
       "        -7.60784954e+04],\n",
       "       [ 6.17063591e+04, -4.19896315e+04,  9.91427993e+04,\n",
       "         1.14313845e+05,  5.81959143e+02, -6.69621451e+03,\n",
       "         4.03134117e+04, -5.59623141e+04,  9.22817574e+03,\n",
       "         1.03086575e+04, -9.23303077e+04,  4.44231216e+04,\n",
       "         8.54574455e+03, -8.02838840e+04, -6.68541904e+04,\n",
       "         5.35844574e+04,  5.14282893e+04,  6.01799688e+04,\n",
       "        -2.77477396e+04,  2.56258701e+04,  7.69994258e+04,\n",
       "        -4.83805158e+04, -1.61227823e+04, -7.18813760e+04,\n",
       "         1.91162720e+04],\n",
       "       [-6.43196195e+03,  2.85943068e+04,  7.61148934e+04,\n",
       "        -6.04528481e+04,  5.39112343e+04, -2.73549685e+04,\n",
       "         8.18865948e+04, -1.19564120e+04, -6.47928037e+04,\n",
       "        -6.74145118e+04, -1.64903649e+04, -5.03867739e+04,\n",
       "         6.85091951e+04, -3.67886232e+04, -8.09100871e+04,\n",
       "         1.12168875e+05, -6.07137833e+03,  8.77014446e+03,\n",
       "        -5.89049841e+04, -4.26330622e+03, -6.69647010e+04,\n",
       "         2.31559486e+04,  2.86741705e+04, -6.82024013e+04,\n",
       "         8.96264365e+04],\n",
       "       [ 8.82013033e+04, -7.18974313e+04, -4.07454324e+04,\n",
       "        -6.69838547e+04,  3.48733878e+04,  5.82743112e+04,\n",
       "        -5.63209482e+04, -2.10009258e+04, -1.10125215e+04,\n",
       "         3.06200662e+04, -1.45292581e+04, -2.07763975e+04,\n",
       "        -5.28951326e+04,  3.43558194e+04,  1.04160406e+04,\n",
       "        -7.53106377e+04,  6.46263613e+04,  2.39872023e+04,\n",
       "        -8.61524743e+04, -2.10662606e+04,  3.01164764e+04,\n",
       "        -1.28600460e+04, -4.60819881e+04, -4.47666774e+04,\n",
       "         5.20162576e+04],\n",
       "       [ 9.04417718e+04, -2.96251467e+04,  1.23445646e+04,\n",
       "        -5.63304920e+04, -4.17252721e+04,  7.51662928e+03,\n",
       "         2.59489148e+04,  3.91920769e+03, -5.44512442e+03,\n",
       "         6.31484708e+04, -6.82598115e+03,  1.38556600e+04,\n",
       "         5.42001634e+04,  6.09227607e+04, -6.01418406e+04,\n",
       "         4.55604747e+04,  1.02982785e+05, -5.68101863e+04,\n",
       "         3.82747823e+04, -4.92870496e+03,  5.97591221e+04,\n",
       "        -4.48040463e+04, -2.81440432e+04, -2.00480931e+04,\n",
       "         9.02961357e+04],\n",
       "       [-4.08433954e+04, -3.24589443e+04,  8.27597849e+04,\n",
       "         2.11153807e+04,  2.80789410e+04,  2.86301668e+04,\n",
       "        -6.37535865e+04, -3.75775315e+04, -4.70409997e+04,\n",
       "        -1.73970328e+04, -5.43174765e+04,  8.87094236e+03,\n",
       "        -1.41114804e+04,  1.40682557e+04, -5.56017198e+03,\n",
       "         6.17246819e+04,  6.26059817e+04, -1.80419951e+04,\n",
       "         2.06144310e+03,  7.82742675e+04,  9.44649153e+01,\n",
       "         1.52212086e+04, -4.54814423e+04,  1.01800088e+04,\n",
       "         3.81718400e+03],\n",
       "       [-8.54124606e+04,  1.36634893e+05, -1.21782879e+05,\n",
       "        -9.73964690e+04,  5.08716075e+04, -2.29185675e+04,\n",
       "         4.48346049e+03, -9.77196345e+04, -9.97606650e+04,\n",
       "         7.43398567e+04,  1.03614814e+05, -8.84064558e+04,\n",
       "         4.99230320e+04, -6.98907828e+03, -6.63533382e+04,\n",
       "        -6.01679917e+04, -5.41234657e+04, -5.69527625e+04,\n",
       "        -1.24163323e+05,  1.04482456e+05, -7.71440094e+04,\n",
       "        -6.51512858e+03,  5.64719168e+04,  6.87352442e+04,\n",
       "        -2.44112531e+04],\n",
       "       [ 4.95699954e+03, -9.58167329e+04,  6.73570467e+04,\n",
       "         1.23268407e+05, -3.91877066e+04, -9.24307915e+04,\n",
       "         4.29559037e+04, -3.68858275e+04,  5.74921490e+03,\n",
       "         6.56770291e+04, -7.43499023e+04, -5.26046282e+02,\n",
       "        -4.28394988e+04, -1.44879431e+05, -3.99526565e+04,\n",
       "         1.11814255e+05,  5.90031624e+04, -7.77898966e+04,\n",
       "        -8.99972257e+04,  1.95182331e+04, -4.69663501e+03,\n",
       "        -6.08365243e+04, -1.72637219e+05,  4.62340502e+04,\n",
       "         6.22871376e+04],\n",
       "       [ 4.39878732e+04,  3.68598481e+04,  2.79494120e+04,\n",
       "        -8.42818937e+03, -1.38919353e+04, -7.10015543e+04,\n",
       "        -5.10066503e+04,  2.08161510e+04,  1.58302902e+04,\n",
       "        -7.10045299e+03, -7.30017222e+03, -1.23396452e+03,\n",
       "         3.26408713e+04,  5.42744728e+03,  7.73105083e+04,\n",
       "        -4.38779394e+04, -8.42844693e+04, -7.12972771e+04,\n",
       "        -2.18646617e+04, -2.59846200e+04, -5.28870444e+03,\n",
       "         9.75431103e+03,  1.51375893e+04, -6.26497656e+04,\n",
       "         6.55968123e+04],\n",
       "       [-7.72231140e+04,  4.25327538e+04,  5.50752930e+03,\n",
       "        -1.56319200e+04, -6.54039495e+04,  2.98089392e+04,\n",
       "        -3.78623139e+04, -2.85127659e+04,  2.18061533e+04,\n",
       "        -1.65125912e+04, -3.23449036e+04,  6.52937004e+04,\n",
       "         6.22884923e+04,  9.73373239e+04,  1.87772304e+04,\n",
       "        -1.76589963e+04, -6.17865341e+04, -7.23850645e+04,\n",
       "         2.90351088e+04,  2.64041690e+04, -1.72888230e+04,\n",
       "         7.69665425e+04, -3.38159778e+04,  1.12866742e+05,\n",
       "        -7.47558686e+04],\n",
       "       [-5.64472957e+04,  1.15785437e+04,  6.10291053e+04,\n",
       "        -2.38676851e+04,  4.83718078e+04,  1.08193972e+04,\n",
       "         4.34800739e+04, -1.81506955e+04, -3.85507126e+04,\n",
       "        -4.50692644e+04,  6.46126980e+04,  3.64116545e+04,\n",
       "        -2.84181163e+04, -9.49500166e+03, -3.91976346e+04,\n",
       "         3.60588879e+04,  6.00395531e+04,  1.47653074e+05,\n",
       "        -5.09578074e+04,  6.96711722e+04, -1.33770416e+03,\n",
       "         6.46024330e+04,  1.20520938e+05, -1.07519422e+05,\n",
       "        -1.13656100e+04],\n",
       "       [-6.65361295e+04,  1.64434895e+04,  1.54335858e+04,\n",
       "         1.10538160e+04,  8.80915357e+04,  6.22724476e+04,\n",
       "         5.27492080e+04, -7.50234076e+04,  7.63989380e+03,\n",
       "        -5.83563879e+04,  5.90758345e+04,  7.73193636e+04,\n",
       "         2.80840139e+04, -1.38141999e+04, -4.77267259e+03,\n",
       "        -2.93321962e+04, -2.87853109e+04,  6.80064054e+04,\n",
       "         2.20113585e+04,  1.02717504e+05, -5.21195419e+04,\n",
       "         2.84323835e+04,  1.67041577e+04,  1.51480658e+05,\n",
       "        -5.84739807e+04],\n",
       "       [ 5.91788905e+04, -9.44884167e+04,  1.69688853e+05,\n",
       "         6.48503399e+04,  1.84514376e+05,  1.22652922e+05,\n",
       "         1.47264013e+04,  1.27025271e+05,  1.76443382e+04,\n",
       "        -1.07445727e+05, -1.64869159e+05,  1.25753006e+05,\n",
       "        -5.36290202e+04,  7.15265338e+04,  9.65922914e+04,\n",
       "        -1.07191646e+05, -1.03278165e+04,  6.63417820e+04,\n",
       "        -4.26941694e+04,  8.61192684e+03, -8.21378654e+03,\n",
       "         2.21854468e+04, -8.59882835e+04,  1.18890296e+05,\n",
       "        -7.11754632e+04],\n",
       "       [ 6.29377344e+04,  8.13900521e+04,  7.81265439e+03,\n",
       "         1.02808057e+05, -3.82727831e+04, -1.00624052e+05,\n",
       "         7.47282010e+04,  6.14085943e+04, -2.46810126e+04,\n",
       "        -9.89564264e+04, -7.60697975e+04,  9.34842033e+04,\n",
       "        -6.39742384e+04, -3.19239378e+04, -8.55954852e+04,\n",
       "         5.56510892e+04,  5.29724520e+04,  8.20638349e+04,\n",
       "         6.49999627e+03, -5.55431833e+04,  7.21956164e+04,\n",
       "         2.66714997e+04, -2.62592333e+04, -6.59588912e+04,\n",
       "        -5.74222157e+04],\n",
       "       [-7.70559870e+04,  1.83553058e+04, -1.26322182e+04,\n",
       "         3.34251414e+04, -6.00776517e+03, -4.18874072e+04,\n",
       "         1.00071823e+05, -6.31063403e+04,  7.47192108e+03,\n",
       "         1.20648193e+05,  3.34270723e+04,  5.85985638e+04,\n",
       "         1.00166594e+05, -4.28571588e+04,  1.29933740e+04,\n",
       "        -3.84216858e+04, -1.94664296e+03,  3.98786000e+04,\n",
       "        -5.31166855e+04, -9.99097271e+04, -9.17926688e+04,\n",
       "        -3.05654444e+04,  6.03774711e+04,  8.65050607e+04,\n",
       "        -9.17964122e+04],\n",
       "       [-1.95680177e+04, -5.92864861e+04, -6.66752282e+04,\n",
       "        -2.00100679e+04, -5.81785335e+03,  2.70409775e+04,\n",
       "         1.96388338e+04,  3.42490264e+04, -4.31955344e+04,\n",
       "         5.02941239e+03, -6.04269024e+04, -4.45683481e+04,\n",
       "        -5.20886064e+04,  1.28801592e+05,  3.38340327e+04,\n",
       "        -1.96647643e+04, -1.70992894e+04, -6.24878256e+04,\n",
       "         1.72999008e+04, -1.91791014e+03, -4.71869833e+04,\n",
       "        -1.16745271e+04,  7.06966627e+03, -1.31099163e+04,\n",
       "        -6.24062950e+03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.transpose(sample, (0, 2, 1))@check_error)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3d590-2ad2-4fcb-bda2-9b4ad545148d",
   "metadata": {},
   "source": [
    "# Softmax (dim=-1) check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f9f0c4c-3535-4810-9493-ebbf6d73870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxLayer3D(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.forward_result = None\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        self.input = x\n",
    "        exp = np.exp(x)\n",
    "        self.forward_result = exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "        return self.forward_result\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        \"https://binpord.github.io/2021/09/26/softmax_backprop.html\"\n",
    "        return (output_error - (output_error*self.forward_result).sum(axis=-1, keepdims=True)) * self.forward_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3de4af5-0e55-48ed-9049-d98da1b20727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода линейного слоя: (100, 32, 16)\n",
      "Градиент по входу совпадает: True\n"
     ]
    }
   ],
   "source": [
    "# проверка того, softmax работает также как и в torch\n",
    "\n",
    "sample = np.random.normal(loc=0, scale=100, size=(100, 32, 16))\n",
    "\n",
    "softmax = SoftMaxLayer3D()\n",
    "\n",
    "torch_input = torch.tensor(sample, dtype=torch.float64, requires_grad=True)\n",
    "torch_out = nn.functional.softmax(torch_input, dim=-1)\n",
    "\n",
    "# проверка что forward работает также как у torch, \n",
    "print(\"Vanilla Forward такой же как и torch forward:\", np.allclose(torch_out.detach().numpy(), softmax(sample)))\n",
    "\n",
    "print(\"Shape выхода слоя:\", softmax(sample).shape)\n",
    "\n",
    "# случайная ошибка, которая приходит \"сверху\" от вышестоящих слоев, по размеру она совпадает с выходом слоя\n",
    "check_error = np.random.normal(loc=-3, scale=100, size=(softmax(sample).shape))\n",
    "check_error_torch = torch.tensor(check_error)\n",
    "\n",
    "torch_out.backward(check_error_torch)  # считаем градиенты для всех тензоров, которые участвуют в forward проходе\n",
    "in_error = softmax.backward(check_error)  # тоже самое, только в ручном слое\n",
    "\n",
    "# проверка градиентов весов и входа\n",
    "print(\"Градиент по входу совпадает:\", np.allclose(torch_input.grad.detach().numpy(), in_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa6f69-ec31-4c49-a3ab-58d84cebf2e2",
   "metadata": {},
   "source": [
    "# attention check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43070d43-77aa-488f-b34a-697d143b2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(BaseLayer):\n",
    "    def __init__(self, hid_dim: int, n_heads: int) -> None:\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.input = None\n",
    "        self.attn_bias = None\n",
    "        self.attentions = []\n",
    "        self.q = None\n",
    "        self.k = None\n",
    "        self.v = None\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = hid_dim // n_heads\n",
    "        \n",
    "        self.c_attn = Linear3d(hid_dim, hid_dim * 3)\n",
    "        self.c_proj = Linear3d(hid_dim, hid_dim)\n",
    "        self.softmax = SoftMaxLayer3D()\n",
    "\n",
    "        self.scale = np.sqrt(self.head_size)\n",
    "\n",
    "    def set_optimizer(self, optimizer) -> None:\n",
    "        self.c_attn.set_optimizer(optimizer)\n",
    "        self.c_proj.set_optimizer(optimizer)\n",
    "\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        self.input = x\n",
    "        \n",
    "        q_k_v = self.c_attn(x)\n",
    "        self.q = q_k_v[:, :, :self.hid_dim]\n",
    "        self.k = q_k_v[:, :, self.hid_dim:self.hid_dim*2]\n",
    "        self.v = q_k_v[:, :, self.hid_dim*2:self.hid_dim*3]\n",
    "        assert self.q.shape == self.k.shape == self.v.shape == x.shape, \"q, k and v must have the same shape as x\"\n",
    "\n",
    "        head_outputs = []\n",
    "        for head_index in range(self.n_heads):\n",
    "            head_selector = range(self.head_size * head_index, self.head_size * (head_index + 1))\n",
    "\n",
    "            head_queries = self.q[..., head_selector]\n",
    "            head_keys = self.k[..., head_selector]\n",
    "            head_values = self.v[..., head_selector]\n",
    "\n",
    "            single_head_output = self._attention_for_head(\n",
    "                head_queries, head_keys, head_values,\n",
    "                is_causal=True)\n",
    "            head_outputs.append(single_head_output)\n",
    "\n",
    "        combined_head_outputs = np.concatenate(head_outputs, axis=-1)\n",
    "        return self.c_proj(combined_head_outputs)\n",
    "\n",
    "    def _attention_for_head(self, query, key, value, is_causal=False):\n",
    "        L, S = query.shape[-2], key.shape[-2]\n",
    "        self.attn_bias = np.zeros((L, S), dtype=query.dtype)\n",
    "        if is_causal:\n",
    "            temp_mask = np.tril(np.ones((L, S)))\n",
    "            self.attn_bias = np.where(temp_mask==0, float('-inf'), 0)\n",
    "            self.attn_bias = self.attn_bias.astype(query.dtype)\n",
    "    \n",
    "        attn_weight = query @ key.transpose(0, 2, 1) / self.scale\n",
    "        attn_weight += self.attn_bias\n",
    "        \n",
    "        attn_weight = self.softmax(attn_weight)\n",
    "        self.attentions.append(attn_weight)\n",
    "        \n",
    "        result = attn_weight @ value\n",
    "\n",
    "        # result = self.softmax((query @ key.transpose(0, 2, 1) / self.scale) + self.attn_bias) @ value\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _attention_for_head_grad(self, query, key, value, output_error, head_n):\n",
    "        # looking at the result expression in the forward pass\n",
    "        cur_attention = self.attentions[head_n]\n",
    "        \n",
    "        v_grad = cur_attention.transpose((0, 2, 1)) @ output_error\n",
    "        input_error = output_error @ value.transpose((0, 2, 1))\n",
    "\n",
    "        # we use layer, which uses it's states to calculate grad, so we need to set state that was used during forward pass in current head\n",
    "        self.softmax.forward_result = cur_attention\n",
    "        softmax_grad = self.softmax.backward(input_error)\n",
    "\n",
    "        k_grad = softmax_grad.transpose(0, 2, 1) @ query / self.scale # we need to transpose output error due to the fact key was transposed in forward\n",
    "        q_grad = softmax_grad @ key / self.scale\n",
    "\n",
    "        return q_grad, k_grad, v_grad\n",
    "\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        c_proj_w_grad, c_proj_b_grad, projection_error = self.c_proj.backward(output_error)\n",
    "        \n",
    "        q_grads, k_grads, v_grads = [], [], []\n",
    "        for head_index in range(self.n_heads):\n",
    "            # for each head we choose it's error\n",
    "            head_selector = range(self.head_size * head_index, self.head_size * (head_index + 1))\n",
    "\n",
    "            attention_error = projection_error[..., head_selector]\n",
    "            head_queries = self.q[..., head_selector]\n",
    "            head_keys = self.k[..., head_selector]\n",
    "            head_values = self.v[..., head_selector]\n",
    "\n",
    "            q_grad, k_grad, v_grad = self._attention_for_head_grad(head_queries, head_keys, head_values, attention_error, head_index)\n",
    "            q_grads.append(q_grad)\n",
    "            k_grads.append(k_grad)\n",
    "            v_grads.append(v_grad)\n",
    "\n",
    "        q_grads = np.concatenate(q_grads, axis=-1)\n",
    "        k_grads = np.concatenate(k_grads, axis=-1)\n",
    "        v_grads = np.concatenate(v_grads, axis=-1)\n",
    "\n",
    "        q_k_v_output = np.concatenate([q_grads, k_grads, v_grads], axis=-1)\n",
    "        \n",
    "        c_attn_w_grad, c_attn_b_grad, input_error = self.c_attn.backward(q_k_v_output)\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "353a550d-b039-46de-997e-5d6413f947f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch attention\n",
    "class MaskedSelfAttention(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        self.c_attn = nn.Linear(dim, dim * 3)  # query + key + value, combined\n",
    "        self.c_proj = nn.Linear(dim, dim)  # output projection\n",
    "        self.dim, self.num_heads = dim, num_heads\n",
    "        self.head_size = dim // num_heads\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_size]))\n",
    "\n",
    "    # you can choose less effective method and uncomment the code below, it works the same\n",
    "    # ------------- start of less effective -------------\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     q, k, v = self.c_attn(x).split(dim=-1, split_size=self.dim)\n",
    "    #     assert q.shape == k.shape == v.shape == x.shape, \"q, k and v must have the same shape as x\"\n",
    "\n",
    "\n",
    "    #     # Note: this is an inefficient implementation that uses a for-loop.\n",
    "    #     # To get the full grade during homework, please re-implement this code:\n",
    "    #     # 1) do not use for-loops (or other loops). Compute everything in parallel with vectorized operations\n",
    "    #     # 2) do not use F.scaled_dot_product_attention - write your own attention code using basic PyTorch ops\n",
    "    #     head_outputs = []\n",
    "    #     for head_index in range(self.num_heads):\n",
    "    #         head_selector = range(self.head_size * head_index, self.head_size * (head_index + 1))\n",
    "\n",
    "    #         head_queries = q[..., head_selector]\n",
    "    #         head_keys = k[..., head_selector]\n",
    "    #         head_values = v[..., head_selector]\n",
    "\n",
    "    #         single_head_output = self.scaled_dot_product_attention(\n",
    "    #             head_queries, head_keys, head_values,\n",
    "    #             is_causal=True)\n",
    "    #         # docs: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
    "    #         head_outputs.append(single_head_output)\n",
    "\n",
    "    #     combined_head_outputs = torch.cat(head_outputs, dim=-1)\n",
    "    #     return self.c_proj(combined_head_outputs)\n",
    "\n",
    "    # def scaled_dot_product_attention(self, query, key, value, attn_mask=None, dropout_p=0.0, is_causal=False, scale=None) -> torch.Tensor:\n",
    "    #     # Efficient implementation equivalent to the following:\n",
    "    #     L, S = query.size(-2), key.size(-2)\n",
    "    #     scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "    #     attn_bias = torch.zeros(L, S, dtype=query.dtype)\n",
    "    #     if is_causal:\n",
    "    #         assert attn_mask is None\n",
    "    #         temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal=0)\n",
    "    #         attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "    #         attn_bias.to(query.dtype)\n",
    "    \n",
    "    #     if attn_mask is not None:\n",
    "    #         if attn_mask.dtype == torch.bool:\n",
    "    #             attn_bias.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "    #         else:\n",
    "    #             attn_bias += attn_mask\n",
    "    #     attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    #     attn_weight += attn_bias\n",
    "    #     attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "    #     # attn_weight = torch.dropout(attn_weight, dropout_p, train=True)\n",
    "    #     return attn_weight @ value\n",
    "\n",
    "    # ------------- end of less effective -------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        # kinda more effective\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        q, k, v = self.c_attn(x).split(dim=-1, split_size=self.dim)\n",
    "        # [BATCH_SIZE, SEQ_LEN, DIM]\n",
    "        assert q.shape == k.shape == v.shape == x.shape, \"q, k and v must have the same shape as x\"\n",
    "        \n",
    "        # [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_SIZE]\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_size).permute(0, 2, 1, 3)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.head_size).permute(0, 2, 1, 3)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.head_size).permute(0, 2, 1, 3)\n",
    "\n",
    "        # [BATCH_SIZE, NUM_HEADS, SEQ_LEN, SEQ_LEN]\n",
    "        energy = torch.matmul(q, k.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "        # чтобы не смотреть в будущее\n",
    "        mask = torch.tril(torch.ones((seq_len, seq_len)))\n",
    "        energy = energy.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # [BATCH_SIZE, NUM_HEADS, SEQ_LEN, SEQ_LEN]\n",
    "        probs = nn.functional.softmax(energy, dim=-1)\n",
    "\n",
    "        # [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_SIZE]\n",
    "        output = torch.matmul(probs, v)\n",
    "\n",
    "        # [BATCH_SIZE, SEQ_LEN, NUM_HEADS, HEAD_SIZE]\n",
    "        output = output.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # [BATCH_SIZE, SEQ_LEN, DIM]\n",
    "        output = output.view(batch_size, -1, self.dim)\n",
    "\n",
    "        # [BATCH_SIZE, SEQ_LEN, DIM]\n",
    "        output = self.c_proj(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "386b2420-5232-496b-8d84-c4936425f4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число голов: 1\n",
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода слоя: (100, 32, 36)\n",
      "Градиент по входу совпадает: True\n",
      "==============================\n",
      "Число голов: 3\n",
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода слоя: (100, 32, 36)\n",
      "Градиент по входу совпадает: True\n",
      "==============================\n",
      "Число голов: 6\n",
      "Vanilla Forward такой же как и torch forward: True\n",
      "Shape выхода слоя: (100, 32, 36)\n",
      "Градиент по входу совпадает: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# проверка того, что multihead masked attention работает также как и в torch\n",
    "\n",
    "for head_n in [1, 3, 6]:\n",
    "    print('Число голов:', head_n)\n",
    "    sample = np.random.randn(100, 32, 36)\n",
    "    \n",
    "    attention = MultiHeadAttentionLayer(36, head_n)\n",
    "    torch_attention = MaskedSelfAttention(36, head_n)\n",
    "    # ставим одинаковые иходные веса для слоев\n",
    "    attention.c_attn.w = torch_attention.c_attn.weight.data.numpy().T\n",
    "    attention.c_attn.b = torch_attention.c_attn.bias.data.numpy().reshape(1, -1)\n",
    "    attention.c_proj.w = torch_attention.c_proj.weight.data.numpy().T\n",
    "    attention.c_proj.b = torch_attention.c_proj.bias.data.numpy().reshape(1, -1)\n",
    "\n",
    "    attention_out = attention(sample)\n",
    "    torch_input = torch.tensor(sample, dtype=torch.float32, requires_grad=True)\n",
    "    torch_out = torch_attention(torch_input)\n",
    "    \n",
    "    # проверка что forward работает также как у torch, \n",
    "    print(\"Vanilla Forward такой же как и torch forward:\", np.allclose(torch_out.detach().numpy(), attention_out, atol=1e-6))\n",
    "    \n",
    "    print(\"Shape выхода слоя:\", attention_out.shape)\n",
    "    \n",
    "    # случайная ошибка, которая приходит \"сверху\" от вышестоящих слоев, по размеру она совпадает с выходом слоя\n",
    "    check_error = np.random.randn(100, 32, 36)\n",
    "    check_error_torch = torch.tensor(check_error)\n",
    "    \n",
    "    torch_out.backward(check_error_torch)  # считаем градиенты для всех тензоров, которые участвуют в forward проходе\n",
    "    in_error = attention.backward(check_error)  # тоже самое, только в ручном слое\n",
    "    \n",
    "    # проверка градиентов весов и входа\n",
    "    print(\"Градиент по входу совпадает:\", np.allclose(torch_input.grad.detach().numpy(), in_error, atol=1e-6))\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba46458-7753-4de9-8ea1-a47273fbf7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yandex_nlp",
   "language": "python",
   "name": "yandex_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
